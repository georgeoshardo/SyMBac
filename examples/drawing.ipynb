{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respiratory-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import raster_geometry as rg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rotate\n",
    "import pickle\n",
    "import sys\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "sys.path.insert(0,'/home/georgeos/Documents/GitHub/SYMPTOMM2')\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "from skimage.morphology import opening\n",
    "from PIL import Image       \n",
    "import pymunk\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "from skimage import data\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage import draw\n",
    "#import napari\n",
    "from itertools import combinations\n",
    "from SYMPTOMM import PSF\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from cupyx.scipy.ndimage import convolve as cuconvolve\n",
    "import tifffile\n",
    "from skimage.exposure import match_histograms\n",
    "import cupy as cp\n",
    "from scipy.optimize import dual_annealing, shgo\n",
    "from skimage.transform import resize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.optimize import basinhopping\n",
    "import image_similarity_measures\n",
    "from image_similarity_measures.quality_metrics import rmse, psnr, fsim, issm, sre, sam, uiq\n",
    "from SYMPTOMM.general_drawing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spare-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/output_pickles/cell_timeseries_short_trench.p\", \"rb\") as f:\n",
    "    cell_timeseries = pickle.load(f)\n",
    "with open(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/output_pickles/space_timeseries_short_trench.p\", \"rb\") as f:\n",
    "    space = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "speaking-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=14)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in cell_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "above-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 5737.76it/s]\n"
     ]
    }
   ],
   "source": [
    "do_transformation = False\n",
    "scenes = Parallel(n_jobs=14)(delayed(draw_scene)(\n",
    "    cell_properties, False\n",
    ") for cell_properties in tqdm(cell_timeseries_properties[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adolescent-neighborhood",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes[-1][1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/training_data/OPL_renders\"\n",
    "_ = Parallel(n_jobs=10)(delayed(scene_plotter)(scenes[x][1],output_dir,\"OPL_mask\",x+4000,matplotlib_draw=False) for x in range(len(scenes)))\n",
    "_ = Parallel(n_jobs=10)(delayed(scene_plotter)(scenes[x][0],output_dir,\"OPL_intensity\",x+4000,matplotlib_draw=False) for x in range(len(scenes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-librarian",
   "metadata": {},
   "source": [
    "# Phase Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_segments = main_segments.reindex(index=main_segments.index[::-1]) # run if you get a zero-width image output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 50\n",
    "\n",
    "#trench_multiplier = 30\n",
    "#cell_multiplier = 2\n",
    "#background_multiplier = 10\n",
    "#grid_def = [range(15,trench_multiplier), np.arange(0.1,cell_multiplier,0.1), range(background_multiplier)]\n",
    "#grid = list(itertools.product(*grid_def))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(generate_PC_OPL(30,1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PC_OPLs = np.array([generate_PC_OPL(*k) for k in grid])\n",
    "#viewer = napari.view_image(np.array(PC_OPLs), rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_phase = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(56)).zfill(2),\n",
    "    str(np.random.randint(20,25)).zfill(3)\n",
    "))\n",
    "plt.imshow(real_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-sauce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-press",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cuconvolve(cp.array(PC_OPLs[2000]),kernel)\n",
    "output = output.get()\n",
    "output = rescale(output, 1/4, anti_aliasing=False)[3:182,3:-3]\n",
    "output = random_noise(output, mode=\"gaussian\", mean=5,var=0.0000051,clip=False)\n",
    "#viewer = napari.view_image(output_rescaled, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_segment = output\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(top_segment,cmap=\"Greys_r\")\n",
    "top_segment.shape += (1,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-request",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = list(zip([min_sigma, 1.0, 0.2, 1], [20.0, 30.0, 5.0, 20.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = shgo(objective_function, bounds = np.array(bounds),callback=callbackSHGo,options={\"minimize_every_iter\":True})\n",
    "ret = dual_annealing(objective_function, bounds = np.array(bounds),callback=callbackF,maxiter=1000,initial_temp=5*10**4,x0=ret.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.callbacks import VerboseCallback\n",
    "res = gp_minimize(objective_function,                  # the function to minimize\n",
    "                  bounds,      # the bounds on each dimension of x\n",
    "                  acq_func=\"gp_hedge\",      # the acquisition function\n",
    "                  n_calls=50,         # the number of evaluations of f\n",
    "                  n_random_starts=5,  # the number of random initialization points\n",
    "                 n_jobs = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_get_image(z):\n",
    "    σ, trench_multiplier, cell_multiplier, background_multiplier, = z\n",
    "    expanded_scene = generate_PC_OPL(trench_multiplier,cell_multiplier,background_multiplier)\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, σ)\n",
    "    convolved_image = convolve_rescale(expanded_scene,kernel)[0:182,10:-10]\n",
    "    #convolved_image = random_noise(convolved_image, mode=\"gaussian\", mean=5,var=σ2,clip=False)\n",
    "    convolved_image = match_histograms(convolved_image, real_image, multichannel=False)\n",
    "    convolved_image = resize(convolved_image,real_image.shape,clip=False,preserve_range=False,anti_aliasing=None)\n",
    "    convolved_image = convolved_image/np.max(convolved_image)\n",
    "    ssim_real = ssim(convolved_image, real_image)\n",
    "    intersection = return_intersection_between_image_hists(convolved_image, real_image, 100)\n",
    "    return convolved_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(1,25)).zfill(3)\n",
    "))\n",
    "optimised_image = objective_function_get_image(ret.x)\n",
    "noisy_image = random_noise(optimised_image, mode=\"gaussian\", mean=5,var=0.0002,clip=False)\n",
    "viewer = napari.view_image(noisy_image, rgb=False)\n",
    "\n",
    "\n",
    "\n",
    "viewer = napari.view_image(real_image, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_outputs = []\n",
    "for x in range(len(PC_OPLs)):\n",
    "    output = cuconvolve(cp.array(PC_OPLs[x]),kernel)\n",
    "    output = output.get()\n",
    "    output = rescale(output, 1/1.75, anti_aliasing=False)[:364,:]\n",
    "    output = random_noise(output, mode=\"gaussian\", mean=5,var=0.85,clip=False)\n",
    "    output_rescaled = match_histograms(output, real_phase[15][30:,:], multichannel=False)\n",
    "    convolved_outputs.append(output_rescaled)\n",
    "convolved_outputs = np.array(convolved_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(convolved_outputs**2, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "    scalebar = ScaleBar(scale, 'um')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.gca().add_artist(scalebar)\n",
    "    plt.imshow(output_rescaled,cmap=\"Greys_r\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Phase Contrast\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-malpractice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuconvolve(cp.array(PC_OPLs[x]),kernel).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-acrylic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4792836a-5c03-4de1-a1fe-6f5a638d14d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from SyMBac.external.DeLTA.model import unet_seg\n",
    "from SyMBac.external.DeLTA.data import saveResult_seg, predictGenerator_seg, postprocess\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tifffile\n",
    "from skimage.exposure import rescale_intensity\n",
    "import skimage\n",
    "from skimage.morphology import opening\n",
    "from glob import glob\n",
    "from tifffile import imread, imsave\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "#from csbdeep.utils import Path, normalize\n",
    "#from stardist import fill_label_holes, random_label_cmap\n",
    "from skimage.measure import regionprops_table, label\n",
    "#lbl_cmap = random_label_cmap()\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5efa51-1fd9-4dee-95b2-4b6d444a24ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DeLTA_data =  \"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/delta_hist_mid_large/\"\n",
    "image_dirs = glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/real_data/*.tif\")\n",
    "training_set = DeLTA_data\n",
    "target_size = (192,32)\n",
    "input_size = target_size + (1,)\n",
    "process_size = 4096\n",
    "# Files:\n",
    "\n",
    "models = natsorted(glob(DeLTA_data + '/models/*'))\n",
    "model_file = DeLTA_data + \"/models/saved-model-frac-0.0005.hdf5\"\n",
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e3e54-bd27-4bfb-bedc-7976adcbb2c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cell_data = pd.DataFrame()\n",
    "for t in range(1):\n",
    "    \n",
    "    \n",
    "    \n",
    "    #inputs_folder = DeLTA_data + 'mother_machine/evaluation/preprocessed/img/'\n",
    "    #outputs_folder = DeLTA_data + 'mother_machine/evaluation/seg_output/'\n",
    "\n",
    "    # Load up model:\n",
    "    model = unet_seg(input_size = input_size)\n",
    "    model.load_weights(model_file)\n",
    "    \n",
    "    data = imread(image_dirs[103])[:1200,:256]#[:,:256,5:37]\n",
    "    X = []\n",
    "    for x in range(len(data)):\n",
    "        X.append(data[x])\n",
    "\n",
    "    requires_resize = True\n",
    "    resize_shape = (192,32) # (320,64) (512,128) (256,64)\n",
    "    if requires_resize:\n",
    "        X = [resize(x,resize_shape, order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in tqdm(X)]\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    cell_data_temp = pd.DataFrame()\n",
    "    all_labels = []\n",
    "    all_imgs = []\n",
    "    for x in tqdm(range(len(X))):\n",
    "        img = normalize(X[x], 1,99.8, axis=(0,1))\n",
    "        masks = model.predict(img.reshape(1,192,32,1)).reshape(192,32)\n",
    "        all_labels.append(masks)\n",
    "        all_imgs.append(img)\n",
    "\n",
    "    cell_data_temp = pd.DataFrame()\n",
    "    properties = [\"area\",\"centroid\",\"major_axis_length\",\"minor_axis_length\",\"label\",\"orientation\"]\n",
    "    for x in range(len(all_labels)):\n",
    "        try:\n",
    "            #border_cleared_nms = clear_border(nms_labels,buffer_size=5).astype(bool)*nms_labels\n",
    "            #all_labels_nms.append(border_cleared_nms)\n",
    "            temp_data = pd.DataFrame(regionprops_table(label((all_labels[x]>0.96).astype(bool)*1),properties = properties))\n",
    "            temp_data = temp_data.sort_values(by = \"centroid-0\").iloc[0]\n",
    "            current_cell_data  = temp_data\n",
    "            current_cell_data[\"time\"] = int(x)\n",
    "            cell_data_temp = cell_data_temp.append(current_cell_data)\n",
    "        except:\n",
    "            pass\n",
    "    cell_data_temp.reset_index(drop=True);\n",
    "    cell_data_temp[\"epoch\"] = t\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot((cell_data_temp[\"major_axis_length\"].reset_index(drop=True)*0.06*2))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    cell_data = cell_data.append(cell_data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1db29-711f-4598-9e2e-0b6c13e74e1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib,numpy\n",
    "import pylab\n",
    "# A random colormap for matplotlib\n",
    "cmap = matplotlib.colors.ListedColormap ( numpy.random.rand ( 256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ffc6b5-bc94-4361-8734-e4ca21b9c8fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for x in range(len(all_imgs)):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(2,6))\n",
    "    ax1.imshow(all_imgs[x],cmap=\"Greys_r\")\n",
    "    ax2.imshow(label(all_labels[x]>0.8),cmap,interpolation=\"nearest\")\n",
    "    ax1.axis(\"off\")\n",
    "    ax2.axis(\"off\")\n",
    "    plt.savefig(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/one_shot_diag/{}.jpeg\".format(str(x).zfill(4)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f076b83-2a68-4261-9f55-ee215450b133",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(label(all_labels[418]>0.99),cmap,interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f46036-16b4-47a5-8ad2-5b8a0e71d102",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Segmentation of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d9a4c1-f26a-4a54-bdad-b7193cfdebf8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-26 11:16:05.601551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-26 11:16:05.625739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-12-26 11:16:05.625753: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-26 11:16:05.626282: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/georgeos/miniconda3/envs/SyMBac/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/DeLTA_new_training_data_hist_fourier/models/new_saved-model-70.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_62447/1035310528.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mt_seg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1200\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0munet_seg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0mcell_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/SyMBac/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/SyMBac/lib/python3.9/site-packages/h5py/_hl/files.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds)\u001B[0m\n\u001B[1;32m    505\u001B[0m                                  \u001B[0mfs_persist\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfs_persist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfs_threshold\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfs_threshold\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m                                  fs_page_size=fs_page_size)\n\u001B[0;32m--> 507\u001B[0;31m                 \u001B[0mfid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmake_fid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muserblock_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfapl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfcpl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mswmr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mswmr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    508\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlibver\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/SyMBac/lib/python3.9/site-packages/h5py/_hl/files.py\u001B[0m in \u001B[0;36mmake_fid\u001B[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001B[0m\n\u001B[1;32m    218\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mswmr\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mswmr_support\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    219\u001B[0m             \u001B[0mflags\u001B[0m \u001B[0;34m|=\u001B[0m \u001B[0mh5f\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mACC_SWMR_READ\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 220\u001B[0;31m         \u001B[0mfid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh5f\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfapl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfapl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    221\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'r+'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m         \u001B[0mfid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh5f\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh5f\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mACC_RDWR\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfapl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfapl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mh5py/_objects.pyx\u001B[0m in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mh5py/_objects.pyx\u001B[0m in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mh5py/h5f.pyx\u001B[0m in \u001B[0;36mh5py.h5f.open\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] Unable to open file (unable to open file: name = '/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/DeLTA_new_training_data_hist_fourier/models/new_saved-model-70.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "DeLTA_data =  \"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/DeLTA_new_training_data_hist_fourier\"\n",
    "image_dirs = glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/real_data/*.tif\")\n",
    "training_set = DeLTA_data\n",
    "target_size = (256,48)\n",
    "input_size = target_size + (1,)\n",
    "process_size = 4096\n",
    "# Files:\n",
    "\n",
    "models = natsorted(glob(DeLTA_data + '/models/*'))\n",
    "epoch = 70\n",
    "model_file = DeLTA_data + \"/models/new_saved-model-{}.hdf5\".format(str(epoch).zfill(2))\n",
    "model_file\n",
    "t_seg = 1200\n",
    "model = unet_seg(input_size = input_size)\n",
    "model.load_weights(model_file)\n",
    "cell_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91372081-e2e7-4044-80ad-ca0189f937c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    savedir=\"../Segmented_Data_Full_New_Epoch_{}_Exponential_Model_hist_fourier\".format(str(epoch).zfill(2))\n",
    "    os.mkdir(savedir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98eef9f2-8fb5-483b-b3ed-28a2d9f11ab4",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7564beb65984a25846ab76bded44bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t in tqdm(range(len(image_dirs))):\n",
    "    data = imread(image_dirs[t])[:t_seg,:256]#[:,:256,5:37]\n",
    "    X = []\n",
    "    for x in range(len(data)):\n",
    "        X.append(data[x])\n",
    "    requires_resize = True\n",
    "    resize_shape = target_size # (320,64) (512,128) (256,64)\n",
    "    if requires_resize:\n",
    "        X = [resize(x,resize_shape, order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in (X)]\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    cell_data_temp = pd.DataFrame()\n",
    "    all_imgs = []\n",
    "    for x in (range(len(X))):\n",
    "        img = normalize(X[x], 1,99.8, axis=(0,1))\n",
    "        all_imgs.append(img)\n",
    "    all_imgs = np.array(all_imgs)\n",
    "    masks = model.predict(all_imgs.reshape((t_seg,)+target_size+(1,))).reshape((t_seg,)+target_size)\n",
    "    output_data = np.zeros((2,)  +  masks.shape)\n",
    "    for x in range(len(all_imgs)):\n",
    "        output_data[1,x,:,:] = all_imgs[x]\n",
    "    output_data[0,:,:,:] = masks\n",
    "    tifffile.imsave(\"{}/trench_{}.tif\".format(savedir,t),output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca66d2e-9eca-4219-8133-317c0346d3b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Segmentation of variable data amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3fecb-c217-4449-901d-db9cf3879f32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DeLTA_data =  \"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/delta_hist_mid_large/\"\n",
    "image_dirs = glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/real_data/*.tif\")\n",
    "training_set = DeLTA_data\n",
    "target_size = (192,32)\n",
    "input_size = target_size + (1,)\n",
    "process_size = 4096\n",
    "# Files:\n",
    "\n",
    "models = natsorted(glob(DeLTA_data + '/models/*'))\n",
    "model_files = glob(DeLTA_data+\"/models/*frac*\")\n",
    "num_imgs = (np.array([0.005,0.001,0.0005,0.01,0.1,0.2,0.5,0.75,0.9])*2000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca83811-119b-4c69-99d2-f37c4e969ed1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for num in num_imgs:\n",
    "    os.mkdir(\"../Variable_Data_Segmentations/{}\".format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fd726-fa13-4930-a8a7-69aa0c174a0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(num_imgs)\n",
    "(model_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af5e2e-c3eb-46f5-8c72-56ac99047989",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_seg = 300\n",
    "for nn in tqdm(range(nn,len(num_imgs))):\n",
    "    model = unet_seg(input_size = input_size)\n",
    "    model.load_weights(model_files[nn])\n",
    "    cell_data = pd.DataFrame()\n",
    "\n",
    "    for t in tqdm(range(len(image_dirs))):\n",
    "    #inputs_folder = DeLTA_data + 'mother_machine/evaluation/preprocessed/img/'\n",
    "    #outputs_folder = DeLTA_data + 'mother_machine/evaluation/seg_output/'\n",
    "\n",
    "        # Load up model:\n",
    "\n",
    "\n",
    "        data = imread(image_dirs[t])[:t_seg,:256]#[:,:256,5:37]\n",
    "        X = []\n",
    "        for x in range(len(data)):\n",
    "            X.append(data[x])\n",
    "\n",
    "        requires_resize = True\n",
    "        resize_shape = (192,32) # (320,64) (512,128) (256,64)\n",
    "        if requires_resize:\n",
    "            X = [resize(x,resize_shape, order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in (X)]\n",
    "\n",
    "        n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "        axis_norm = (0,1)   # normalize channels independently\n",
    "        # axis_norm = (0,1,2) # normalize channels jointly\n",
    "        if n_channel > 1:\n",
    "            print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "        cell_data_temp = pd.DataFrame()\n",
    "        all_imgs = []\n",
    "        for x in (range(len(X))):\n",
    "            img = normalize(X[x], 1,99.8, axis=(0,1))\n",
    "            all_imgs.append(img)\n",
    "        all_imgs = np.array(all_imgs)\n",
    "        masks = model.predict(all_imgs.reshape(t_seg,192,32,1)).reshape(t_seg,192,32)\n",
    "        output_data = np.zeros((2,)  +  masks.shape)\n",
    "        for x in range(len(all_imgs)):\n",
    "            output_data[1,x,:,:] = all_imgs[x]\n",
    "        output_data[0,:,:,:] = masks\n",
    "        tifffile.imsave(\"../Variable_Data_Segmentations/{}/trench_{}.tif\".format(num_imgs[nn],t),output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792836a-5c03-4de1-a1fe-6f5a638d14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SyMBac.external.DeLTA.model import unet_seg\n",
    "from SyMBac.external.DeLTA.data import saveResult_seg, predictGenerator_seg, postprocess\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tifffile\n",
    "from skimage.exposure import rescale_intensity\n",
    "import skimage\n",
    "from skimage.morphology import opening\n",
    "from glob import glob\n",
    "from tifffile import imread, imsave\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "from csbdeep.utils import Path, normalize\n",
    "from stardist import fill_label_holes, random_label_cmap\n",
    "from skimage.measure import regionprops_table, label\n",
    "lbl_cmap = random_label_cmap()\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5efa51-1fd9-4dee-95b2-4b6d444a24ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DeLTA_data =  \"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/delta_hist_mid_large/\"\n",
    "image_dirs = glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/real_data/*.tif\")\n",
    "training_set = DeLTA_data\n",
    "target_size = (192,32)\n",
    "input_size = target_size + (1,)\n",
    "process_size = 4096\n",
    "# Files:\n",
    "\n",
    "models = natsorted(glob(DeLTA_data + '/models/*'))\n",
    "model_file = DeLTA_data + \"/models/saved-model-frac-0.0005.hdf5\"\n",
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e3e54-bd27-4bfb-bedc-7976adcbb2c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_data = pd.DataFrame()\n",
    "for t in range(1):\n",
    "    \n",
    "    \n",
    "    \n",
    "    #inputs_folder = DeLTA_data + 'mother_machine/evaluation/preprocessed/img/'\n",
    "    #outputs_folder = DeLTA_data + 'mother_machine/evaluation/seg_output/'\n",
    "\n",
    "    # Load up model:\n",
    "    model = unet_seg(input_size = input_size)\n",
    "    model.load_weights(model_file)\n",
    "    \n",
    "    data = imread(image_dirs[103])[:1200,:256]#[:,:256,5:37]\n",
    "    X = []\n",
    "    for x in range(len(data)):\n",
    "        X.append(data[x])\n",
    "\n",
    "    requires_resize = True\n",
    "    resize_shape = (192,32) # (320,64) (512,128) (256,64)\n",
    "    if requires_resize:\n",
    "        X = [resize(x,resize_shape, order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in tqdm(X)]\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    cell_data_temp = pd.DataFrame()\n",
    "    all_labels = []\n",
    "    all_imgs = []\n",
    "    for x in tqdm(range(len(X))):\n",
    "        img = normalize(X[x], 1,99.8, axis=(0,1))\n",
    "        masks = model.predict(img.reshape(1,192,32,1)).reshape(192,32)\n",
    "        all_labels.append(masks)\n",
    "        all_imgs.append(img)\n",
    "\n",
    "    cell_data_temp = pd.DataFrame()\n",
    "    properties = [\"area\",\"centroid\",\"major_axis_length\",\"minor_axis_length\",\"label\",\"orientation\"]\n",
    "    for x in range(len(all_labels)):\n",
    "        try:\n",
    "            #border_cleared_nms = clear_border(nms_labels,buffer_size=5).astype(bool)*nms_labels\n",
    "            #all_labels_nms.append(border_cleared_nms)\n",
    "            temp_data = pd.DataFrame(regionprops_table(label((all_labels[x]>0.96).astype(bool)*1),properties = properties))\n",
    "            temp_data = temp_data.sort_values(by = \"centroid-0\").iloc[0]\n",
    "            current_cell_data  = temp_data\n",
    "            current_cell_data[\"time\"] = int(x)\n",
    "            cell_data_temp = cell_data_temp.append(current_cell_data)\n",
    "        except:\n",
    "            pass\n",
    "    cell_data_temp.reset_index(drop=True);\n",
    "    cell_data_temp[\"epoch\"] = t\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot((cell_data_temp[\"major_axis_length\"].reset_index(drop=True)*0.06*2))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    cell_data = cell_data.append(cell_data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1db29-711f-4598-9e2e-0b6c13e74e1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib,numpy\n",
    "import pylab\n",
    "# A random colormap for matplotlib\n",
    "cmap = matplotlib.colors.ListedColormap ( numpy.random.rand ( 256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ffc6b5-bc94-4361-8734-e4ca21b9c8fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in range(len(all_imgs)):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(2,6))\n",
    "    ax1.imshow(all_imgs[x],cmap=\"Greys_r\")\n",
    "    ax2.imshow(label(all_labels[x]>0.8),cmap,interpolation=\"nearest\")\n",
    "    ax1.axis(\"off\")\n",
    "    ax2.axis(\"off\")\n",
    "    plt.savefig(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/one_shot_diag/{}.jpeg\".format(str(x).zfill(4)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f076b83-2a68-4261-9f55-ee215450b133",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(label(all_labels[418]>0.99),cmap,interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f46036-16b4-47a5-8ad2-5b8a0e71d102",
   "metadata": {},
   "source": [
    "## Segmentation of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d9a4c1-f26a-4a54-bdad-b7193cfdebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeLTA_data =  \"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/DeLTA_new_training_data_hist_fourier\"\n",
    "image_dirs = glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/real_data/*.tif\")\n",
    "training_set = DeLTA_data\n",
    "target_size = (256,48)\n",
    "input_size = target_size + (1,)\n",
    "process_size = 4096\n",
    "# Files:\n",
    "\n",
    "models = natsorted(glob(DeLTA_data + '/models/*'))\n",
    "epoch = 70\n",
    "model_file = DeLTA_data + \"/models/new_saved-model-{}.hdf5\".format(str(epoch).zfill(2))\n",
    "model_file\n",
    "t_seg = 1200\n",
    "model = unet_seg(input_size = input_size)\n",
    "model.load_weights(model_file)\n",
    "cell_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91372081-e2e7-4044-80ad-ca0189f937c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    savedir=\"../Segmented_Data_Full_New_Epoch_{}_Exponential_Model_hist_fourier\".format(str(epoch).zfill(2))\n",
    "    os.mkdir(savedir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98eef9f2-8fb5-483b-b3ed-28a2d9f11ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7564beb65984a25846ab76bded44bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t in tqdm(range(len(image_dirs))):\n",
    "    data = imread(image_dirs[t])[:t_seg,:256]#[:,:256,5:37]\n",
    "    X = []\n",
    "    for x in range(len(data)):\n",
    "        X.append(data[x])\n",
    "    requires_resize = True\n",
    "    resize_shape = target_size # (320,64) (512,128) (256,64)\n",
    "    if requires_resize:\n",
    "        X = [resize(x,resize_shape, order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in (X)]\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    cell_data_temp = pd.DataFrame()\n",
    "    all_imgs = []\n",
    "    for x in (range(len(X))):\n",
    "        img = normalize(X[x], 1,99.8, axis=(0,1))\n",
    "        all_imgs.append(img)\n",
    "    all_imgs = np.array(all_imgs)\n",
    "    masks = model.predict(all_imgs.reshape((t_seg,)+target_size+(1,))).reshape((t_seg,)+target_size)\n",
    "    output_data = np.zeros((2,)  +  masks.shape)\n",
    "    for x in range(len(all_imgs)):\n",
    "        output_data[1,x,:,:] = all_imgs[x]\n",
    "    output_data[0,:,:,:] = masks\n",
    "    tifffile.imsave(\"{}/trench_{}.tif\".format(savedir,t),output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca66d2e-9eca-4219-8133-317c0346d3b0",
   "metadata": {},
   "source": [
    "# Segmentation of variable data amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3fecb-c217-4449-901d-db9cf3879f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeLTA_data =  \"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/delta_hist_mid_large/\"\n",
    "image_dirs = glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/real_data/*.tif\")\n",
    "training_set = DeLTA_data\n",
    "target_size = (192,32)\n",
    "input_size = target_size + (1,)\n",
    "process_size = 4096\n",
    "# Files:\n",
    "\n",
    "models = natsorted(glob(DeLTA_data + '/models/*'))\n",
    "model_files = glob(DeLTA_data+\"/models/*frac*\")\n",
    "num_imgs = (np.array([0.005,0.001,0.0005,0.01,0.1,0.2,0.5,0.75,0.9])*2000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca83811-119b-4c69-99d2-f37c4e969ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in num_imgs:\n",
    "    os.mkdir(\"../Variable_Data_Segmentations/{}\".format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fd726-fa13-4930-a8a7-69aa0c174a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_imgs)\n",
    "(model_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af5e2e-c3eb-46f5-8c72-56ac99047989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_seg = 300\n",
    "for nn in tqdm(range(nn,len(num_imgs))):\n",
    "    model = unet_seg(input_size = input_size)\n",
    "    model.load_weights(model_files[nn])\n",
    "    cell_data = pd.DataFrame()\n",
    "\n",
    "    for t in tqdm(range(len(image_dirs))):\n",
    "    #inputs_folder = DeLTA_data + 'mother_machine/evaluation/preprocessed/img/'\n",
    "    #outputs_folder = DeLTA_data + 'mother_machine/evaluation/seg_output/'\n",
    "\n",
    "        # Load up model:\n",
    "\n",
    "\n",
    "        data = imread(image_dirs[t])[:t_seg,:256]#[:,:256,5:37]\n",
    "        X = []\n",
    "        for x in range(len(data)):\n",
    "            X.append(data[x])\n",
    "\n",
    "        requires_resize = True\n",
    "        resize_shape = (192,32) # (320,64) (512,128) (256,64)\n",
    "        if requires_resize:\n",
    "            X = [resize(x,resize_shape, order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in (X)]\n",
    "\n",
    "        n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "        axis_norm = (0,1)   # normalize channels independently\n",
    "        # axis_norm = (0,1,2) # normalize channels jointly\n",
    "        if n_channel > 1:\n",
    "            print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "        cell_data_temp = pd.DataFrame()\n",
    "        all_imgs = []\n",
    "        for x in (range(len(X))):\n",
    "            img = normalize(X[x], 1,99.8, axis=(0,1))\n",
    "            all_imgs.append(img)\n",
    "        all_imgs = np.array(all_imgs)\n",
    "        masks = model.predict(all_imgs.reshape(t_seg,192,32,1)).reshape(t_seg,192,32)\n",
    "        output_data = np.zeros((2,)  +  masks.shape)\n",
    "        for x in range(len(all_imgs)):\n",
    "            output_data[1,x,:,:] = all_imgs[x]\n",
    "        output_data[0,:,:,:] = masks\n",
    "        tifffile.imsave(\"../Variable_Data_Segmentations/{}/trench_{}.tif\".format(num_imgs[nn],t),output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e38a5f-416c-4871-a509-e81c061d812d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/DeLTA_new_training_data_hist_fourier_mixed/convolutions/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1500454/2435392381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mtraining_img_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"convolutions/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mtraining_img_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_img_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mmasks_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"masks/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/DeLTA_new_training_data_hist_fourier_mixed/convolutions/'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "from skimage.measure import label\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import os\n",
    "from skimage.exposure import rescale_intensity\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from csbdeep.utils import Path, normalize\n",
    "from tifffile import imread, imsave\n",
    "import sys\n",
    "#sys.path.insert(0,'../../../../SyMBac')\n",
    "from SyMBac.misc import resize_mask\n",
    "from skimage.measure import label\n",
    "from tqdm.notebook import tqdm\n",
    "def unet_weight_map(y, wc=None, w0 = 10, sigma = 5):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate weight maps as specified in the U-Net paper\n",
    "    for boolean mask.\n",
    "\n",
    "    \"U-Net: Convolutional Networks for Biomedical Image Segmentation\"\n",
    "    https://arxiv.org/pdf/1505.04597.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask: Numpy array\n",
    "        2D array of shape (image_height, image_width) representing binary mask\n",
    "        of objects.\n",
    "    wc: dict\n",
    "        Dictionary of weight classes.\n",
    "    w0: int\n",
    "        Border weight parameter.\n",
    "    sigma: int\n",
    "        Border width parameter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array\n",
    "        Training weights. A 2D array of shape (image_height, image_width).\n",
    "    \"\"\"\n",
    "\n",
    "    labels = label(y)\n",
    "    no_labels = labels == 0\n",
    "    label_ids = sorted(np.unique(labels))[1:]\n",
    "\n",
    "    if len(label_ids) > 1:\n",
    "        distances = np.zeros((y.shape[0], y.shape[1], len(label_ids)))\n",
    "\n",
    "        for i, label_id in enumerate(label_ids):\n",
    "            distances[:,:,i] = distance_transform_edt(labels != label_id)\n",
    "\n",
    "        distances = np.sort(distances, axis=2)\n",
    "        d1 = distances[:,:,0]\n",
    "        d2 = distances[:,:,1]\n",
    "        w = w0 * np.exp(-1/2*((d1 + d2) / sigma)**2) * no_labels\n",
    "    else:\n",
    "        w = np.zeros_like(y)\n",
    "    if wc:\n",
    "        class_weights = np.zeros_like(y)\n",
    "        for k, v in wc.items():\n",
    "            class_weights[y == k] = v\n",
    "        w = w + class_weights\n",
    "    return w\n",
    "\n",
    "base_directory = \"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/DeLTA_new_training_data_hist_fourier_mixed/\"\n",
    "\n",
    "training_img_dir = base_directory + \"convolutions/\"\n",
    "training_img_files = os.listdir(training_img_dir)\n",
    "\n",
    "masks_dir = base_directory + \"masks/\"\n",
    "masks_files = os.listdir(masks_dir)\n",
    "weightmap_dir = base_directory + \"WEIGHTMAPS\"\n",
    "\n",
    "try: \n",
    "    os.mkdir(base_directory + \"preprocessed\")\n",
    "    os.mkdir(base_directory + \"preprocessed/CROPPED_FILTERED\")\n",
    "    os.mkdir(base_directory + \"preprocessed/CROPPED_MASKS\")\n",
    "    os.mkdir(base_directory + \"preprocessed/WEIGHTMAPS\")\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "def crop_and_resize(image_dir, resize_shape):\n",
    "    image = imread(image_dir)\n",
    "    image = resize(image,resize_shape, order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=False, anti_aliasing_sigma=None)\n",
    "    return image\n",
    "    \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85029b9f-653d-4d18-a1f2-6ea859daba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "#from skimage.segmentation import find_boundaries\n",
    "#from skimage.transform import resize\n",
    "#def resize_mask(mask, resize_shape, ret_label):\n",
    "#    \"\"\"\n",
    "#    Resize masks while maintaining their connectivity and values\n",
    "#    \"\"\"\n",
    "#    #labeled_mask = label(mask>0,connectivity=1)\n",
    "#    labeled_mask = mask\n",
    "#    labeled_mask = resize(labeled_mask,resize_shape, order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=False, anti_aliasing_sigma=None).astype(int)\n",
    "#    mask = resize(mask,resize_shape, order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=False, anti_aliasing_sigma=None).astype(int)\n",
    "#    mask_borders = find_boundaries(labeled_mask,mode=\"outer\", connectivity=2)\n",
    "#    labeled_mask = np.where(mask_borders, 0,labeled_mask)\n",
    "#    assert len(np.unique(mask)) == len(np.unique(label(labeled_mask > 0))), \"you joined some masks\"\n",
    "#    if ret_label:\n",
    "#        return labeled_mask\n",
    "#    else:\n",
    "#        return labeled_mask > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70024879-ac85-4b02-81fc-f6e41c574ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658a76bb87c04118951420d40917ffde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f41a8e0b5a74e1abd5a9b7644052e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5331fe2dc95e4affa7ca0a11e34c89fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize_shape = (256,48)\n",
    "\n",
    "for x in tqdm(range(len(training_img_files))):\n",
    "    cropped = crop_and_resize(training_img_dir + training_img_files[x], resize_shape)\n",
    "    cropped = normalize(cropped, 1,99.8, axis=(0,1))\n",
    "    cropped = Image.fromarray(cropped)\n",
    "    cropped.save(base_directory + \"preprocessed/CROPPED_FILTERED/\"+training_img_files[x])\n",
    "    \n",
    "for x in tqdm(range(len(masks_files))):\n",
    "    cropped = crop_and_resize(masks_dir + masks_files[x], resize_shape)\n",
    "    cropped = np.array(cropped).astype(bool)\n",
    "    assert len(np.unique(label(imread(masks_dir + masks_files[x]).astype(bool)))) == len(np.unique(label(cropped)))\n",
    "    imsave(base_directory + \"preprocessed/CROPPED_MASKS/\"+masks_files[x],cropped)\n",
    "    \n",
    "#for x in range(len(masks_files)):\n",
    "#    cropped = resize_mask(imread((masks_dir + masks_files[x])), resize_shape, ret_label=False)\n",
    "#    cropped = np.array(cropped).astype(bool)\n",
    "#    imsave(base_directory + \"preprocessed/CROPPED_MASKS/\"+masks_files[x],cropped)\n",
    "    \n",
    "    \n",
    "wc = {\n",
    "    0: 1, # background\n",
    "    1: 5  # objects\n",
    "}\n",
    "\n",
    "for x in tqdm(range(len(masks_files))):\n",
    "    image = imread(base_directory + \"preprocessed/CROPPED_MASKS/\" + masks_files[x])\n",
    "    w = unet_weight_map(image, wc)\n",
    "    image = w.astype(np.uint8)\n",
    "    imsave(base_directory + \"preprocessed/WEIGHTMAPS/\"+masks_files[x],image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

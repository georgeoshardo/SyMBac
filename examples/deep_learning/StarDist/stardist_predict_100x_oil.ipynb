{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560f8a4-340e-4593-a36c-f5b57d7a4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tifffile import imread, imsave\n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "\n",
    "from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n",
    "from stardist.models import StarDist2D\n",
    "\n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()\n",
    "from ipywidgets import interactive, interact\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.measure import regionprops_table\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "from joblib import delayed, Parallel\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from natsort import natsorted\n",
    "from skimage.segmentation import clear_border, find_boundaries\n",
    "from skimage.morphology import opening, erosion\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e7dab-a522-42ce-b3ff-ec83c413d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/models/bent_noisematched_allsize_empty_und6_unarelu_unlasigmoid_epc2000_exp/\"\n",
    "model = StarDist2D(None, name='stardist_no_shape_completion', basedir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5680db-a1de-44ae-83fa-757afb1e91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dirs = glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/real_data/*.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c837d4-45d7-4919-9ec1-9d20a5c31341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cell_data = pd.DataFrame()\n",
    "properties = [\"area\",\"centroid\",\"major_axis_length\",\"minor_axis_length\",\"label\",\"orientation\"]\n",
    "data = imread(image_dirs[3])[:500,:256,5:37]#[:,:256,5:37]\n",
    "X = []\n",
    "for x in range(len(data)):\n",
    "    X.append(data[x])\n",
    "\n",
    "requires_resize = True\n",
    "resize_shape = (256,64) # (320,64) (512,128) (256,64)\n",
    "if requires_resize:\n",
    "    #X = [resize(x,(80,16), order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in tqdm(X)]\n",
    "    X = [resize(x,resize_shape, order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in tqdm(X)]\n",
    "\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "cell_data_temp = pd.DataFrame()\n",
    "for x in tqdm(range(len(X))):\n",
    "    img = normalize(X[x], 1,99.8, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.5,nms_thresh=0.1)\n",
    "    #labels = resize(labels,(256,32), order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None).astype(int)\n",
    "    #img = resize(img,(256,32), order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None)\n",
    "    #nms_labels, details = model.predict_instances(img, prob_thresh=0.3,nms_thresh=0.3)\n",
    "    border_cleared = clear_border(labels,buffer_size=4).astype(bool)*labels\n",
    "    #border_cleared_nms = clear_border(nms_labels,buffer_size=5).astype(bool)*nms_labels\n",
    "    all_labels.append(border_cleared)\n",
    "    #all_labels_nms.append(border_cleared_nms)\n",
    "    all_imgs.append(img)\n",
    "    current_cell_data  = pd.DataFrame(regionprops_table(border_cleared,properties = properties)).sort_values(by = \"centroid-0\").iloc[0]\n",
    "    current_cell_data[\"time\"] = int(x)\n",
    "    cell_data_temp = cell_data_temp.append(current_cell_data)\n",
    "cell_data_temp[\"trench\"] = t\n",
    "cell_data = cell_data.append(cell_data_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e78eb7-e074-436a-8a24-f70f7267481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35,3))\n",
    "plt.plot(cell_data.reset_index()[\"major_axis_length\"][:600]*0.065*(42/64))\n",
    "plt.ylabel(\"Length (micron)\")\n",
    "plt.xlabel(\"Frame\")\n",
    "##5% val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10d937-414d-44c2-af8a-ce82afc81e66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@interact(x=(0,499))\n",
    "def f(x):\n",
    "    img = normalize(X[x], 1,99.8, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.2,nms_thresh=0.01)\n",
    "    #labels = resize(labels,(256,32), order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None).astype(int)\n",
    "    #img = resize(img,(256,32), order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(img if img.ndim==2 else img[...,0], clim=(0,1), cmap='gray')\n",
    "    plt.imshow(labels, cmap=lbl_cmap, alpha=0.3)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d7e96-1e9d-4b6b-a79a-30c596297e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cell_data = pd.DataFrame()\n",
    "properties = [\"area\",\"centroid\",\"major_axis_length\",\"minor_axis_length\",\"label\",\"orientation\"]\n",
    "for t in range(len(image_dirs)):\n",
    "    data = imread(image_dirs[t])[:500,:256]#[:,:256,5:37]\n",
    "    X = []\n",
    "    for x in range(len(data)):\n",
    "        X.append(data[x])\n",
    "\n",
    "    requires_resize = True\n",
    "    resize_shape = (320,64) # (320,64) (512,128)\n",
    "    if requires_resize:\n",
    "        #X = [resize(x,(80,16), order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in tqdm(X)]\n",
    "        X = [resize(x,resize_shape, order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in tqdm(X)]\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    try:\n",
    "        cell_data_temp = pd.DataFrame()\n",
    "        for x in tqdm(range(len(X))):\n",
    "            img = normalize(X[x], 1,99.8, axis=axis_norm)\n",
    "            labels, details = model.predict_instances(img, prob_thresh=0.5,nms_thresh=0.1)\n",
    "            #labels = resize(labels,(256,32), order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None).astype(int)\n",
    "            #img = resize(img,(256,32), order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None)\n",
    "            #nms_labels, details = model.predict_instances(img, prob_thresh=0.3,nms_thresh=0.3)\n",
    "            border_cleared = clear_border(labels,buffer_size=4).astype(bool)*labels\n",
    "            #border_cleared_nms = clear_border(nms_labels,buffer_size=5).astype(bool)*nms_labels\n",
    "            all_labels.append(border_cleared)\n",
    "            #all_labels_nms.append(border_cleared_nms)\n",
    "            all_imgs.append(img)\n",
    "            current_cell_data  = pd.DataFrame(regionprops_table(border_cleared,properties = properties)).sort_values(by = \"centroid-0\").iloc[0]\n",
    "            current_cell_data[\"time\"] = int(x)\n",
    "            cell_data_temp = cell_data_temp.append(current_cell_data)\n",
    "        cell_data_temp[\"trench\"] = t\n",
    "        cell_data = cell_data.append(cell_data_temp)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f627e4-91b4-4758-afd2-e6e0f41957a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches = cell_data[\"trench\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d37f3-cb79-46bc-9812-41dcac912e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltas = []\n",
    "birth_lengths = []\n",
    "division_lengths = []\n",
    "for trench in trenches:\n",
    "    sawtooth = np.array(cell_data[cell_data[\"trench\"] == trench][\"major_axis_length\"][::3].reset_index(drop=True))\n",
    "    top_peaks = find_peaks(sawtooth, prominence=20,distance=3)[0]\n",
    "    bot_peaks = find_peaks(-sawtooth, prominence=20,distance=3)[0]\n",
    "    #plt.figure(figsize=(24,4))\n",
    "    #plt.plot(sawtooth)\n",
    "    #plt.scatter(top_peaks, sawtooth[top_peaks],c=\"g\")\n",
    "    #plt.scatter(bot_peaks, sawtooth[bot_peaks],c=\"r\")\n",
    "    #plt.show()\n",
    "    peak_pairs = []\n",
    "    if top_peaks[0] - bot_peaks[0] > 0:\n",
    "        for x in range(len(top_peaks)-1):\n",
    "            peak_pairs.append([top_peaks[x+1],bot_peaks[x]])\n",
    "    elif top_peaks[0] - bot_peaks[0] < 0:\n",
    "        for x in range(len(bot_peaks)-1):\n",
    "            peak_pairs.append([top_peaks[x],bot_peaks[x]])\n",
    "    for pair in peak_pairs:\n",
    "        delta = sawtooth[pair[0]] - sawtooth[pair[1]]\n",
    "        deltas.append(delta)\n",
    "    for peak in top_peaks:\n",
    "        division_lengths.append(sawtooth[peak])\n",
    "    for peak in bot_peaks:\n",
    "        birth_lengths.append(sawtooth[peak])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206e3f9-b76e-4a7f-8757-f570cbabc076",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(deltas)*0.065,bins=30)\n",
    "plt.title(\"$\\Delta$, $\\mu$m\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f66bc6-dbfb-4665-9409-f90596d24a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cell_data[\"major_axis_length\"]*0.065,bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9b9a0-a36a-4544-a547-6de362268fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(birth_lengths)*0.065,bins=30)\n",
    "plt.title(\"Birth length, $\\mu$m\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8a529-3f1b-46e2-8c51-6f785f69b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(division_lengths)*0.065,bins=30)\n",
    "plt.title(\"Birth length, $\\mu$m\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b683557-e975-43a2-a456-8a98db7cbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(birth_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f23f1-5864-4215-912a-e0ac5e0b2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(division_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ed86c-0d2b-45c1-8c3f-ef6097b37605",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(birth_lengths,division_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ec8c1-eedc-400c-8dd4-f2989f960992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_labels_nms = []\n",
    "all_imgs = []\n",
    "cell_data = pd.DataFrame()\n",
    "properties = [\"area\",\"centroid\",\"major_axis_length\",\"minor_axis_length\",\"label\",\"orientation\"]\n",
    "for x in tqdm(range(len(X))):\n",
    "    img = normalize(X[x], 1,99.8, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.5,nms_thresh=0.1)\n",
    "    #labels = resize(labels,(256,32), order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None).astype(int)\n",
    "    #img = resize(img,(256,32), order=1, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None)\n",
    "    #nms_labels, details = model.predict_instances(img, prob_thresh=0.3,nms_thresh=0.3)\n",
    "    border_cleared = clear_border(labels,buffer_size=4).astype(bool)*labels\n",
    "    #border_cleared_nms = clear_border(nms_labels,buffer_size=5).astype(bool)*nms_labels\n",
    "    all_labels.append(border_cleared)\n",
    "    #all_labels_nms.append(border_cleared_nms)\n",
    "    all_imgs.append(img)\n",
    "    \n",
    "    cell_data = cell_data.append(pd.DataFrame(regionprops_table(border_cleared,properties = properties)).sort_values(by = \"centroid-0\").iloc[0])\n",
    "cell_data.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814ebb6-e365-43df-8563-074c9d03fe08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_true_mother(x):\n",
    "    all_labels_converted = (all_labels[x].astype(bool) * all_labels_nms[x].astype(bool))*all_labels_nms[x]\n",
    "    for lab in np.unique(all_labels_converted):\n",
    "        if np.sum(all_labels_converted == lab) < 15:\n",
    "            all_labels_converted = np.where(all_labels_converted != lab, all_labels_converted, 0)\n",
    "    mother_cell_data = pd.DataFrame(regionprops_table(all_labels_converted,properties = properties)).sort_values(by = \"centroid-0\").iloc[0]\n",
    "    mother_cell_mask = all_labels_converted == mother_cell_data[\"label\"]\n",
    "    mother_cell_border = find_boundaries(mother_cell_mask,mode=\"outer\")\n",
    "    nms_mask_labels = np.unique(mother_cell_border*(all_labels_nms[x]))\n",
    "    nms_mask_labels = np.setdiff1d(nms_mask_labels,np.unique(all_labels_converted))\n",
    "    nms_mask_labels = nms_mask_labels[nms_mask_labels > 0]\n",
    "    border_nms = (find_boundaries(mother_cell_mask,mode=\"outer\")*all_labels_nms[x])\n",
    "    entire_mother = np.zeros(mother_cell_mask.shape)\n",
    "    entire_mother += mother_cell_mask\n",
    "    for lab in nms_mask_labels:\n",
    "        if np.sum(border_nms == lab) > 30: \n",
    "            entire_mother += (all_labels_nms[x] == lab)\n",
    "    return entire_mother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb02ac-db1a-47a4-8f61-f3fc7c095dc3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mothers = []\n",
    "mother_data = pd.DataFrame()\n",
    "for x in range(len(all_labels_nms)):\n",
    "    true_mother = get_true_mother(x).astype(int)\n",
    "    mothers.append(true_mother)\n",
    "    mother_data = mother_data.append(pd.DataFrame(regionprops_table(true_mother,properties = properties)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496e565-4599-4903-80c5-cdf4743bca42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mother_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e742f59-5e06-4dab-84dd-8c07b87b7d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35,3))\n",
    "plt.plot(mother_data[\"major_axis_length\"][:600]*0.065)\n",
    "plt.ylabel(\"Length (micron)\")\n",
    "plt.xlabel(\"Frame\")\n",
    "##5% val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db11100-ead9-4cb4-836a-5eca36ea2f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35,3))\n",
    "plt.plot(cell_data.reset_index()[\"minor_axis_length\"][:600]*0.065*(42/64))\n",
    "plt.ylabel(\"Length (micron)\")\n",
    "plt.xlabel(\"Frame\")\n",
    "##5% val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f41db-5597-4e9d-94cb-3d53573a7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35,3))\n",
    "plt.plot(cell_data.reset_index()[\"major_axis_length\"][:600]*0.065*(42/64))\n",
    "plt.ylabel(\"Length (micron)\")\n",
    "plt.xlabel(\"Frame\")\n",
    "##5% val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f30f5a-48b3-4cdc-962e-5f2e8d30cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cell_data.reset_index()[\"minor_axis_length\"][:600]*0.065*(42/64),bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8698990-5ae4-4bea-b0c7-05c92b8e0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/cropped_histmatched/masks/*.tif\"))\n",
    "Y = list(map(imread,Y))\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "requires_resize = False\n",
    "resize_shape = (256,32)\n",
    "if requires_resize:\n",
    "    Y = [resize(y,resize_shape, order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None).astype(int) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa14d1-27c4-4e6c-9880-d31d8d2f6186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "syn_mothers = pd.DataFrame()\n",
    "for y in range(len(cell_data)):\n",
    "    syn_mothers = syn_mothers.append(pd.DataFrame(regionprops_table(Y[y],properties = properties)).sort_values(by = \"centroid-0\").iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0afa05-ef6a-43df-9a4f-5276e3435acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_mothers = syn_mothers.reset_index()\n",
    "syn_mothers = syn_mothers[syn_mothers[\"orientation\"] > -0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d8039-a0cb-4683-b1e6-ebd07a908986",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_mothers = syn_mothers[syn_mothers[\"orientation\"] < 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8302f59-abe0-4bdd-acac-b3e963c5b786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(cell_data[\"orientation\"]/(cell_data[\"major_axis_length\"]),bins = 20,alpha=0.4)\n",
    "plt.hist(syn_mothers[\"orientation\"]/syn_mothers[\"major_axis_length\"],bins = 28,alpha=0.4)\n",
    "plt.title(\"Orientation/major_length\")\n",
    "plt.legend([\"Real\",\"Synthetic\"])\n",
    "plt.show()\n",
    "plt.hist(cell_data[\"orientation\"]/(cell_data[\"minor_axis_length\"]),bins = 20,alpha=0.4)\n",
    "plt.hist(syn_mothers[\"orientation\"]/syn_mothers[\"minor_axis_length\"],bins = 28,alpha=0.4)\n",
    "plt.title(\"Orientation/minor_length\")\n",
    "plt.legend([\"Real\",\"Synthetic\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33482781-aabf-4f78-9329-aba98f78368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(syn_mothers[\"orientation\"]/syn_mothers[\"major_axis_length\"],bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3987d66-6c88-454f-a5ec-5236abce0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35,3))\n",
    "plt.plot(cell_data.reset_index()[\"major_axis_length\"][::2][:600]*0.065)\n",
    "plt.ylabel(\"Length (micron)\")\n",
    "plt.xlabel(\"Frame\")\n",
    "##5% val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7816090-2a21-40f3-82f6-14f8ee9a0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb779b-812e-4cf1-ad75-30dbad5090ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234919f8-dc94-44fb-88b2-1e169fe6e442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35,3))\n",
    "plt.plot(cell_data.reset_index()[\"major_axis_length\"][:600]*0.065*(256/128))\n",
    "plt.ylabel(\"Length (micron)\")\n",
    "plt.xlabel(\"Frame\")\n",
    "##5% val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1e52a-0302-48b6-9a4b-23adc1ec89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(x=(0,len(mothers)-1))\n",
    "def f(x):\n",
    "    plt.imshow(mothers[x])\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94e97a-b245-4299-a4de-207bb784dfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in tqdm(range(len(all_labels))):\n",
    "    f, ax = plt.subplots(1,2,figsize=(3,7))\n",
    "    ax[0].imshow(all_imgs[x],cmap=\"Greys_r\")\n",
    "    ax[1].imshow(all_labels[x],cmap=lbl_cmap)\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[0].axis(\"off\")\n",
    "    plt.savefig(model_dir+\"/diagnostics/{}.jpeg\".format(str(x).zfill(4)))\n",
    "    plt.tight_layout()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8bffc-3d31-4584-bb64-2d5378fecd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a195c06-c5e8-4500-9caf-183c3dac319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_data = np.array(cell_data.reset_index()[\"major_axis_length\"])\n",
    "fig,ax = plt.subplots(figsize=(35,3))\n",
    "ax.plot(np.diff(np.log2(growth_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5ac25-dae4-42e4-bd52-44324e73070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rates = np.diff(np.log2(growth_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce2e2d-7996-468e-ad68-45bc81fd6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d464e-41a3-4917-a8b0-740fedd24881",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(35,3))\n",
    "plt.plot(moving_average(np.where((growth_rates > 0) & (growth_rates < 0.1), growth_rates, 0),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb7b11-19d9-4d9f-be80-a4d841a3eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(35,3))\n",
    "ax.plot(cell_data.reset_index()[\"minor_axis_length\"][:]*0.065*(42/64),alpha=0.6)\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(cell_data.reset_index()[\"major_axis_length\"][::2]*0.065,c=\"r\",alpha=0.6)\n",
    "ax.set_ylabel(\"Width (micron)\")\n",
    "ax2.set_ylabel(\"Length (micron)\")\n",
    "#plt.savefig(\"/home/georgeos/testtwin3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505bbe3-c7fb-4894-945b-f6b8d88a6617",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cell_data.reset_index()[\"minor_axis_length\"][:]*0.065*(42/64),cell_data.reset_index()[\"major_axis_length\"][:]*0.065)\n",
    "plt.ylabel(\"Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f5f034-e645-4b44-9ef4-fc9ff8eda782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "rs = np.random.RandomState(11)\n",
    "x = cell_data.reset_index()[\"minor_axis_length\"][:]*0.065*(42/64)\n",
    "y = cell_data.reset_index()[\"major_axis_length\"][:]*0.065\n",
    "\n",
    "sns.jointplot(x=x, y=y, color=\"#4CB391\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd2ee4-4722-47bc-9eba-e78678c6ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(np.convolve(x, np.ones(15)/15, mode='valid')-x[7:-7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b48bb2-49f8-43f9-9f99-78c3284ada48",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(np.convolve(x, np.ones(15)/15, mode='valid')-x[7:-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267ae53-6ebb-423d-8bca-0553b8f9f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,1))\n",
    "plt.plot(cell_data.reset_index()[\"minor_axis_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cb264-b6da-4eaa-b15c-ee4e70ec6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/predictions_0.2\"\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(output_dir+\"/masks_resized/\")\n",
    "    os.mkdir(output_dir+\"/images_resized/\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(output_dir+\"/diagnostics/\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(output_dir+\"/postprocessed/\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e362c-99cc-4c2a-8083-03e9c9a5de54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_details = []\n",
    "for z in tqdm(range(len(X))):\n",
    "    img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.2, nms_thresh=0.01)\n",
    "    imsave(\n",
    "        output_dir+\"/masks_resized/{}\".format(names[z]),labels)\n",
    "    imsave(\n",
    "        output_dir+\"/images_resized/{}\".format(names[z]),img)\n",
    "    all_labels.append(labels)\n",
    "    all_details.append(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526550f-3b56-4497-90a4-c4e28b9c8fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "for trench in tqdm(trench_names):\n",
    "    idxs = trenches_idx[trench]\n",
    "    for z in (idxs):\n",
    "        cleared_mask = clear_side_masks(all_labels[z],a)\n",
    "        imsave(output_dir+\"/postprocessed/{}\".format(names[z]),cleared_mask)\n",
    "    a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ac80e-63c5-4c5e-99e6-1a050f57f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/predictions_0.2/postprocessed/*\"))\n",
    "lbls = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/predictions_0.2/postprocessed/*\"))\n",
    "\n",
    "\n",
    "def plotter(z): \n",
    "    labels = all_labels[z]\n",
    "    details = all_details[z]\n",
    "    img = X[z]\n",
    "    probmap = np.zeros(labels.shape)\n",
    "    for x in range(len(details[\"points\"])):\n",
    "        probmap[np.where(labels == labels[details[\"points\"][x][0],details[\"points\"][x][1]])] = details[\"prob\"][x]\n",
    "    f, ax = plt.subplots(1,5,figsize=(7.9,4))\n",
    "    ax[0].imshow(img,cmap=\"Greys_r\")\n",
    "    ax[1].imshow(labels,cmap=lbl_cmap)\n",
    "    prob = ax[3].imshow(probmap,cmap=\"afmhot\",vmin=0,vmax=1)\n",
    "    ax[2].imshow(img,cmap=\"Greys_r\")\n",
    "    ax[2].imshow(labels,cmap=lbl_cmap,alpha=0.45)\n",
    "    ax[2].set_title(\"PC+Masks\")\n",
    "    f.colorbar(prob,ax=ax[3])\n",
    "    ax[3].set_title(\"P(Mask)\")\n",
    "    ax[1].set_title(\"Masks\")\n",
    "    ax[0].set_title(\"PC_image\")\n",
    "    ax[4].imshow(imread(pp[z]),cmap=lbl_cmap)\n",
    "    ax[4].set_title(\"Post-proc\")\n",
    "    for axs in ax:\n",
    "        axs.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir+\"/diagnostics/{}\".format(names[z][:-3]+\"jpeg\"),dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195377ef-4acc-405f-b41b-d396d4e09520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=1)(delayed(plotter)(i) for i in tqdm(range(len(all_labels)))) #plotter is leaking memory, use n_jobs = 1 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00faf868-152f-4f2f-b213-6493d719f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/predictions_0.1\"\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(output_dir+\"/masks_resized/\")\n",
    "    os.mkdir(output_dir+\"/images_resized/\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(output_dir+\"/diagnostics/\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(output_dir+\"/postprocessed/\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04716fa-0a14-4b99-a205-89543b8e5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_details = []\n",
    "for z in tqdm(range(len(X))):\n",
    "    img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.1, nms_thresh=0.01)\n",
    "    imsave(\n",
    "        output_dir+\"/masks_resized/{}\".format(names[z]),labels)\n",
    "    imsave(\n",
    "        output_dir+\"/images_resized/{}\".format(names[z]),img)\n",
    "    all_labels.append(labels)\n",
    "    all_details.append(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead60e6-63ab-44e1-bbe6-47d86a0679e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for trench in tqdm(trench_names):\n",
    "    idxs = trenches_idx[trench]\n",
    "    for z in (idxs):\n",
    "        cleared_mask = clear_side_masks(all_labels[z],a)\n",
    "        imsave(output_dir+\"/postprocessed/{}\".format(names[z]),cleared_mask)\n",
    "    a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aecbeab-cf59-48ad-b515-7901cbd53b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/predictions_0.1/postprocessed/*\"))\n",
    "\n",
    "def plotter(z): \n",
    "    labels = all_labels[z]\n",
    "    details = all_details[z]\n",
    "    img = X[z]\n",
    "    probmap = np.zeros(labels.shape)\n",
    "    for x in range(len(details[\"points\"])):\n",
    "        probmap[np.where(labels == labels[details[\"points\"][x][0],details[\"points\"][x][1]])] = details[\"prob\"][x]\n",
    "    f, ax = plt.subplots(1,5,figsize=(7.9,4))\n",
    "    ax[0].imshow(img,cmap=\"Greys_r\")\n",
    "    ax[1].imshow(labels,cmap=lbl_cmap)\n",
    "    prob = ax[3].imshow(probmap,cmap=\"afmhot\",vmin=0,vmax=1)\n",
    "    ax[2].imshow(img,cmap=\"Greys_r\")\n",
    "    ax[2].imshow(labels,cmap=lbl_cmap,alpha=0.45)\n",
    "    ax[2].set_title(\"PC+Masks\")\n",
    "    f.colorbar(prob,ax=ax[3])\n",
    "    ax[3].set_title(\"P(Mask)\")\n",
    "    ax[1].set_title(\"Masks\")\n",
    "    ax[0].set_title(\"PC_image\")\n",
    "    ax[4].imshow(imread(pp[z]),cmap=lbl_cmap)\n",
    "    ax[4].set_title(\"Post-proc\")\n",
    "    for axs in ax:\n",
    "        axs.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir+\"/diagnostics/{}\".format(names[z][:-3]+\"jpeg\"),dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517a413-9137-4413-b14c-597308f6166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=1)(delayed(plotter)(i) for i in tqdm(range(len(all_labels)))) #plotter is leaking memory, use n_jobs = 1 for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4fa81-8eb2-4ded-9a18-e7f3459fc245",
   "metadata": {},
   "source": [
    "## playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4f91b-1cfb-45af-922c-ddd15f578bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_1 = []\n",
    "all_details_1 = []\n",
    "all_imgs_1 = []\n",
    "for z in range(len(X)):\n",
    "    img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.7, nms_thresh=0.1)\n",
    "    all_labels_1.append(labels)\n",
    "    all_details_1.append(details)\n",
    "    all_imgs_1.append(img)\n",
    "\n",
    "@interact\n",
    "def plotter_1(x=(0,len(X)-1)):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(all_imgs_1[x] if all_imgs_1[x].ndim==2 else all_imgs_1[x][...,0], clim=(0,1), cmap='gray')\n",
    "    plt.imshow(all_labels_1[x], cmap=lbl_cmap, alpha=0.35)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffd617-4a86-4886-b0c7-ab5019ba2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resize(all_imgs_1[0],(211,40), order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None),cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b4601c-f857-4d15-aea3-72199cf49f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from skimage.segmentation import clear_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9581e7-b2d7-4d55-ac63-1a35659fa4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties = [\"area\",\"centroid\",\"major_axis_length\",\"minor_axis_length\"]\n",
    "\n",
    "trenches = os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/\")\n",
    "trenches.sort()\n",
    "model = StarDist2D(None, name='stardist_no_shape_completion', basedir='models_mixed_size_1600_epoch_good_50')\n",
    "all_cell_data = pd.DataFrame()\n",
    "master_label = []\n",
    "master_imgs = []\n",
    "exception_trenches = [\"trench_52\", \"trench_54\"]\n",
    "for trench in tqdm(trenches):\n",
    "    cell_data = pd.DataFrame()\n",
    "\n",
    "    X = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/{}/*.tif\".format(trench)))\n",
    "    X = list(map(imread,X))\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "\n",
    "\n",
    "    all_labels = []\n",
    "    all_details = []\n",
    "    all_imgs = []\n",
    "    for z in range(3,25):\n",
    "        img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "        if z == 3:\n",
    "            if trench in exception_trenches:\n",
    "                midpoint = int(img.shape[1]/2)\n",
    "            else:\n",
    "                image_profile = img.mean(axis=0)\n",
    "                peaks = find_peaks(image_profile, height=np.mean(image_profile)*0.9)\n",
    "                if len(peaks[0]) > 1:\n",
    "                    midpoint = int(np.sum(peaks[0])/2)\n",
    "                elif len(peaks[0]) == 1:\n",
    "                    midpoint = peaks[0][0]\n",
    "                trench_half_width = 15\n",
    "        \n",
    "        labels, details = model.predict_instances(img, prob_thresh=0.7, nms_thresh=0.1)\n",
    "        \n",
    "\n",
    "        labels = clear_border(labels[:,midpoint-trench_half_width:midpoint+trench_half_width])\n",
    "        \n",
    "        \n",
    "        all_labels.append(labels)\n",
    "        all_details.append(details)\n",
    "        all_imgs.append(img[:,midpoint-trench_half_width:midpoint+trench_half_width])\n",
    "        \n",
    "    for label_image in all_labels:\n",
    "        if len(np.unique(label_image)) > 1:\n",
    "            cell_data = cell_data.append(pd.DataFrame(regionprops_table(label_image=label_image, properties=properties)).sort_values(by = \"centroid-0\").iloc[0])\n",
    "        else:\n",
    "            cell_data = cell_data.append(pd.Series([np.nan]*len(properties)),ignore_index=True)\n",
    "    cell_data.reset_index(inplace=True,drop=True)\n",
    "    cell_data[\"cell\"] = trench\n",
    "    cell_data[\"time\"] = range(3,25)\n",
    "    all_cell_data = all_cell_data.append(cell_data)\n",
    "    all_cell_data.reset_index(inplace=True,drop=True)\n",
    "    master_label.append(all_labels)\n",
    "    master_imgs.append(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866724e-7b82-49dd-bfd1-3bc43d6e876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(all_cell_data, col='cell', col_wrap=7)\n",
    "g = g.map(sns.lineplot, 'time', 'major_axis_length', ci=None).add_legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_1600_epoch_50perc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a2cc8-80c8-44e9-a22c-7fa1bfbcf73f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in range(len(master_imgs[0])):\n",
    "    plt.imshow(master_imgs[54][x],cmap=\"Greys_r\")\n",
    "    plt.imshow(master_label[54][x],alpha=0.4,cmap=\"jet\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b4319-ab7a-4aa7-8b5f-653138b43107",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    fig, ax = plt.subplots(7,8, figsize=(16,16))\n",
    "    for i,(a,x) in enumerate(zip(ax.flat, X)):\n",
    "        a.imshow(x if x.ndim==2 else x[...,0], cmap='gray')\n",
    "        a.set_title(i)\n",
    "    [a.axis('off') for a in ax.flat]\n",
    "    plt.tight_layout()\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fafb1f-a4e8-43ec-995f-002719e4f004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_details = []\n",
    "all_imgs = []\n",
    "for z in range(25):\n",
    "    img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.6, nms_thresh=0.1)\n",
    "    all_labels.append(labels)\n",
    "    all_details.append(details)\n",
    "    all_imgs.append(img)\n",
    "    \n",
    "@interact\n",
    "def plotter(x=(0,len(X)-1)):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(all_imgs[x] if all_imgs[x].ndim==2 else all_imgs[x][...,0], clim=(0,1), cmap='gray')\n",
    "    plt.imshow(all_labels[x], cmap=lbl_cmap, alpha=0.35)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df294ba3-8746-4491-aad1-03afe0e12cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops, regionprops_table\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836a5af-c33a-4f60-9115-9d323aa2c6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073ae48-fa60-49db-b630-26a833014301",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches = os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e528a-d540-4802-9ef5-371ed5a5c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for t in range(len(trench))\n",
    "cell_data = pd.DataFrame()\n",
    "for label_image in all_labels:\n",
    "    cell_data = cell_data.append(pd.DataFrame(regionprops_table(label_image=label_image, properties=properties)).sort_values(by = \"centroid-0\").iloc[0])\n",
    "cell_data.reset_index(inplace=True,drop=True)\n",
    "cell_data[\"cell\"] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dffc0d-ea88-4df7-aa9e-1ef3d6126e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b73792-b54d-4730-9a0c-0bd7fc510d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = StarDist2D(None, name='stardist_no_shape_completion', basedir='models_nohist')\n",
    "\n",
    "trenches = os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/\")\n",
    "all_cell_data = pd.DataFrame()\n",
    "for trench in trenches:\n",
    "    cell_data = pd.DataFrame()\n",
    "\n",
    "    X = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/{}/*.tif\".format(trench)))\n",
    "    X = list(map(imread,X))\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "\n",
    "\n",
    "    all_labels = []\n",
    "    all_details = []\n",
    "    all_imgs = []\n",
    "    for z in range(0,25):\n",
    "        img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "        labels, details = model.predict_instances(img, prob_thresh=0.7, nms_thresh=0.1)\n",
    "        all_labels.append(labels)\n",
    "        all_details.append(details)\n",
    "        all_imgs.append(img)\n",
    "        \n",
    "    for label_image in all_labels:\n",
    "        cell_data = cell_data.append(pd.DataFrame(regionprops_table(label_image=label_image, properties=properties)).sort_values(by = \"centroid-0\").iloc[0])\n",
    "    cell_data.reset_index(inplace=True,drop=True)\n",
    "    cell_data[\"cell\"] = trench\n",
    "    cell_data[\"time\"] = range(0,25)\n",
    "    all_cell_data = all_cell_data.append(cell_data)\n",
    "    all_cell_data.reset_index(inplace=True,drop=True)\n",
    "    print(trench)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2390f5-9304-4bfe-af8f-3a24cf417cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_data[\"minor_axis_length\"] = (all_cell_data[\"minor_axis_length\"])*2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f238e22-2247-473f-adca-efab3a778339",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_data_temp = pd.melt(all_cell_data,value_vars=[\"major_axis_length\",\"minor_axis_length\"],id_vars =[\"centroid-0\",\"centroid-1\",\"cell\",\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae900e4-0f98-444c-9457-574915b530dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(all_cell_data_temp, col='cell', hue=\"variable\",col_wrap=7)\n",
    "g = g.map(sns.lineplot, 'time', \"value\", ci=None).add_legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_nohist.pdf\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a9e64-423f-4af0-8372-ccc3d658642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist2D(None, name='stardist_no_shape_completion', basedir='models')\n",
    "\n",
    "trenches = os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/\")\n",
    "all_cell_data = pd.DataFrame()\n",
    "for trench in trenches:\n",
    "    cell_data = pd.DataFrame()\n",
    "\n",
    "    X = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/{}/*.tif\".format(trench)))\n",
    "    X = list(map(imread,X))\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "\n",
    "\n",
    "    all_labels = []\n",
    "    all_details = []\n",
    "    all_imgs = []\n",
    "    for z in range(0,25):\n",
    "        img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "        labels, details = model.predict_instances(img, prob_thresh=0.65, nms_thresh=0.1)\n",
    "        all_labels.append(labels)\n",
    "        all_details.append(details)\n",
    "        all_imgs.append(img)\n",
    "        \n",
    "    for label_image in all_labels:\n",
    "        cell_data = cell_data.append(pd.DataFrame(regionprops_table(label_image=label_image, properties=properties)).sort_values(by = \"centroid-0\").iloc[0])\n",
    "    cell_data.reset_index(inplace=True,drop=True)\n",
    "    cell_data[\"cell\"] = trench\n",
    "    cell_data[\"time\"] = range(0,25)\n",
    "    all_cell_data = all_cell_data.append(cell_data)\n",
    "    all_cell_data.reset_index(inplace=True,drop=True)\n",
    "    print(trench)\n",
    "g = sns.FacetGrid(all_cell_data, col='cell', col_wrap=7)\n",
    "g = g.map(sns.lineplot, 'time', 'major_axis_length', ci=None).add_legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_mixed_cells.png\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e5219-ad98-4ecb-a490-e3429a870296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels_1 = []\n",
    "all_details_1 = []\n",
    "all_imgs_1 = []\n",
    "for z in range(25):\n",
    "    img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.6, nms_thresh=0.1)\n",
    "    all_labels_1.append(labels)\n",
    "    all_details_1.append(details)\n",
    "    all_imgs_1.append(img)\n",
    "    \n",
    "@interact\n",
    "def plotter_1(x=(0,len(X)-1)):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(all_imgs_1[x] if all_imgs[x].ndim==2 else all_imgs_1[x][...,0], clim=(0,1), cmap='gray')\n",
    "    plt.imshow(all_labels_1[x], cmap=lbl_cmap, alpha=0.35)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22323d-e51d-4179-b405-374460ec135a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

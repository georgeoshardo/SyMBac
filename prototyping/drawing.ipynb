{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extreme-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "import raster_geometry as rg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rotate\n",
    "import pickle\n",
    "import sys\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "sys.path.insert(0,'/home/georgeos/Documents/GitHub/SYMPTOMM2')\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "from skimage.morphology import opening\n",
    "from PIL import Image       \n",
    "import pymunk\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "from skimage import data\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage import draw\n",
    "#import napari\n",
    "from itertools import combinations\n",
    "from SYMPTOMM import PSF\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from cupyx.scipy.ndimage import convolve as cuconvolve\n",
    "import tifffile\n",
    "from skimage.exposure import match_histograms\n",
    "import cupy as cp\n",
    "from scipy.optimize import dual_annealing, shgo\n",
    "from skimage.transform import resize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.optimize import basinhopping\n",
    "import image_similarity_measures\n",
    "from image_similarity_measures.quality_metrics import rmse, psnr, fsim, issm, sre, sam, uiq\n",
    "from SYMPTOMM.general_drawing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enclosed-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/output_pickles/cell_timeseries_short_trench.p\", \"rb\") as f:\n",
    "    cell_timeseries = pickle.load(f)\n",
    "with open(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/output_pickles/space_timeseries_short_trench.p\", \"rb\") as f:\n",
    "    space = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "residential-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=14)(delayed(gen_cell_props_for_draw)(a, ID_props) for a in cell_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "owned-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_transformation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-howard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/399 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▎         | 14/399 [00:00<00:04, 87.51it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "scenes = Parallel(n_jobs=14)(delayed(draw_scene)(cell_properties, False) for cell_properties in tqdm(cell_timeseries_properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/training_data/OPL_renders\"\n",
    "_ = Parallel(n_jobs=10)(delayed(scene_plotter)(scenes[x][1],output_dir,\"OPL_mask\",x+4000,matplotlib_draw=False) for x in range(len(scenes)))\n",
    "_ = Parallel(n_jobs=10)(delayed(scene_plotter)(scenes[x][0],output_dir,\"OPL_intensity\",x+4000,matplotlib_draw=False) for x in range(len(scenes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-kitchen",
   "metadata": {},
   "source": [
    "# Phase Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "##From here, prototyping phase contrast\n",
    "def get_trench_segments(space):\n",
    "    trench_shapes = []\n",
    "    for shape, body in zip(space.shapes, space.bodies):\n",
    "        if body.body_type == 2:\n",
    "            trench_shapes.append(shape)\n",
    "    return trench_shapes\n",
    "\n",
    "trench_segment_props = []\n",
    "for x in get_trench_segments(space):\n",
    "    trench_segment_props.append([x.bb,x.area, x.a, x.b])\n",
    "    \n",
    "trench_segment_props = pd.DataFrame(trench_segment_props)\n",
    "trench_segment_props.columns = [\"bb\", \"area\", \"a\", \"b\"]\n",
    "main_segments = trench_segment_props.sort_values(\"area\",ascending=False).iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_segments = main_segments.reindex(index=main_segments.index[::-1]) # run if you get a zero-width image output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 50\n",
    "\n",
    "trench_multiplier = 30\n",
    "cell_multiplier = 2\n",
    "background_multiplier = 10\n",
    "grid_def = [range(15,trench_multiplier), np.arange(0.1,cell_multiplier,0.1), range(background_multiplier)]\n",
    "grid = list(itertools.product(*grid_def))\n",
    "def generate_PC_OPL(trench_multiplier,cell_multiplier,background_multiplier):\n",
    "    segment_1_top_left = (0 + offset, int(main_segments.iloc[0][\"bb\"][0] + offset))\n",
    "    segment_1_bottom_right = (int(main_segments.iloc[0][\"bb\"][3] + offset), int(main_segments.iloc[0][\"bb\"][2] + offset))\n",
    "\n",
    "    segment_2_top_left = (0 + offset, int(main_segments.iloc[1][\"bb\"][0] + offset))\n",
    "    segment_2_bottom_right = (int(main_segments.iloc[1][\"bb\"][3] + offset), int(main_segments.iloc[1][\"bb\"][2] + offset))\n",
    "\n",
    "    test_scene = np.zeros(scenes[300][0].shape) + background_multiplier\n",
    "    rr, cc = draw.rectangle(start = segment_1_top_left, end = segment_1_bottom_right, shape = test_scene.shape)\n",
    "    test_scene[rr,cc] = 1 * trench_multiplier\n",
    "    rr, cc = draw.rectangle(start = segment_2_top_left, end = segment_2_bottom_right, shape = test_scene.shape)\n",
    "    test_scene[rr,cc] = 1 * trench_multiplier\n",
    "\n",
    "    circ_midpoint_y = (segment_1_top_left[1] + segment_2_bottom_right[1])/2\n",
    "    radius = (segment_1_top_left[1] - offset - (segment_2_bottom_right[1] - offset))/2\n",
    "    circ_midpoint_x = (offset) + radius\n",
    "\n",
    "    rr, cc = draw.rectangle(start = segment_2_top_left, end = (circ_midpoint_x,80+segment_1_top_left[1] - offset), shape = test_scene.shape)\n",
    "    test_scene[rr.astype(int),cc.astype(int)] = 1 * trench_multiplier\n",
    "\n",
    "    rr, cc = draw.disk(center = (circ_midpoint_x, circ_midpoint_y), radius = radius, shape = test_scene.shape)\n",
    "    rr_semi = rr[rr < (circ_midpoint_x + 1)]\n",
    "    cc_semi = cc[rr < (circ_midpoint_x + 1)]\n",
    "    test_scene[rr_semi,cc_semi] = background_multiplier\n",
    "    test_scene += scenes[np.random.randint(len(scenes))][0] * cell_multiplier\n",
    "    test_scene = test_scene[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "\n",
    "    expanded_scene = np.zeros((int(test_scene.shape[0]*1.2), test_scene.shape[1]*2)) + trench_multiplier\n",
    "    expanded_scene[expanded_scene.shape[0] - test_scene.shape[0]:,int(test_scene.shape[1]/2):int(test_scene.shape[1]/2) + test_scene.shape[1]] = test_scene\n",
    "    return expanded_scene\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(generate_PC_OPL(30,1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PC_OPLs = np.array([generate_PC_OPL(*k) for k in grid])\n",
    "#viewer = napari.view_image(np.array(PC_OPLs), rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_phase = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(56)).zfill(2),\n",
    "    str(np.random.randint(20,25)).zfill(3)\n",
    "))\n",
    "plt.imshow(real_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_2D(size, σ):\n",
    "    x = np.linspace(0,size,size)\n",
    "    μ = np.mean(x)\n",
    "    A = 1/(σ*np.sqrt(2*np.pi))\n",
    "    B = np.exp(-1/2 * (x-μ)**2/(σ**2))\n",
    "    _gaussian_1D = A*B\n",
    "    _gaussian_2D = np.outer(_gaussian_1D,_gaussian_1D)\n",
    "    return _gaussian_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensers = {\n",
    "    \"Ph1\": (0.45, 3.75, 24),\n",
    "    \"Ph2\": (0.8, 5.0, 24),\n",
    "    \"Ph3\": (1.0, 9.5, 24),\n",
    "    \"Ph4\": (1.5, 14.0, 24),\n",
    "    \"PhF\": (1.5, 19.0, 25)\n",
    "} #W, R, Diameter\n",
    "\n",
    "from scipy.special import jv, jve\n",
    "\n",
    "\n",
    "def somb(x):\n",
    "    z = np.zeros(x.shape)\n",
    "    x = np.abs(x)\n",
    "    idx = np.nonzero(x)\n",
    "    z[idx] = 2*jv(1,np.pi*x[idx])/(np.pi*x[idx])\n",
    "    return z\n",
    "\n",
    "def get_phase_contrast_kernel(R,W,radius,scale,F,sigma):\n",
    "    scale1 = 1000 # micron per millimeter\n",
    "    F = F * scale1 # to microm\n",
    "    Lambda = 0.55 # in micron % wavelength of light\n",
    "    R = R * scale1 # to microm\n",
    "    W = W * scale1 # to microm\n",
    "    #The corresponding point spread kernel function for the negative phase contrast \n",
    "\n",
    "    meshgrid_arrange = np.arange(-radius,radius + 1,1)\n",
    "    [xx,yy] = np.meshgrid(meshgrid_arrange,meshgrid_arrange)\n",
    "    rr = np.sqrt(xx**2 + yy**2)*scale\n",
    "    rr_dl = rr*(1/F)*(1/Lambda); # scaling with F and Lambda for dimension correction\n",
    "    kernel1 = np.pi*R**2*somb(2*R*rr_dl);     \n",
    "    kernel2 = np.pi*(R-W)**2*somb(2*(R-W)*rr_dl)\n",
    "\n",
    "\n",
    "    kernel = kernel1 - 0*kernel2\n",
    "    kernel = kernel/np.max(kernel)\n",
    "    kernel[radius,radius] = kernel[radius,radius] + 1\n",
    "    kernel = -kernel/np.sum(kernel)\n",
    "    gaussian = gaussian_2D(radius*2+1, sigma)\n",
    "    kernel = kernel * gaussian\n",
    "    return kernel\n",
    "\n",
    "\n",
    "W, R, diameter = condensers[\"Ph2\"]\n",
    "scale = 0.108379937 / 3 #0.35 #micron per pixel\n",
    "min_sigma = 0.42*0.6/2 / scale # micron\n",
    "kernel= get_phase_contrast_kernel(R, W, 50, scale, 5, 15)\n",
    "scalebar = ScaleBar(scale, 'um')\n",
    "plt.figure(figsize=(5.1,5.1))\n",
    "plt.gca().add_artist(scalebar)\n",
    "plt.imshow(kernel,cmap=\"Greys_r\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Phase Contrast\")\n",
    "plt.show()\n",
    "kernel = cp.array(kernel)\n",
    "kernel_np = kernel.get()\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(np.arange(-50,51)*scale,kernel_np[50,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "output = cuconvolve(cp.array(PC_OPLs[2000]),kernel)\n",
    "output = output.get()\n",
    "output = rescale(output, 1/4, anti_aliasing=False)[3:182,3:-3]\n",
    "output = random_noise(output, mode=\"gaussian\", mean=5,var=0.0000051,clip=False)\n",
    "#viewer = napari.view_image(output_rescaled, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_segment = output\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(top_segment,cmap=\"Greys_r\")\n",
    "top_segment.shape += (1,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_intersection_between_image_hists(img1, img2, bins):\n",
    "    hist_1, _ = np.histogram(img1.flatten()/img1.flatten().max(), bins=bins)\n",
    "    hist_2, _ = np.histogram(img2.flatten()/img2.flatten().max(), bins=bins)\n",
    "    minima = np.minimum(hist_1, hist_2)\n",
    "    intersection = np.true_divide(np.sum(minima), np.sum(hist_2))\n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_rescale(image,kernel):\n",
    "    output = cuconvolve(cp.array(image),cp.array(kernel))\n",
    "    output = output.get()\n",
    "    output = rescale(output, 1/4, anti_aliasing=False)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(z, ret_tuple = False):\n",
    "    real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(20,25)).zfill(3)\n",
    "))\n",
    "    real_image = real_image.astype(np.float64)/np.max(real_image)\n",
    "    σ, trench_multiplier, cell_multiplier, background_multiplier = z\n",
    "    expanded_scene = generate_PC_OPL(trench_multiplier,cell_multiplier,background_multiplier)\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, σ)\n",
    "    convolved_image = convolve_rescale(expanded_scene,kernel)[0:182,3:-3]\n",
    "    #convolved_image = random_noise(convolved_image, mode=\"gaussian\", mean=5,var=σ2,clip=False)\n",
    "    convolved_image = match_histograms(convolved_image, real_image, multichannel=False)\n",
    "    convolved_image = resize(convolved_image,real_image.shape,clip=False,preserve_range=False,anti_aliasing=None)\n",
    "    convolved_image = convolved_image/np.max(convolved_image)\n",
    "    ssim_real = ssim(convolved_image, real_image)\n",
    "    intersection = return_intersection_between_image_hists(convolved_image, real_image, 100)\n",
    "    #sims \n",
    "    convolved_image.shape += (1,)\n",
    "    real_image.shape += (1,)\n",
    "    _fsim = fsim(convolved_image,real_image)\n",
    "    _issm = issm(convolved_image,real_image)\n",
    "    _sam = sam(convolved_image,real_image)\n",
    "    _sre = sre(convolved_image,real_image)\n",
    "    objs = [ssim_real, 0.5*intersection, _fsim, _issm, _sam, _sre/20]\n",
    "    if ret_tuple == False:\n",
    "        return -np.linalg.norm(objs)\n",
    "    else:\n",
    "        return objs\n",
    "\n",
    "progress = []\n",
    "def callbackF(x, f, context):\n",
    "    print(x)\n",
    "    progress.append(x)\n",
    "    \n",
    "def callbackSHGo(x):\n",
    "    print(x)\n",
    "    progress.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = list(zip([min_sigma, 1.0, 0.2, 1], [20.0, 30.0, 5.0, 20.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = shgo(objective_function, bounds = np.array(bounds),callback=callbackSHGo,options={\"minimize_every_iter\":True})\n",
    "ret = dual_annealing(objective_function, bounds = np.array(bounds),callback=callbackF,maxiter=1000,initial_temp=5*10**4,x0=ret.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.callbacks import VerboseCallback\n",
    "res = gp_minimize(objective_function,                  # the function to minimize\n",
    "                  bounds,      # the bounds on each dimension of x\n",
    "                  acq_func=\"gp_hedge\",      # the acquisition function\n",
    "                  n_calls=50,         # the number of evaluations of f\n",
    "                  n_random_starts=5,  # the number of random initialization points\n",
    "                 n_jobs = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_get_image(z):\n",
    "    σ, trench_multiplier, cell_multiplier, background_multiplier, = z\n",
    "    expanded_scene = generate_PC_OPL(trench_multiplier,cell_multiplier,background_multiplier)\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, σ)\n",
    "    convolved_image = convolve_rescale(expanded_scene,kernel)[0:182,10:-10]\n",
    "    #convolved_image = random_noise(convolved_image, mode=\"gaussian\", mean=5,var=σ2,clip=False)\n",
    "    convolved_image = match_histograms(convolved_image, real_image, multichannel=False)\n",
    "    convolved_image = resize(convolved_image,real_image.shape,clip=False,preserve_range=False,anti_aliasing=None)\n",
    "    convolved_image = convolved_image/np.max(convolved_image)\n",
    "    ssim_real = ssim(convolved_image, real_image)\n",
    "    intersection = return_intersection_between_image_hists(convolved_image, real_image, 100)\n",
    "    return convolved_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(1,25)).zfill(3)\n",
    "))\n",
    "optimised_image = objective_function_get_image(ret.x)\n",
    "noisy_image = random_noise(optimised_image, mode=\"gaussian\", mean=5,var=0.0002,clip=False)\n",
    "viewer = napari.view_image(noisy_image, rgb=False)\n",
    "\n",
    "\n",
    "\n",
    "viewer = napari.view_image(real_image, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_outputs = []\n",
    "for x in range(len(PC_OPLs)):\n",
    "    output = cuconvolve(cp.array(PC_OPLs[x]),kernel)\n",
    "    output = output.get()\n",
    "    output = rescale(output, 1/1.75, anti_aliasing=False)[:364,:]\n",
    "    output = random_noise(output, mode=\"gaussian\", mean=5,var=0.85,clip=False)\n",
    "    output_rescaled = match_histograms(output, real_phase[15][30:,:], multichannel=False)\n",
    "    convolved_outputs.append(output_rescaled)\n",
    "convolved_outputs = np.array(convolved_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(convolved_outputs**2, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "    scalebar = ScaleBar(scale, 'um')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.gca().add_artist(scalebar)\n",
    "    plt.imshow(output_rescaled,cmap=\"Greys_r\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Phase Contrast\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-draft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuconvolve(cp.array(PC_OPLs[x]),kernel).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-drunk",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "portuguese-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import raster_geometry as rg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rotate\n",
    "import pickle\n",
    "import sys\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "sys.path.insert(0,'/home/georgeos/Documents/GitHub/SYMPTOMM2')\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "from skimage.morphology import opening\n",
    "from PIL import Image       \n",
    "import pymunk\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "from skimage import data\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage import draw\n",
    "#import napari\n",
    "from itertools import combinations\n",
    "from SYMPTOMM import PSF\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from cupyx.scipy.ndimage import convolve as cuconvolve\n",
    "import tifffile\n",
    "from skimage.exposure import match_histograms\n",
    "import cupy as cp\n",
    "from scipy.optimize import dual_annealing, shgo\n",
    "from skimage.transform import resize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.optimize import basinhopping\n",
    "import image_similarity_measures\n",
    "from image_similarity_measures.quality_metrics import rmse, psnr, fsim, issm, sre, sam, uiq\n",
    "from SYMPTOMM.general_drawing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "straight-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/output_pickles/cell_timeseries_short_trench.p\", \"rb\") as f:\n",
    "    cell_timeseries = pickle.load(f)\n",
    "with open(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/output_pickles/space_timeseries_short_trench.p\", \"rb\") as f:\n",
    "    space = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "likely-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=14)(delayed(gen_cell_props_for_draw)(a, ID_props) for a in cell_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greenhouse-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_transformation = False\n",
    "scenes = Parallel(n_jobs=14)(delayed(draw_scene)(cell_properties, False) for cell_properties in tqdm(cell_timeseries_properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "blessed-steal",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/399 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▎         | 14/399 [00:00<00:04, 87.51it/s]\u001b[A\n",
      "  7%|▋         | 28/399 [00:06<01:33,  3.97it/s]\u001b[A\n",
      " 11%|█         | 42/399 [00:13<02:14,  2.65it/s]\u001b[A\n",
      " 14%|█▍        | 56/399 [00:20<02:30,  2.28it/s]\u001b[A\n",
      " 18%|█▊        | 70/399 [00:26<02:22,  2.30it/s]\u001b[A\n",
      " 21%|██        | 84/399 [00:33<02:22,  2.21it/s]\u001b[A\n",
      " 25%|██▍       | 98/399 [00:40<02:21,  2.12it/s]\u001b[A\n",
      " 28%|██▊       | 112/399 [00:46<02:08,  2.23it/s]\u001b[A\n",
      " 32%|███▏      | 126/399 [00:53<02:09,  2.11it/s]\u001b[A\n",
      " 35%|███▌      | 140/399 [01:02<02:15,  1.91it/s]\u001b[A\n",
      " 39%|███▊      | 154/399 [01:09<02:04,  1.96it/s]\u001b[A\n",
      " 42%|████▏     | 168/399 [01:15<01:51,  2.07it/s]\u001b[A\n",
      " 46%|████▌     | 182/399 [01:22<01:46,  2.04it/s]\u001b[A\n",
      " 49%|████▉     | 196/399 [01:29<01:42,  1.99it/s]\u001b[A\n",
      " 53%|█████▎    | 210/399 [01:35<01:29,  2.12it/s]\u001b[A\n",
      " 56%|█████▌    | 224/399 [01:41<01:19,  2.21it/s]\u001b[A\n",
      " 60%|█████▉    | 238/399 [01:49<01:19,  2.03it/s]\u001b[A\n",
      " 63%|██████▎   | 252/399 [01:56<01:12,  2.01it/s]\u001b[A\n",
      " 67%|██████▋   | 266/399 [02:01<01:01,  2.17it/s]\u001b[A\n",
      " 70%|███████   | 280/399 [02:09<00:59,  2.02it/s]\u001b[A\n",
      " 74%|███████▎  | 294/399 [02:16<00:51,  2.03it/s]\u001b[A\n",
      " 77%|███████▋  | 308/399 [02:22<00:41,  2.17it/s]\u001b[A\n",
      " 81%|████████  | 322/399 [02:28<00:35,  2.16it/s]\u001b[A\n",
      " 84%|████████▍ | 336/399 [02:35<00:29,  2.11it/s]\u001b[A\n",
      " 88%|████████▊ | 350/399 [02:41<00:22,  2.19it/s]\u001b[A\n",
      " 91%|█████████ | 364/399 [02:48<00:16,  2.13it/s]\u001b[A\n",
      " 95%|█████████▍| 378/399 [02:56<00:10,  2.03it/s]\u001b[A\n",
      "100%|██████████| 399/399 [03:02<00:00,  2.18it/s]\u001b[A\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/training_data/OPL_renders\"\n",
    "_ = Parallel(n_jobs=10)(delayed(scene_plotter)(scenes[x][1],output_dir,\"OPL_mask\",x+4000,matplotlib_draw=False) for x in range(len(scenes)))\n",
    "_ = Parallel(n_jobs=10)(delayed(scene_plotter)(scenes[x][0],output_dir,\"OPL_intensity\",x+4000,matplotlib_draw=False) for x in range(len(scenes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-revolution",
   "metadata": {},
   "source": [
    "# Phase Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_segments = main_segments.reindex(index=main_segments.index[::-1]) # run if you get a zero-width image output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 50\n",
    "\n",
    "#trench_multiplier = 30\n",
    "#cell_multiplier = 2\n",
    "#background_multiplier = 10\n",
    "#grid_def = [range(15,trench_multiplier), np.arange(0.1,cell_multiplier,0.1), range(background_multiplier)]\n",
    "#grid = list(itertools.product(*grid_def))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(generate_PC_OPL(30,1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PC_OPLs = np.array([generate_PC_OPL(*k) for k in grid])\n",
    "#viewer = napari.view_image(np.array(PC_OPLs), rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_phase = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(56)).zfill(2),\n",
    "    str(np.random.randint(20,25)).zfill(3)\n",
    "))\n",
    "plt.imshow(real_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-macro",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-identity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cuconvolve(cp.array(PC_OPLs[2000]),kernel)\n",
    "output = output.get()\n",
    "output = rescale(output, 1/4, anti_aliasing=False)[3:182,3:-3]\n",
    "output = random_noise(output, mode=\"gaussian\", mean=5,var=0.0000051,clip=False)\n",
    "#viewer = napari.view_image(output_rescaled, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_segment = output\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(top_segment,cmap=\"Greys_r\")\n",
    "top_segment.shape += (1,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-roberts",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_rescale(image,kernel):\n",
    "    output = cuconvolve(cp.array(image),cp.array(kernel))\n",
    "    output = output.get()\n",
    "    output = rescale(output, 1/4, anti_aliasing=False)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(z, ret_tuple = False):\n",
    "    real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(20,25)).zfill(3)\n",
    "))\n",
    "    real_image = real_image.astype(np.float64)/np.max(real_image)\n",
    "    σ, trench_multiplier, cell_multiplier, background_multiplier = z\n",
    "    expanded_scene = generate_PC_OPL(trench_multiplier,cell_multiplier,background_multiplier)\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, σ)\n",
    "    convolved_image = convolve_rescale(expanded_scene,kernel)[0:182,3:-3]\n",
    "    #convolved_image = random_noise(convolved_image, mode=\"gaussian\", mean=5,var=σ2,clip=False)\n",
    "    convolved_image = match_histograms(convolved_image, real_image, multichannel=False)\n",
    "    convolved_image = resize(convolved_image,real_image.shape,clip=False,preserve_range=False,anti_aliasing=None)\n",
    "    convolved_image = convolved_image/np.max(convolved_image)\n",
    "    ssim_real = ssim(convolved_image, real_image)\n",
    "    intersection = return_intersection_between_image_hists(convolved_image, real_image, 100)\n",
    "    #sims \n",
    "    convolved_image.shape += (1,)\n",
    "    real_image.shape += (1,)\n",
    "    _fsim = fsim(convolved_image,real_image)\n",
    "    _issm = issm(convolved_image,real_image)\n",
    "    _sam = sam(convolved_image,real_image)\n",
    "    _sre = sre(convolved_image,real_image)\n",
    "    objs = [ssim_real, 0.5*intersection, _fsim, _issm, _sam, _sre/20]\n",
    "    if ret_tuple == False:\n",
    "        return -np.linalg.norm(objs)\n",
    "    else:\n",
    "        return objs\n",
    "\n",
    "progress = []\n",
    "def callbackF(x, f, context):\n",
    "    print(x)\n",
    "    progress.append(x)\n",
    "    \n",
    "def callbackSHGo(x):\n",
    "    print(x)\n",
    "    progress.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = list(zip([min_sigma, 1.0, 0.2, 1], [20.0, 30.0, 5.0, 20.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = shgo(objective_function, bounds = np.array(bounds),callback=callbackSHGo,options={\"minimize_every_iter\":True})\n",
    "ret = dual_annealing(objective_function, bounds = np.array(bounds),callback=callbackF,maxiter=1000,initial_temp=5*10**4,x0=ret.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.callbacks import VerboseCallback\n",
    "res = gp_minimize(objective_function,                  # the function to minimize\n",
    "                  bounds,      # the bounds on each dimension of x\n",
    "                  acq_func=\"gp_hedge\",      # the acquisition function\n",
    "                  n_calls=50,         # the number of evaluations of f\n",
    "                  n_random_starts=5,  # the number of random initialization points\n",
    "                 n_jobs = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_get_image(z):\n",
    "    σ, trench_multiplier, cell_multiplier, background_multiplier, = z\n",
    "    expanded_scene = generate_PC_OPL(trench_multiplier,cell_multiplier,background_multiplier)\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, σ)\n",
    "    convolved_image = convolve_rescale(expanded_scene,kernel)[0:182,10:-10]\n",
    "    #convolved_image = random_noise(convolved_image, mode=\"gaussian\", mean=5,var=σ2,clip=False)\n",
    "    convolved_image = match_histograms(convolved_image, real_image, multichannel=False)\n",
    "    convolved_image = resize(convolved_image,real_image.shape,clip=False,preserve_range=False,anti_aliasing=None)\n",
    "    convolved_image = convolved_image/np.max(convolved_image)\n",
    "    ssim_real = ssim(convolved_image, real_image)\n",
    "    intersection = return_intersection_between_image_hists(convolved_image, real_image, 100)\n",
    "    return convolved_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(1,25)).zfill(3)\n",
    "))\n",
    "optimised_image = objective_function_get_image(ret.x)\n",
    "noisy_image = random_noise(optimised_image, mode=\"gaussian\", mean=5,var=0.0002,clip=False)\n",
    "viewer = napari.view_image(noisy_image, rgb=False)\n",
    "\n",
    "\n",
    "\n",
    "viewer = napari.view_image(real_image, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_outputs = []\n",
    "for x in range(len(PC_OPLs)):\n",
    "    output = cuconvolve(cp.array(PC_OPLs[x]),kernel)\n",
    "    output = output.get()\n",
    "    output = rescale(output, 1/1.75, anti_aliasing=False)[:364,:]\n",
    "    output = random_noise(output, mode=\"gaussian\", mean=5,var=0.85,clip=False)\n",
    "    output_rescaled = match_histograms(output, real_phase[15][30:,:], multichannel=False)\n",
    "    convolved_outputs.append(output_rescaled)\n",
    "convolved_outputs = np.array(convolved_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(convolved_outputs**2, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "    scalebar = ScaleBar(scale, 'um')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.gca().add_artist(scalebar)\n",
    "    plt.imshow(output_rescaled,cmap=\"Greys_r\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Phase Contrast\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-consciousness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuconvolve(cp.array(PC_OPLs[x]),kernel).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-mechanism",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560f8a4-340e-4593-a36c-f5b57d7a4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tifffile import imread, imsave\n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "\n",
    "from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n",
    "from stardist.models import StarDist2D\n",
    "\n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()\n",
    "from ipywidgets import interactive, interact\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.measure import regionprops_table\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "from joblib import delayed, Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e7dab-a522-42ce-b3ff-ec83c413d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist2D(None, name='stardist_no_shape_completion', basedir='/home/georgeos/Storage/Google Drive (Cambridge Univeristy)/SYMPTOMM_models/bent_noisematched_allsize_empty_und6_unarelu_unlasigmoid_epc1000_lessaugval')\n",
    "\n",
    "\n",
    "X = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/extracted_long_trenches/*.tif\"))\n",
    "X = list(map(imread,X))\n",
    "\n",
    "requires_resize = True\n",
    "resize_shape = (256,64)\n",
    "if requires_resize:\n",
    "    #X = [resize(x,(32,8), order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in tqdm(X)]\n",
    "    X = [resize(x,resize_shape, order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None) for x in tqdm(X)]\n",
    "\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc183c-eae1-4585-bccc-6abe3fb0ad6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = sorted(os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/extracted_long_trenches/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cb264-b6da-4eaa-b15c-ee4e70ec6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/predictions_0.2_lessaugval_unlasigmoid\"\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(output_dir+\"/masks_resized/\")\n",
    "    os.mkdir(output_dir+\"/images_resized/\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(output_dir+\"/diagnostics/\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e362c-99cc-4c2a-8083-03e9c9a5de54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_details = []\n",
    "for z in tqdm(range(len(X))):\n",
    "    img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.1, nms_thresh=0.01)\n",
    "    imsave(\n",
    "        output_dir+\"/masks_resized/{}\".format(names[z]),labels)\n",
    "    imsave(\n",
    "        output_dir+\"/images_resized/{}\".format(names[z]),img)\n",
    "    all_labels.append(labels)\n",
    "    all_details.append(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526550f-3b56-4497-90a4-c4e28b9c8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(z): \n",
    "    labels = all_labels[z]\n",
    "    details = all_details[z]\n",
    "    img = X[z]\n",
    "    probmap = np.zeros(labels.shape)\n",
    "    for x in range(len(details[\"points\"])):\n",
    "        probmap[np.where(labels == labels[details[\"points\"][x][0],details[\"points\"][x][1]])] = details[\"prob\"][x]\n",
    "    f, ax = plt.subplots(1,4,figsize=(5.5,4))\n",
    "    ax[0].imshow(img,cmap=\"Greys_r\")\n",
    "    ax[1].imshow(labels,cmap=lbl_cmap)\n",
    "    prob = ax[3].imshow(probmap,cmap=\"afmhot\",vmin=0,vmax=1)\n",
    "    ax[2].imshow(img,cmap=\"Greys_r\")\n",
    "    ax[2].imshow(labels,cmap=lbl_cmap,alpha=0.45)\n",
    "    ax[2].set_title(\"PC+Masks\")\n",
    "    f.colorbar(prob,ax=ax[3])\n",
    "    ax[3].set_title(\"P(Mask)\")\n",
    "    ax[1].set_title(\"Masks\")\n",
    "    ax[0].set_title(\"PC_image\")\n",
    "    for axs in ax:\n",
    "        axs.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir+\"/diagnostics/{}\".format(names[z][:-3]+\"jpeg\"),dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195377ef-4acc-405f-b41b-d396d4e09520",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(plotter)(i) for i in tqdm(range(len(all_labels))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4fa81-8eb2-4ded-9a18-e7f3459fc245",
   "metadata": {},
   "source": [
    "## playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4f91b-1cfb-45af-922c-ddd15f578bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_1 = []\n",
    "all_details_1 = []\n",
    "all_imgs_1 = []\n",
    "for z in range(len(X)):\n",
    "    img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.7, nms_thresh=0.1)\n",
    "    all_labels_1.append(labels)\n",
    "    all_details_1.append(details)\n",
    "    all_imgs_1.append(img)\n",
    "\n",
    "@interact\n",
    "def plotter_1(x=(0,len(X)-1)):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(all_imgs_1[x] if all_imgs_1[x].ndim==2 else all_imgs_1[x][...,0], clim=(0,1), cmap='gray')\n",
    "    plt.imshow(all_labels_1[x], cmap=lbl_cmap, alpha=0.35)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffd617-4a86-4886-b0c7-ab5019ba2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resize(all_imgs_1[0],(211,40), order=0, mode='reflect', cval=0, clip=True, preserve_range=True, anti_aliasing=None, anti_aliasing_sigma=None),cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b4601c-f857-4d15-aea3-72199cf49f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from skimage.segmentation import clear_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9581e7-b2d7-4d55-ac63-1a35659fa4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties = [\"area\",\"centroid\",\"major_axis_length\",\"minor_axis_length\"]\n",
    "\n",
    "trenches = os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/\")\n",
    "trenches.sort()\n",
    "model = StarDist2D(None, name='stardist_no_shape_completion', basedir='models_mixed_size_1600_epoch_good_50')\n",
    "all_cell_data = pd.DataFrame()\n",
    "master_label = []\n",
    "master_imgs = []\n",
    "exception_trenches = [\"trench_52\", \"trench_54\"]\n",
    "for trench in tqdm(trenches):\n",
    "    cell_data = pd.DataFrame()\n",
    "\n",
    "    X = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/{}/*.tif\".format(trench)))\n",
    "    X = list(map(imread,X))\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "\n",
    "\n",
    "    all_labels = []\n",
    "    all_details = []\n",
    "    all_imgs = []\n",
    "    for z in range(3,25):\n",
    "        img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "        if z == 3:\n",
    "            if trench in exception_trenches:\n",
    "                midpoint = int(img.shape[1]/2)\n",
    "            else:\n",
    "                image_profile = img.mean(axis=0)\n",
    "                peaks = find_peaks(image_profile, height=np.mean(image_profile)*0.9)\n",
    "                if len(peaks[0]) > 1:\n",
    "                    midpoint = int(np.sum(peaks[0])/2)\n",
    "                elif len(peaks[0]) == 1:\n",
    "                    midpoint = peaks[0][0]\n",
    "                trench_half_width = 15\n",
    "        \n",
    "        labels, details = model.predict_instances(img, prob_thresh=0.7, nms_thresh=0.1)\n",
    "        \n",
    "\n",
    "        labels = clear_border(labels[:,midpoint-trench_half_width:midpoint+trench_half_width])\n",
    "        \n",
    "        \n",
    "        all_labels.append(labels)\n",
    "        all_details.append(details)\n",
    "        all_imgs.append(img[:,midpoint-trench_half_width:midpoint+trench_half_width])\n",
    "        \n",
    "    for label_image in all_labels:\n",
    "        if len(np.unique(label_image)) > 1:\n",
    "            cell_data = cell_data.append(pd.DataFrame(regionprops_table(label_image=label_image, properties=properties)).sort_values(by = \"centroid-0\").iloc[0])\n",
    "        else:\n",
    "            cell_data = cell_data.append(pd.Series([np.nan]*len(properties)),ignore_index=True)\n",
    "    cell_data.reset_index(inplace=True,drop=True)\n",
    "    cell_data[\"cell\"] = trench\n",
    "    cell_data[\"time\"] = range(3,25)\n",
    "    all_cell_data = all_cell_data.append(cell_data)\n",
    "    all_cell_data.reset_index(inplace=True,drop=True)\n",
    "    master_label.append(all_labels)\n",
    "    master_imgs.append(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866724e-7b82-49dd-bfd1-3bc43d6e876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(all_cell_data, col='cell', col_wrap=7)\n",
    "g = g.map(sns.lineplot, 'time', 'major_axis_length', ci=None).add_legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_1600_epoch_50perc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a2cc8-80c8-44e9-a22c-7fa1bfbcf73f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in range(len(master_imgs[0])):\n",
    "    plt.imshow(master_imgs[54][x],cmap=\"Greys_r\")\n",
    "    plt.imshow(master_label[54][x],alpha=0.4,cmap=\"jet\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b4319-ab7a-4aa7-8b5f-653138b43107",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    fig, ax = plt.subplots(7,8, figsize=(16,16))\n",
    "    for i,(a,x) in enumerate(zip(ax.flat, X)):\n",
    "        a.imshow(x if x.ndim==2 else x[...,0], cmap='gray')\n",
    "        a.set_title(i)\n",
    "    [a.axis('off') for a in ax.flat]\n",
    "    plt.tight_layout()\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fafb1f-a4e8-43ec-995f-002719e4f004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_details = []\n",
    "all_imgs = []\n",
    "for z in range(25):\n",
    "    img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.6, nms_thresh=0.1)\n",
    "    all_labels.append(labels)\n",
    "    all_details.append(details)\n",
    "    all_imgs.append(img)\n",
    "    \n",
    "@interact\n",
    "def plotter(x=(0,len(X)-1)):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(all_imgs[x] if all_imgs[x].ndim==2 else all_imgs[x][...,0], clim=(0,1), cmap='gray')\n",
    "    plt.imshow(all_labels[x], cmap=lbl_cmap, alpha=0.35)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df294ba3-8746-4491-aad1-03afe0e12cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops, regionprops_table\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836a5af-c33a-4f60-9115-9d323aa2c6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073ae48-fa60-49db-b630-26a833014301",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches = os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e528a-d540-4802-9ef5-371ed5a5c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for t in range(len(trench))\n",
    "cell_data = pd.DataFrame()\n",
    "for label_image in all_labels:\n",
    "    cell_data = cell_data.append(pd.DataFrame(regionprops_table(label_image=label_image, properties=properties)).sort_values(by = \"centroid-0\").iloc[0])\n",
    "cell_data.reset_index(inplace=True,drop=True)\n",
    "cell_data[\"cell\"] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dffc0d-ea88-4df7-aa9e-1ef3d6126e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b73792-b54d-4730-9a0c-0bd7fc510d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = StarDist2D(None, name='stardist_no_shape_completion', basedir='models_nohist')\n",
    "\n",
    "trenches = os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/\")\n",
    "all_cell_data = pd.DataFrame()\n",
    "for trench in trenches:\n",
    "    cell_data = pd.DataFrame()\n",
    "\n",
    "    X = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/{}/*.tif\".format(trench)))\n",
    "    X = list(map(imread,X))\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "\n",
    "\n",
    "    all_labels = []\n",
    "    all_details = []\n",
    "    all_imgs = []\n",
    "    for z in range(0,25):\n",
    "        img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "        labels, details = model.predict_instances(img, prob_thresh=0.7, nms_thresh=0.1)\n",
    "        all_labels.append(labels)\n",
    "        all_details.append(details)\n",
    "        all_imgs.append(img)\n",
    "        \n",
    "    for label_image in all_labels:\n",
    "        cell_data = cell_data.append(pd.DataFrame(regionprops_table(label_image=label_image, properties=properties)).sort_values(by = \"centroid-0\").iloc[0])\n",
    "    cell_data.reset_index(inplace=True,drop=True)\n",
    "    cell_data[\"cell\"] = trench\n",
    "    cell_data[\"time\"] = range(0,25)\n",
    "    all_cell_data = all_cell_data.append(cell_data)\n",
    "    all_cell_data.reset_index(inplace=True,drop=True)\n",
    "    print(trench)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2390f5-9304-4bfe-af8f-3a24cf417cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_data[\"minor_axis_length\"] = (all_cell_data[\"minor_axis_length\"])*2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f238e22-2247-473f-adca-efab3a778339",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_data_temp = pd.melt(all_cell_data,value_vars=[\"major_axis_length\",\"minor_axis_length\"],id_vars =[\"centroid-0\",\"centroid-1\",\"cell\",\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae900e4-0f98-444c-9457-574915b530dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(all_cell_data_temp, col='cell', hue=\"variable\",col_wrap=7)\n",
    "g = g.map(sns.lineplot, 'time', \"value\", ci=None).add_legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_nohist.pdf\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a9e64-423f-4af0-8372-ccc3d658642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist2D(None, name='stardist_no_shape_completion', basedir='models')\n",
    "\n",
    "trenches = os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/\")\n",
    "all_cell_data = pd.DataFrame()\n",
    "for trench in trenches:\n",
    "    cell_data = pd.DataFrame()\n",
    "\n",
    "    X = sorted(glob(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/{}/*.tif\".format(trench)))\n",
    "    X = list(map(imread,X))\n",
    "\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "\n",
    "\n",
    "    all_labels = []\n",
    "    all_details = []\n",
    "    all_imgs = []\n",
    "    for z in range(0,25):\n",
    "        img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "        labels, details = model.predict_instances(img, prob_thresh=0.65, nms_thresh=0.1)\n",
    "        all_labels.append(labels)\n",
    "        all_details.append(details)\n",
    "        all_imgs.append(img)\n",
    "        \n",
    "    for label_image in all_labels:\n",
    "        cell_data = cell_data.append(pd.DataFrame(regionprops_table(label_image=label_image, properties=properties)).sort_values(by = \"centroid-0\").iloc[0])\n",
    "    cell_data.reset_index(inplace=True,drop=True)\n",
    "    cell_data[\"cell\"] = trench\n",
    "    cell_data[\"time\"] = range(0,25)\n",
    "    all_cell_data = all_cell_data.append(cell_data)\n",
    "    all_cell_data.reset_index(inplace=True,drop=True)\n",
    "    print(trench)\n",
    "g = sns.FacetGrid(all_cell_data, col='cell', col_wrap=7)\n",
    "g = g.map(sns.lineplot, 'time', 'major_axis_length', ci=None).add_legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_mixed_cells.png\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e5219-ad98-4ecb-a490-e3429a870296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels_1 = []\n",
    "all_details_1 = []\n",
    "all_imgs_1 = []\n",
    "for z in range(25):\n",
    "    img = normalize(X[z], 1,100, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.6, nms_thresh=0.1)\n",
    "    all_labels_1.append(labels)\n",
    "    all_details_1.append(details)\n",
    "    all_imgs_1.append(img)\n",
    "    \n",
    "@interact\n",
    "def plotter_1(x=(0,len(X)-1)):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(all_imgs_1[x] if all_imgs[x].ndim==2 else all_imgs_1[x][...,0], clim=(0,1), cmap='gray')\n",
    "    plt.imshow(all_labels_1[x], cmap=lbl_cmap, alpha=0.35)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22323d-e51d-4179-b405-374460ec135a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

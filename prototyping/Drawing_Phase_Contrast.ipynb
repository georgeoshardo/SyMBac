{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8403999f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3704125e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "import sys\n",
    "sys.path.insert(0,'/home/georgeos/Documents/GitHub/SYMPTOMM2')\n",
    "from SYMPTOMM.cell import Cell\n",
    "from SYMPTOMM.scene_functions import create_space, step_and_update\n",
    "from SYMPTOMM.trench_geometry import trench_creator\n",
    "from SYMPTOMM.phase_contrast_drawing import *\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "div_odd = lambda n: (n//2, n//2 + 1)\n",
    "perc_diff = lambda a, b: abs(a-b)/((a+b)/2)\n",
    "from skimage.exposure import rescale_intensity\n",
    "from ipywidgets import interactive\n",
    "import os\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "\n",
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(10,20)).zfill(3)))\n",
    "\n",
    "#viewer = napari.view_image(real_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64476ce1-d433-4a92-965a-6d8d0cf5534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/Lane_02_pos_002_trench_x_1963_y_0067_w_0046_h_0460_c_Phase.tif\")[0][:300,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa476171-0ee2-4c5c-af18-a7fdf33e9374",
   "metadata": {},
   "source": [
    "## FuncDefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11affddf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_simulation(trench_length, trench_width, cell_max_length, cell_width, sim_length):\n",
    "    \n",
    "    \n",
    "    space = create_space()\n",
    "    space.gravity = 0, 0 # arbitrasry units\n",
    "    dt = 1/100 #time-step per frame\n",
    "    pix_mic_conv = 10 # pixels per micron\n",
    "    scale_factor = pix_mic_conv * 3 # resolution scaling factor \n",
    "\n",
    "    trench_length = trench_length*scale_factor\n",
    "    trench_width = trench_width*scale_factor\n",
    "    trench_creator(trench_width,trench_length,(35,0),space) # Coordinates of bottom left corner of the trench\n",
    "    #trench_creator(35,trench_length,(35*3,0),space) # Coordinates of bottom left corner of the trench\n",
    "    #trench_creator(35,trench_length,(35*5,0),space) # Coordinates of bottom left corner of the trench\n",
    "\n",
    "    cell1 = Cell(\n",
    "        length = cell_max_length*scale_factor,  \n",
    "        width = cell_width*scale_factor, \n",
    "        resolution = 60, \n",
    "        position = (20+35,40), \n",
    "        angle = 0.8, \n",
    "        space = space,\n",
    "        dt = 1/60,\n",
    "        growth_rate_constant = 1,\n",
    "        max_length = cell_max_length*scale_factor,\n",
    "        max_length_mean =cell_max_length*scale_factor,\n",
    "        max_length_var = 0.5*np.sqrt(scale_factor),\n",
    "        width_var = 0.07*np.sqrt(scale_factor),\n",
    "        width_mean = cell_width*scale_factor\n",
    "    )\n",
    "\n",
    "\n",
    "    cells = [cell1]\n",
    "    cell_timeseries = []\n",
    "    phys_iters = 250\n",
    "    for x in tqdm(range(sim_length+250),desc=\"Simulation Progress\"):\n",
    "        cells = step_and_update(dt=dt, cells=cells, space=space, phys_iters=phys_iters,ylim=trench_length)\n",
    "        if x > 250:\n",
    "            cell_timeseries.append(deepcopy(cells))\n",
    "    return cell_timeseries, space\n",
    "\n",
    "\n",
    "def get_similarity_metrics(real_image,synthetic_image):\n",
    "    synthetic_image = match_histograms(synthetic_image, real_image, multichannel=False)\n",
    "    synthetic_image = resize(synthetic_image,real_image.shape,clip=False,preserve_range=False,anti_aliasing=None)\n",
    "    synthetic_image = synthetic_image/np.max(synthetic_image)\n",
    "    ssim_real = ssim(synthetic_image, real_image)\n",
    "    intersection = return_intersection_between_image_hists(synthetic_image, real_image, 100)\n",
    "    #sims \n",
    "    synthetic_image_ = deepcopy(synthetic_image)\n",
    "    synthetic_image_.shape += (1,)\n",
    "    \n",
    "    real_image_ = deepcopy(real_image)\n",
    "    real_image_.shape += (1,)\n",
    "    _fsim = fsim(synthetic_image_,real_image_)\n",
    "    _issm = issm(synthetic_image_,real_image_)\n",
    "    _sam = sam(synthetic_image_,real_image_)\n",
    "    _sre = sre(synthetic_image_,real_image_)\n",
    "    objs = [ssim_real, 0.5*intersection, _fsim, _issm, _sam, _sre/20]\n",
    "    return objs\n",
    "\n",
    "def generate_PC_OPL(main_segments, offset, scene, mask, media_multiplier,cell_multiplier,device_multiplier):\n",
    "    def get_OPL_image():\n",
    "        segment_1_top_left = (0 + offset, int(main_segments.iloc[0][\"bb\"][0] + offset))\n",
    "        segment_1_bottom_right = (int(main_segments.iloc[0][\"bb\"][3] + offset), int(main_segments.iloc[0][\"bb\"][2] + offset))\n",
    "\n",
    "        segment_2_top_left = (0 + offset, int(main_segments.iloc[1][\"bb\"][0] + offset))\n",
    "        segment_2_bottom_right = (int(main_segments.iloc[1][\"bb\"][3] + offset), int(main_segments.iloc[1][\"bb\"][2] + offset))\n",
    "\n",
    "        test_scene = np.zeros(scene.shape) + device_multiplier\n",
    "        rr, cc = draw.rectangle(start = segment_1_top_left, end = segment_1_bottom_right, shape = test_scene.shape)\n",
    "        test_scene[rr,cc] = 1 * media_multiplier\n",
    "        rr, cc = draw.rectangle(start = segment_2_top_left, end = segment_2_bottom_right, shape = test_scene.shape)\n",
    "        test_scene[rr,cc] = 1 * media_multiplier\n",
    "        circ_midpoint_y = (segment_1_top_left[1] + segment_2_bottom_right[1])/2\n",
    "        radius = (segment_1_top_left[1] - offset - (segment_2_bottom_right[1] - offset))/2\n",
    "        circ_midpoint_x = (offset) + radius\n",
    "\n",
    "        rr, cc = draw.rectangle(start = segment_2_top_left, end = (circ_midpoint_x,segment_1_top_left[1]), shape = test_scene.shape)\n",
    "        test_scene[rr.astype(int),cc.astype(int)] = 1 * media_multiplier\n",
    "        rr, cc = draw.disk(center = (circ_midpoint_x, circ_midpoint_y), radius = radius, shape = test_scene.shape)\n",
    "        rr_semi = rr[rr < (circ_midpoint_x + 1)]\n",
    "        cc_semi = cc[rr < (circ_midpoint_x + 1)]\n",
    "        test_scene[rr_semi,cc_semi] = device_multiplier\n",
    "        no_cells = deepcopy(test_scene)\n",
    "        test_scene += scene * cell_multiplier\n",
    "        test_scene = test_scene[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "        mask_resized = mask[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "        \n",
    "        no_cells = no_cells[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "        expanded_scene_no_cells = np.zeros((int(no_cells.shape[0]*1.2), no_cells.shape[1]*2)) + media_multiplier\n",
    "        expanded_scene_no_cells[expanded_scene_no_cells.shape[0] - no_cells.shape[0]:,int(no_cells.shape[1]/2):int(no_cells.shape[1]/2) + no_cells.shape[1]] = no_cells\n",
    "\n",
    "        expanded_scene = np.zeros((int(test_scene.shape[0]*1.2), test_scene.shape[1]*2)) + media_multiplier\n",
    "        expanded_scene[expanded_scene.shape[0] - test_scene.shape[0]:,int(test_scene.shape[1]/2):int(test_scene.shape[1]/2) + test_scene.shape[1]] = test_scene\n",
    "        \n",
    "        expanded_mask = np.zeros((int(test_scene.shape[0]*1.2), test_scene.shape[1]*2))\n",
    "        expanded_mask[expanded_mask.shape[0] - test_scene.shape[0]:,int(test_scene.shape[1]/2):int(test_scene.shape[1]/2) + test_scene.shape[1]] = mask_resized\n",
    "        \n",
    "        return expanded_scene, expanded_scene_no_cells, expanded_mask\n",
    "    expanded_scene, expanded_scene_no_cells, expanded_mask = get_OPL_image()\n",
    "    if expanded_scene is None:\n",
    "        main_segments = main_segments.reindex(index=main_segments.index[::-1])\n",
    "        expanded_scene, expanded_scene_no_cells, expanded_mask = get_OPL_image()\n",
    "    return expanded_scene, expanded_scene_no_cells, expanded_mask\n",
    "\n",
    "def convolve_rescale(image,kernel,rescale_factor, rescale_int):\n",
    "    output = cuconvolve(cp.array(image),cp.array(kernel))\n",
    "    output = output.get()\n",
    "    output = rescale(output, rescale_factor, anti_aliasing=False)\n",
    "    \n",
    "    if rescale_int:\n",
    "        output = rescale_intensity(output.astype(np.float32), out_range=(0,1))\n",
    "    return output\n",
    "\n",
    "#make convolved image and real image same shape\n",
    "def make_images_same_shape(real_image,synthetic_image, rescale_int = True):\n",
    "    x_diff = synthetic_image.shape[1] - real_image.shape[1]\n",
    "    remove_from_left, remove_from_right = div_odd(x_diff)\n",
    "    y_diff = synthetic_image.shape[0] - real_image.shape[0]\n",
    "    if y_diff > 0:\n",
    "        synthetic_image = synthetic_image[y_diff:,remove_from_left-1:-remove_from_right]\n",
    "    else:\n",
    "        synthetic_image = synthetic_image[:,remove_from_left:-remove_from_right]\n",
    "        real_image = real_image[abs(y_diff):,:]\n",
    "\n",
    "    if rescale_int:\n",
    "        real_image = rescale_intensity(real_image.astype(np.float32), out_range=(0,1))\n",
    "        synthetic_image = rescale_intensity(synthetic_image.astype(np.float32), out_range=(0,1))\n",
    "    return real_image, synthetic_image\n",
    "\n",
    "def generate_test_comparison(media_multiplier, cell_multiplier, device_multiplier, sigma, scene_no, scale, match_histogram, match_noise, offset, debug_plot=True, noise_var=0.002):\n",
    "    \n",
    "    \n",
    "    expanded_scene, expanded_scene_no_cells, expanded_mask = generate_PC_OPL(\n",
    "        main_segments=main_segments,\n",
    "        offset=offset,\n",
    "        scene = scenes[scene_no][0],\n",
    "        mask = scenes[scene_no][1],\n",
    "        media_multiplier=media_multiplier,\n",
    "        cell_multiplier=cell_multiplier,\n",
    "        device_multiplier=device_multiplier\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, sigma, 0.75)\n",
    "\n",
    "\n",
    "\n",
    "    convolved = convolve_rescale(expanded_scene, kernel, 1/resize_amount, rescale_int = True)\n",
    "    real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "    \n",
    "    \n",
    "    if match_histogram:\n",
    "        matched = match_histograms(expanded_resized, real_resize, multichannel=False)\n",
    "    else:\n",
    "        matched = expanded_resized\n",
    "    \n",
    "    \n",
    "    noisy_img = random_noise(rescale_intensity(matched), mode=\"poisson\")\n",
    "    noisy_img = random_noise(rescale_intensity(noisy_img), mode=\"gaussian\", mean=0,var=noise_var,clip=False)\n",
    "    \n",
    "    if match_noise:\n",
    "        noisy_img = match_histograms(noisy_img, real_resize, multichannel=False)\n",
    "    else:\n",
    "        pass\n",
    "    noisy_img = rescale_intensity(noisy_img.astype(np.float32), out_range=(0,1))\n",
    "    \n",
    "    ## getting the cell mask to the right shape\n",
    "    expanded_mask_resized = rescale(expanded_mask, 1/resize_amount, anti_aliasing=False, preserve_range=True,order=0)\n",
    "    if len(np.unique(expanded_mask_resized)) > 2:\n",
    "        _, expanded_mask_resized_reshaped = make_images_same_shape(real_image,expanded_mask_resized, rescale_int=False)\n",
    "    else:\n",
    "        _, expanded_mask_resized_reshaped = make_images_same_shape(real_image,expanded_mask_resized, rescale_int=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    expanded_media_mask = rescale((expanded_scene_no_cells == device_multiplier) ^ (expanded_scene - expanded_scene_no_cells).astype(bool) , 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_media_mask = make_images_same_shape(real_image,expanded_media_mask, rescale_int=True)\n",
    "    just_media = expanded_media_mask * noisy_img\n",
    "    \n",
    "    expanded_cell_pseudo_mask = (expanded_scene - expanded_scene_no_cells).astype(bool)\n",
    "    expanded_cell_pseudo_mask = rescale(expanded_cell_pseudo_mask, 1/resize_amount, anti_aliasing=False)\n",
    "\n",
    "    real_resize, expanded_cell_pseudo_mask = make_images_same_shape(real_image,expanded_cell_pseudo_mask, rescale_int=True)\n",
    "    just_cells = expanded_cell_pseudo_mask * noisy_img\n",
    "    \n",
    "    expanded_device_mask = expanded_scene_no_cells == media_multiplier\n",
    "    expanded_device_mask = rescale(expanded_device_mask, 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_device_mask = make_images_same_shape(real_image,expanded_device_mask, rescale_int=True)\n",
    "    just_device = expanded_device_mask * noisy_img\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    simulated_means = np.array([just_media[np.where(just_media)].mean(), just_cells[np.where(just_cells)].mean(), just_device[np.where(just_device)].mean()])\n",
    "    simulated_vars = np.array([just_media[np.where(just_media)].var(), just_cells[np.where(just_cells)].var(), just_device[np.where(just_device)].var()])\n",
    "\n",
    "    \n",
    "    \n",
    "    mean_error.append(np.mean(perc_diff(real_means, simulated_means)))\n",
    "    media_error.append(perc_diff(simulated_means[0], real_media_mean))\n",
    "    cell_error.append(perc_diff(simulated_means[1], real_cell_mean))\n",
    "    device_error.append(perc_diff(simulated_means[2], real_device_mean))\n",
    "    \n",
    "    \n",
    "    mean_var_error.append(np.mean(perc_diff(real_vars, simulated_vars)))\n",
    "    media_var_error.append(perc_diff(simulated_vars[0], real_media_var))\n",
    "    cell_var_error.append(perc_diff(simulated_vars[1], real_cell_var))\n",
    "    device_var_error.append(perc_diff(simulated_vars[2], real_device_var))\n",
    "    if debug_plot == True:\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax1 = plt.subplot2grid((1,8),(0,0),colspan=1,rowspan=1)\n",
    "        ax2 = plt.subplot2grid((1,8),(0,1),colspan=1,rowspan=1)\n",
    "        ax3 = plt.subplot2grid((1,8),(0,2),colspan=3,rowspan=1)\n",
    "        ax4 = plt.subplot2grid((1,8),(0,5),colspan=3,rowspan=1)\n",
    "        ax1.imshow(noisy_img,cmap=\"Greys_r\")\n",
    "        ax1.set_title(\"Synthetic\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(real_resize,cmap=\"Greys_r\")\n",
    "        ax2.set_title(\"Real\")\n",
    "        ax2.axis(\"off\")\n",
    "        ax3.plot(mean_error)\n",
    "        ax3.plot(media_error)\n",
    "        ax3.plot(cell_error)\n",
    "        ax3.plot(device_error)\n",
    "        ax3.legend([\"Mean error\", \"Media error\", \"Cell error\", \"Device error\"])\n",
    "        ax3.set_title(\"Intensity Error\")\n",
    "\n",
    "        ax4.plot(mean_var_error)\n",
    "        ax4.plot(media_var_error)\n",
    "        ax4.plot(cell_var_error)\n",
    "        ax4.plot(device_var_error)\n",
    "        ax4.legend([\"Mean error\", \"Media error\", \"Cell error\", \"Device error\"])\n",
    "        ax4.set_title(\"Variance Error\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    else:\n",
    "        return noisy_img, expanded_mask_resized_reshaped.astype(int)\n",
    "\n",
    "def get_space_size(cell_timeseries_properties):\n",
    "    \"\"\"Iterates through the simulation timeseries properties, \n",
    "    finds the extreme cell positions and retrieves the required \n",
    "    image size to fit all cells into\"\"\"\n",
    "    max_x, max_y = 0, 0\n",
    "    for timepoint in cell_timeseries_properties:\n",
    "        for cell in timepoint:\n",
    "            x_, y_ = np.ceil(cell[3]).astype(int)\n",
    "            length_ = np.ceil(cell[0]).astype(int)\n",
    "            width_ = np.ceil(cell[1]).astype(int)\n",
    "            max_y_ = y_ + length_\n",
    "            max_x_ = x_ + width_\n",
    "            if max_x_ > max_x:\n",
    "                max_x = max_x_\n",
    "            if max_y_ > max_y:\n",
    "                max_y = max_y_\n",
    "    return (int(1.2*max_y), int(1.5*max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2a5b16-2ba8-4bb4-a907-aea6f3c64d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scene(cell_properties, do_transformation, mask_threshold, space_size, offset, label_masks):\n",
    "    space_size = np.array(space_size) # 1000, 200 a good value\n",
    "    space = np.zeros(space_size)\n",
    "    space_masks = np.zeros(space_size)\n",
    "    offsets = offset\n",
    "    if label_masks:\n",
    "        colour_label = 1\n",
    "    for properties in cell_properties:\n",
    "        length, width, angle, position, freq_modif, amp_modif, phase_modif,phase_mult = properties\n",
    "        length = length; width = width ; position = np.array(position) \n",
    "        angle = np.rad2deg(angle) - 90\n",
    "        x, y = np.array(position).astype(int) + offsets\n",
    "        OPL_cell = raster_cell(length = length, width=width)\n",
    "\n",
    "        if do_transformation:\n",
    "            OPL_cell_2 = np.zeros((OPL_cell.shape[0],int(OPL_cell.shape[1]*2)))\n",
    "            midpoint = int(np.median(range(OPL_cell_2.shape[1])))\n",
    "            OPL_cell_2[:,midpoint-int(OPL_cell.shape[1]/2):midpoint-int(OPL_cell.shape[1]/2)+OPL_cell.shape[1]] = OPL_cell\n",
    "            roll_coords = np.array(range(OPL_cell_2.shape[0]))\n",
    "            freq_mult = (OPL_cell_2.shape[0])\n",
    "            amp_mult = OPL_cell_2.shape[1]/10\n",
    "            sin_transform_cell = transform_func(amp_modif, freq_modif, phase_modif)\n",
    "            roll_amounts = sin_transform_cell(roll_coords,amp_mult,freq_mult,phase_mult)\n",
    "            for B in roll_coords:\n",
    "                OPL_cell_2[B,:] = np.roll(OPL_cell_2[B,:], roll_amounts[B])\n",
    "            OPL_cell = (OPL_cell_2)\n",
    "\n",
    "        rotated_OPL_cell = rotate(OPL_cell,angle,resize=True,clip=False,preserve_range=True)\n",
    "        cell_y, cell_x = (np.array(rotated_OPL_cell.shape)/2).astype(int)\n",
    "        offset_y = rotated_OPL_cell.shape[0] - space[y-cell_y:y+cell_y,x-cell_x:x+cell_x].shape[0]\n",
    "        offset_x = rotated_OPL_cell.shape[1] - space[y-cell_y:y+cell_y,x-cell_x:x+cell_x].shape[1]\n",
    "        assert y > cell_y, \"Cell has {} negative pixels in y coordinate, try increasing your offset\".format(y - cell_y)\n",
    "        assert x > cell_x, \"Cell has negative pixels in x coordinate, try increasing your offset\"\n",
    "        space[\n",
    "            y-cell_y:y+cell_y+offset_y,\n",
    "            x-cell_x:x+cell_x+offset_x\n",
    "        ] += rotated_OPL_cell\n",
    "        if label_masks:\n",
    "            space_masks[y-cell_y:y+cell_y+offset_y,x-cell_x:x+cell_x+offset_x] = (rotated_OPL_cell > 0)*colour_label\n",
    "            colour_label += 1\n",
    "        else:\n",
    "            space_masks[y-cell_y:y+cell_y+offset_y,x-cell_x:x+cell_x+offset_x] += (rotated_OPL_cell > mask_threshold)*colour_label\n",
    "            space_masks = space_masks == 1\n",
    "\n",
    "\n",
    "        #space_masks = opening(space_masks,np.ones((2,11)))\n",
    "    return space, space_masks.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30746946-f64c-48f0-bda8-5c454d7dfcb0",
   "metadata": {},
   "source": [
    "### Do large cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e81a7c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad83548dfef49b2b920b37c2d56f578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simulation Progress:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd77b231c5a4baeb882461dc4d15f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Timeseries Properties:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3431b754894e3197e189e27287429a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scene Draw::   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_length = 250\n",
    "cell_timeseries, space = run_simulation(trench_length=15, trench_width=1.45, cell_max_length=5.5, cell_width=1.15, sim_length = sim_length) # growth phase\n",
    "#cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=1.45, cell_width=0.85, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=14)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties'))\n",
    "do_transformation = False\n",
    "offset = 5\n",
    "mask_threshold = 17\n",
    "label_masks = True\n",
    "space_size = get_space_size(cell_timeseries_properties)\n",
    "scenes = Parallel(n_jobs=12)(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset, label_masks) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "034e81eb-89c7-4ea5-afcc-c078f2d18480",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_multiplier=-30\n",
    "cell_multiplier=-1\n",
    "device_multiplier=150\n",
    "\n",
    "\n",
    "condensers = get_condensers()\n",
    "W, R, diameter = condensers[\"Ph2\"]\n",
    "scale = 0.108379937 / 3 #0.35 #micron per pixel\n",
    "min_sigma = 0.42*0.6/6 / scale # micron\n",
    "\n",
    "resize_amount = 1/scale/10\n",
    "\n",
    "\n",
    "\n",
    "temp_expanded_scene, temp_expanded_scene_no_cells, temp_expanded_mask = generate_PC_OPL(\n",
    "    main_segments=main_segments,\n",
    "    offset=50,\n",
    "    scene = scenes[0][0],\n",
    "    mask = scenes[0][1],\n",
    "    media_multiplier=1,\n",
    "    cell_multiplier=1,\n",
    "    device_multiplier=1\n",
    ")\n",
    "\n",
    "temp_kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, min_sigma, 0.75)\n",
    "\n",
    "\n",
    "\n",
    "convolved = convolve_rescale(temp_expanded_scene, temp_kernel, 1/resize_amount, rescale_int = True)\n",
    "real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "\n",
    "viewer = napari.view_image(real_resize)\n",
    "media_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"media\")\n",
    "cell_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"cell\")\n",
    "device_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402fc7cd-5c59-4702-b0b0-c3241cf707e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_media_mean = real_resize[np.where(media_label.data)].mean();\n",
    "real_cell_mean = real_resize[np.where(cell_label.data)].mean(); \n",
    "real_device_mean = real_resize[np.where(device_label.data)].mean()\n",
    "real_means = np.array((real_media_mean, real_cell_mean, real_device_mean))\n",
    "\n",
    "real_media_var = real_resize[np.where(media_label.data)].var();\n",
    "real_cell_var = real_resize[np.where(cell_label.data)].var(); \n",
    "real_device_var = real_resize[np.where(device_label.data)].var()\n",
    "real_vars = np.array((real_media_var, real_cell_var, real_device_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef9f0e0-ec46-410a-ae01-60ef3caa87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=(scale,scale,scale),\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "offset=(offset,offset,offset));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6836af3-3e30-4e62-8dcb-2f1cd7900c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6b234e6995453d96e344419ef02d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='media_multiplier', max=300, min=-300), FloatSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c10830fe-3a9b-4ec7-a591-e1079693ea91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11549"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5874dbde-ddfe-41ee-8059-99c93a2cf732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(interactive_output, sample_amount, randomise_hist_match, randomise_noise_match, sim_length, burn_in, n_samples, save_dir):\n",
    "    media_multiplier, cell_multiplier, device_multiplier, sigma, scene_no, scale, match_histogram, match_noise, offset, debug_plot, noise_var = list(interactive_output.kwargs.values())\n",
    "    debug_plot = False\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(save_dir + \"/convolutions\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(save_dir + \"/masks\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    current_file_num = len(os.listdir(save_dir+\"/convolutions\"))\n",
    "    #for z in range(n_samples):\n",
    "    def generate_samples(z):\n",
    "        _media_multiplier = np.random.uniform(1-sample_amount,1+sample_amount) * media_multiplier\n",
    "        _cell_multiplier = np.random.uniform(1-sample_amount,1+sample_amount) * cell_multiplier\n",
    "        _device_multiplier = np.random.uniform(1-sample_amount,1+sample_amount) * device_multiplier\n",
    "        _sigma = np.random.uniform(1-sample_amount,1+sample_amount) * sigma\n",
    "        _scene_no = np.random.randint(burn_in,sim_length-2)\n",
    "        _noise_var = np.random.uniform(1-sample_amount,1+sample_amount) * noise_var\n",
    "        if randomise_hist_match:\n",
    "            _match_histogram = np.random.choice([True, False])\n",
    "        if randomise_noise_match:\n",
    "            _match_noise = np.random.choice([True, False])\n",
    "        \n",
    "        syn_image, mask = generate_test_comparison(_media_multiplier, _cell_multiplier, _device_multiplier, _sigma, _scene_no, scale, _match_histogram, match_noise, offset, debug_plot, noise_var)\n",
    "        \n",
    "        syn_image = Image.fromarray(skimage.img_as_uint(rescale_intensity(syn_image)))\n",
    "        syn_image.save(\"{}/convolutions/synth_{}.tif\".format(save_dir, str(z).zfill(5)))\n",
    "        mask = Image.fromarray(mask.astype(np.uint8))\n",
    "        mask.save(\"{}/masks/synth_{}.tif\".format(save_dir, str(z).zfill(5)))        \n",
    "    ## TODO: change parallel if not using GPU\n",
    "    Parallel(n_jobs=1)(delayed(generate_samples)(z) for z in tqdm(range(current_file_num,n_samples+current_file_num), desc=\"Sample generation:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "005633aa-0587-4639-a40e-24cc202dad5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30149ec4cb4942d49c3bd39ed20548c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sample generation::   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.02, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  5000, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/for_stardist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695e753-539c-4365-b373-e38329014986",
   "metadata": {},
   "source": [
    "### Do small cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d312d5fb-ca93-4fcf-b322-c9a17ee866c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11816b186f04fa6bf2e3190a911bf29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simulation Progress:   0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5f3a920be942deac43a63997692105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Timeseries Properties::   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2379aa5d5a4647da9151d77ad475723a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scene Draw:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_length = 200\n",
    "cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=1.45, cell_width=0.85, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=-1)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties:'))\n",
    "do_transformation = False\n",
    "offset = 20\n",
    "mask_threshold = 17\n",
    "space_size = (1000,200)\n",
    "label_masks = True\n",
    "scenes = Parallel(n_jobs=-1, backend='multiprocessing')(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset, label_masks) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99bd965a-cc77-444a-aa0c-2b5fb0e30029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92300c1fdd842e8be08063f4ff51d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='media_multiplier', max=300, min=-300), FloatSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=scale,\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "offset=(offset,offset,offset));\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6abcdd96-3e14-4e2b-b9ef-8f19ab5a5ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6302a851868348a8943bb2711505b1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sample generation::   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.02, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  200, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/for_stardist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886209b-3b9e-4daf-9161-498fab1ecfa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_images_to_optimise(expanded_scene,expanded_scene_no_cells,expanded_resized, real_image, convolved, resize_amount):\n",
    "    expanded_media_mask = rescale((expanded_scene_no_cells == device_multiplier) ^ (expanded_scene - expanded_scene_no_cells).astype(bool) , 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_media_mask = make_images_same_shape(real_image,expanded_media_mask, rescale_int=True)\n",
    "    just_media = expanded_media_mask * expanded_resized\n",
    "    \n",
    "    expanded_cell_pseudo_mask = (expanded_scene - expanded_scene_no_cells).astype(bool)\n",
    "    expanded_cell_pseudo_mask = rescale(expanded_cell_pseudo_mask, 1/resize_amount, anti_aliasing=False)\n",
    "\n",
    "    real_resize, expanded_cell_pseudo_mask = make_images_same_shape(real_image,expanded_cell_pseudo_mask, rescale_int=True)\n",
    "    just_cells = expanded_cell_pseudo_mask * expanded_resized\n",
    "    \n",
    "    expanded_device_mask = expanded_scene_no_cells == media_multiplier\n",
    "    expanded_device_mask = rescale(expanded_device_mask, 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_device_mask = make_images_same_shape(real_image,expanded_device_mask, rescale_int=True)\n",
    "    just_device = expanded_device_mask * expanded_resized\n",
    "    \n",
    "    return just_media, just_cells, just_device, expanded_media_mask, expanded_cell_pseudo_mask, expanded_device_mask\n",
    "\n",
    "just_media, just_cells, just_device, perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask = get_images_to_optimise(expanded_scene,expanded_scene_no_cells,expanded_resized, real_image, convolved, resize_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4872d-44c8-4bd4-9df2-1f481701b261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_intensity_means(perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask, expanded_resized):\n",
    "    return (perm_expanded_media_mask * expanded_resized).mean(), (perm_expanded_cell_pseudo_mask * expanded_resized).mean(), (perm_expanded_device_mask * expanded_resized).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1be0b7-0723-41e1-afad-dee308759e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPL_image_convolved = []\n",
    "global current_error\n",
    "current_error = 10\n",
    "best_input = []\n",
    "\n",
    "def objective_function(v, return_diagnostics = False):\n",
    "    global current_error\n",
    "    media_multiplier, cell_multiplier, device_multiplier= v\n",
    "    expanded_scene, expanded_scene_no_cells, expanded_mask = generate_PC_OPL(\n",
    "    main_segments=main_segments,\n",
    "    offset=50,\n",
    "    scene = scenes[4][0],\n",
    "    mask = scenes[4][1],\n",
    "    media_multiplier=media_multiplier,\n",
    "    cell_multiplier=cell_multiplier,\n",
    "    device_multiplier=device_multiplier\n",
    "    )\n",
    "\n",
    "\n",
    "    resize_amount = 1/scale/10\n",
    "\n",
    "    ## Creating the synthetic image\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, 7, 0.6)\n",
    "    convolved = convolve_rescale(expanded_scene, kernel, resize_amount, rescale_int = True)\n",
    "    real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "\n",
    "    ## getting the cell mask to the right shape\n",
    "    expanded_mask_resized = rescale(expanded_mask,1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_mask_resized_reshaped = make_images_same_shape(real_image,expanded_mask_resized, rescale_int=True)\n",
    "    _, _, _, perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask = get_images_to_optimise(expanded_scene,expanded_scene_no_cells,expanded_resized, real_image, convolved, resize_amount)\n",
    "    simulated_means = np.array(get_intensity_means(perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask, expanded_resized))\n",
    "\n",
    "    perc_sum = sum(perc_diff(real_means, simulated_means))\n",
    "\n",
    "    if perc_sum < current_error:\n",
    "        current_error = perc_sum\n",
    "        print(current_error)\n",
    "        best_input.append(v)\n",
    "        OPL_image_convolved.append(expanded_resized)\n",
    "    \n",
    "    if return_diagnostics == True:\n",
    "        return expanded_resized, simulated_means, perc_sum\n",
    "    else:\n",
    "        if np.isnan(perc_sum):\n",
    "            return 100\n",
    "        else:\n",
    "            return perc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db630504-15b5-45d2-81e7-c7ce07003771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_function(np.array([-20,-1,20]), return_diagnostics = True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eface7cb-62fe-41de-8971-f6ae3df3309d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(objective_function(np.array([-20,-1,10]), return_diagnostics = True)[0], cmap=\"Greys_r\", vmax=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae16f7-8a7c-4ed0-954f-67653b13fab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(perm_expanded_cell_pseudo_mask*objective_function(np.array([-20,-1,20]), return_diagnostics = True)[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87599530-8f38-4f3b-917f-afed2dc010c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_intensity_means(perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask, objective_function(np.array([-20,-1,20]), return_diagnostics = True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7d0a0-3cb6-4e01-b178-2e604d18a45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "perc_diff = lambda a, b: abs(a-b)/abs((a+b)/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0617b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "progress = []\n",
    "def callbackF(x, f, context):\n",
    "    print(x)\n",
    "    progress.append(x)\n",
    "    \n",
    "def callbackSHGo(x):\n",
    "    print(x)\n",
    "    progress.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fbb71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bounds = list(zip([-500, -500, -500], [500.0, 500.0, 500.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff629a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ret = shgo(objective_function, bounds = np.array(bounds),callback=callbackSHGo,options={\"minimize_every_iter\":True})\n",
    "ret = dual_annealing(objective_function, bounds = np.array(bounds),callback=callbackF) # ,maxiter=10,initial_temp=5*10**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0cc47-57c0-45e6-88b1-89d5a67ae16a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret = basinhopping(objective_function, x0 = (0,0,0),callback=callbackF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2bed2-33a3-4351-af9a-500c0cfe74ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808fbde-39bf-433a-a33b-a35665a52956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret = differential_evolution(objective_function, bounds, popsize = 200, mutation = 1.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c24683-68a7-4956-a38d-b9aadb91fbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranges = [np.arange(-50,50, 5), np.arange(-50,50, 5), np.arange(-50,50, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512915d-0728-4730-9e0f-2337112bd2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = (list(itertools.product(*ranges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073e1c1-bd91-4341-9c02-aa1bb1a3431a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fd458-aa46-4927-b332-e765a936d708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.uniform(low=-1000,high=1000,size=(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cde0c3-407f-4433-81a2-84f2ab20209f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPL_image_convolved = []\n",
    "current_error = 10\n",
    "best_input = []\n",
    "a = 0\n",
    "while True:    \n",
    "    temp_output = objective_function(np.random.uniform(low=-1000,high=1000,size=(3)), True)\n",
    "    a+=1\n",
    "    if temp_output[1] < current_error:\n",
    "        current_error = temp_output[1]\n",
    "        print(current_error)\n",
    "        best_input.append(list(input_) + [3.9])\n",
    "        OPL_image_convolved.append(temp_output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a5014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(OPL_image_convolved[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8403999f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3704125e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "import sys\n",
    "sys.path.insert(0,'/home/georgeos/Documents/GitHub/SYMPTOMM2')\n",
    "from SYMPTOMM.cell import Cell\n",
    "from SYMPTOMM.scene_functions import create_space, step_and_update\n",
    "from SYMPTOMM.trench_geometry import trench_creator\n",
    "from SYMPTOMM.phase_contrast_drawing import *\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from skimage.exposure import rescale_intensity\n",
    "from ipywidgets import interactive\n",
    "import os\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "from SYMPTOMM.PSF import get_phase_contrast_kernel, get_condensers\n",
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(10,20)).zfill(3)))\n",
    "\n",
    "#viewer = napari.view_image(real_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64476ce1-d433-4a92-965a-6d8d0cf5534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/Lane_02_pos_002_trench_x_1963_y_0067_w_0046_h_0460_c_Phase.tif\")[0][:300,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa476171-0ee2-4c5c-af18-a7fdf33e9374",
   "metadata": {},
   "source": [
    "## FuncDefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30746946-f64c-48f0-bda8-5c454d7dfcb0",
   "metadata": {},
   "source": [
    "### Do large cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e81a7c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulation Progress: 100%|██████████| 270/270 [00:02<00:00, 119.31it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6da5b4ff704db2aafac2ae9170a875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Timeseries Properties:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a735e7421a144edb0ccb134914632b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scene Draw::   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_length = 20\n",
    "cell_timeseries, space = run_simulation(trench_length=15, trench_width=1.45, cell_max_length=4.7, cell_width=1.15, sim_length = sim_length) # growth phase\n",
    "#cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=1.45, cell_width=0.85, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=14)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties'))\n",
    "do_transformation = True\n",
    "offset = 10\n",
    "mask_threshold = 18\n",
    "label_masks = True\n",
    "space_size = get_space_size(cell_timeseries_properties)\n",
    "scenes = Parallel(n_jobs=-1)(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset, label_masks) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "034e81eb-89c7-4ea5-afcc-c078f2d18480",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_multiplier=-30\n",
    "cell_multiplier=-1\n",
    "device_multiplier=150\n",
    "\n",
    "\n",
    "condensers = get_condensers()\n",
    "W, R, diameter = condensers[\"Ph2\"]\n",
    "scale = 0.108379937 / 3 #0.35 #micron per pixel\n",
    "min_sigma = 0.42*0.6/6 / scale # micron#\n",
    "sigma=min_sigma\n",
    "radius=50\n",
    "F = 5\n",
    "λ = 0.75\n",
    "resize_amount = 1/scale/10\n",
    "kernel_params = (R,W,radius,scale,F,sigma,λ)\n",
    "\n",
    "\n",
    "\n",
    "temp_expanded_scene, temp_expanded_scene_no_cells, temp_expanded_mask = generate_PC_OPL(\n",
    "   main_segments=main_segments,\n",
    "    offset=50,\n",
    "    scene = scenes[0][0],\n",
    "    mask = scenes[0][1],\n",
    "    media_multiplier=1,\n",
    "    cell_multiplier=1,\n",
    "    device_multiplier=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "### Generate temporary image to make same shape\n",
    "temp_kernel = get_phase_contrast_kernel(*kernel_params)\n",
    "convolved = convolve_rescale(temp_expanded_scene, temp_kernel, 1/resize_amount, rescale_int = True)\n",
    "real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6eb54f0-ee62-4dd0-afcd-69374fbe6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(real_resize)\n",
    "media_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"media\")\n",
    "cell_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"cell\")\n",
    "device_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "402fc7cd-5c59-4702-b0b0-c3241cf707e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_media_mean = real_resize[np.where(media_label.data)].mean();\n",
    "real_cell_mean = real_resize[np.where(cell_label.data)].mean(); \n",
    "real_device_mean = real_resize[np.where(device_label.data)].mean()\n",
    "real_means = np.array((real_media_mean, real_cell_mean, real_device_mean))\n",
    "\n",
    "real_media_var = real_resize[np.where(media_label.data)].var();\n",
    "real_cell_var = real_resize[np.where(cell_label.data)].var(); \n",
    "real_device_var = real_resize[np.where(device_label.data)].var()\n",
    "real_vars = np.array((real_media_var, real_cell_var, real_device_var))\n",
    "\n",
    "image_params = (real_media_mean, real_cell_mean, real_device_mean, real_means, real_media_var, real_cell_var, real_device_var, real_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ef9f0e0-ec46-410a-ae01-60ef3caa87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "error_params = (mean_error,media_error,cell_error,device_error,mean_var_error,media_var_error,cell_var_error,device_var_error)\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=(scale,scale,scale),\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "    offset=fixed(offset),\n",
    "    main_segments = fixed(main_segments),\n",
    "    debug_plot=fixed(True),\n",
    "    scenes = fixed(scenes),\n",
    "    kernel_params = fixed(kernel_params),\n",
    "    resize_amount = fixed(resize_amount), \n",
    "    real_image = fixed(real_image),\n",
    "    image_params = fixed(image_params),\n",
    "    error_params = fixed(error_params)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46a8a43d-4bae-4630-8cdb-ac33f03181ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea4639aa33347a9a5211ef64f64b49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='media_multiplier', max=300, min=-300), FloatSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10830fe-3a9b-4ec7-a591-e1079693ea91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "005633aa-0587-4639-a40e-24cc202dad5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-45c67fbc9ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractive_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_amount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomise_hist_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomise_noise_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mburn_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/for_stardist_bent_histmatched/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/SYMPTOMM2/SYMPTOMM/phase_contrast_drawing.py\u001b[0m in \u001b[0;36mgenerate_training_data\u001b[0;34m(interactive_output, sample_amount, randomise_hist_match, randomise_noise_match, sim_length, burn_in, n_samples, save_dir)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractive_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_amount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomise_hist_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomise_noise_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mburn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mmedia_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_histogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractive_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0mdebug_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 11)"
     ]
    }
   ],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.01, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  5000, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/for_stardist_bent_histmatched/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695e753-539c-4365-b373-e38329014986",
   "metadata": {},
   "source": [
    "### Do medium cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312d5fb-ca93-4fcf-b322-c9a17ee866c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_length = 50\n",
    "cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=2.45, cell_width=1.0, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=-1)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties:'))\n",
    "do_transformation = False\n",
    "offset = 40\n",
    "mask_threshold = 25\n",
    "space_size = (1000,200)\n",
    "label_masks = True\n",
    "scenes = Parallel(n_jobs=-1, backend='multiprocessing')(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset, label_masks) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd965a-cc77-444a-aa0c-2b5fb0e30029",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=scale,\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "offset=(offset,offset,offset));\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcdd96-3e14-4e2b-b9ef-8f19ab5a5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.02, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  1000, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/for_stardist_bent_histmatched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9ba8f-bbea-4da8-8be0-1be158493b41",
   "metadata": {},
   "source": [
    "## Do small cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0a552-e91e-4175-93d1-a43462971fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_length = 100\n",
    "cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=1.45, cell_width=1.0, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=-1)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties:'))\n",
    "do_transformation = False\n",
    "offset = 40\n",
    "mask_threshold = 25\n",
    "space_size = (1000,200)\n",
    "label_masks = True\n",
    "scenes = Parallel(n_jobs=-1, backend='multiprocessing')(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset, label_masks) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f35ce-86a5-41f8-a1c7-210812aeb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=scale,\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "offset=(offset,offset,offset));\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545c16f-6cf4-40c8-9a86-e2acd5d943c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.02, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  200, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/for_stardist_bent_histmatched\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

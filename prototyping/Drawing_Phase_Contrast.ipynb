{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8403999f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3704125e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "import sys\n",
    "sys.path.insert(0,'/home/georgeos/Documents/GitHub/SYMPTOMM2')\n",
    "from SYMPTOMM.cell import Cell\n",
    "from SYMPTOMM.scene_functions import create_space, step_and_update\n",
    "from SYMPTOMM.trench_geometry import trench_creator\n",
    "from SYMPTOMM.phase_contrast_drawing import *\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "div_odd = lambda n: (n//2, n//2 + 1)\n",
    "perc_diff = lambda a, b: abs(a-b)/((a+b)/2)\n",
    "from skimage.exposure import rescale_intensity\n",
    "from ipywidgets import interactive\n",
    "import os\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(0,5)).zfill(3)))\n",
    "\n",
    "#viewer = napari.view_image(real_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64476ce1-d433-4a92-965a-6d8d0cf5534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/Lane_02_pos_002_trench_x_1963_y_0067_w_0046_h_0460_c_Phase.tif\")[0][:300,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa476171-0ee2-4c5c-af18-a7fdf33e9374",
   "metadata": {},
   "source": [
    "## FuncDefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11affddf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_simulation(trench_length, trench_width, cell_max_length, cell_width, sim_length):\n",
    "    \n",
    "    \n",
    "    space = create_space()\n",
    "    space.gravity = 0, 0 # arbitrasry units\n",
    "    dt = 1/100 #time-step per frame\n",
    "    pix_mic_conv = 10 # pixels per micron\n",
    "    scale_factor = pix_mic_conv * 3 # resolution scaling factor \n",
    "\n",
    "    trench_length = trench_length*scale_factor\n",
    "    trench_width = trench_width*scale_factor\n",
    "    trench_creator(trench_width,trench_length,(35,0),space) # Coordinates of bottom left corner of the trench\n",
    "    #trench_creator(35,trench_length,(35*3,0),space) # Coordinates of bottom left corner of the trench\n",
    "    #trench_creator(35,trench_length,(35*5,0),space) # Coordinates of bottom left corner of the trench\n",
    "\n",
    "    cell1 = Cell(\n",
    "        length = cell_max_length*scale_factor,  \n",
    "        width = cell_width*scale_factor, \n",
    "        resolution = 60, \n",
    "        position = (20+35,40), \n",
    "        angle = 0.8, \n",
    "        space = space,\n",
    "        dt = 1/60,\n",
    "        growth_rate_constant = 1,\n",
    "        max_length = cell_max_length*scale_factor,\n",
    "        max_length_mean =cell_max_length*scale_factor,\n",
    "        max_length_var = 0.5*np.sqrt(scale_factor),\n",
    "        width_var = 0.07*np.sqrt(scale_factor),\n",
    "        width_mean = cell_width*scale_factor\n",
    "    )\n",
    "\n",
    "\n",
    "    cells = [cell1]\n",
    "    cell_timeseries = []\n",
    "    phys_iters = 250\n",
    "    for x in tqdm(range(sim_length+250),desc=\"Simulation Progress\"):\n",
    "        cells = step_and_update(dt=dt, cells=cells, space=space, phys_iters=phys_iters,ylim=trench_length)\n",
    "        if x > 250:\n",
    "            cell_timeseries.append(deepcopy(cells))\n",
    "    return cell_timeseries, space\n",
    "\n",
    "\n",
    "def get_similarity_metrics(real_image,synthetic_image):\n",
    "    synthetic_image = match_histograms(synthetic_image, real_image, multichannel=False)\n",
    "    synthetic_image = resize(synthetic_image,real_image.shape,clip=False,preserve_range=False,anti_aliasing=None)\n",
    "    synthetic_image = synthetic_image/np.max(synthetic_image)\n",
    "    ssim_real = ssim(synthetic_image, real_image)\n",
    "    intersection = return_intersection_between_image_hists(synthetic_image, real_image, 100)\n",
    "    #sims \n",
    "    synthetic_image_ = deepcopy(synthetic_image)\n",
    "    synthetic_image_.shape += (1,)\n",
    "    \n",
    "    real_image_ = deepcopy(real_image)\n",
    "    real_image_.shape += (1,)\n",
    "    _fsim = fsim(synthetic_image_,real_image_)\n",
    "    _issm = issm(synthetic_image_,real_image_)\n",
    "    _sam = sam(synthetic_image_,real_image_)\n",
    "    _sre = sre(synthetic_image_,real_image_)\n",
    "    objs = [ssim_real, 0.5*intersection, _fsim, _issm, _sam, _sre/20]\n",
    "    return objs\n",
    "\n",
    "def generate_PC_OPL(main_segments, offset, scene, mask, media_multiplier,cell_multiplier,device_multiplier):\n",
    "    def get_OPL_image():\n",
    "        segment_1_top_left = (0 + offset, int(main_segments.iloc[0][\"bb\"][0] + offset))\n",
    "        segment_1_bottom_right = (int(main_segments.iloc[0][\"bb\"][3] + offset), int(main_segments.iloc[0][\"bb\"][2] + offset))\n",
    "\n",
    "        segment_2_top_left = (0 + offset, int(main_segments.iloc[1][\"bb\"][0] + offset))\n",
    "        segment_2_bottom_right = (int(main_segments.iloc[1][\"bb\"][3] + offset), int(main_segments.iloc[1][\"bb\"][2] + offset))\n",
    "\n",
    "        test_scene = np.zeros(scene.shape) + device_multiplier\n",
    "        rr, cc = draw.rectangle(start = segment_1_top_left, end = segment_1_bottom_right, shape = test_scene.shape)\n",
    "        test_scene[rr,cc] = 1 * media_multiplier\n",
    "        rr, cc = draw.rectangle(start = segment_2_top_left, end = segment_2_bottom_right, shape = test_scene.shape)\n",
    "        test_scene[rr,cc] = 1 * media_multiplier\n",
    "        circ_midpoint_y = (segment_1_top_left[1] + segment_2_bottom_right[1])/2\n",
    "        radius = (segment_1_top_left[1] - offset - (segment_2_bottom_right[1] - offset))/2\n",
    "        circ_midpoint_x = (offset) + radius\n",
    "\n",
    "        rr, cc = draw.rectangle(start = segment_2_top_left, end = (circ_midpoint_x,segment_1_top_left[1]), shape = test_scene.shape)\n",
    "        test_scene[rr.astype(int),cc.astype(int)] = 1 * media_multiplier\n",
    "        rr, cc = draw.disk(center = (circ_midpoint_x, circ_midpoint_y), radius = radius, shape = test_scene.shape)\n",
    "        rr_semi = rr[rr < (circ_midpoint_x + 1)]\n",
    "        cc_semi = cc[rr < (circ_midpoint_x + 1)]\n",
    "        test_scene[rr_semi,cc_semi] = device_multiplier\n",
    "        no_cells = deepcopy(test_scene)\n",
    "        test_scene += scene * cell_multiplier\n",
    "        test_scene = test_scene[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "        mask_resized = mask[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "        \n",
    "        no_cells = no_cells[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "        expanded_scene_no_cells = np.zeros((int(no_cells.shape[0]*1.2), no_cells.shape[1]*2)) + media_multiplier\n",
    "        expanded_scene_no_cells[expanded_scene_no_cells.shape[0] - no_cells.shape[0]:,int(no_cells.shape[1]/2):int(no_cells.shape[1]/2) + no_cells.shape[1]] = no_cells\n",
    "\n",
    "        expanded_scene = np.zeros((int(test_scene.shape[0]*1.2), test_scene.shape[1]*2)) + media_multiplier\n",
    "        expanded_scene[expanded_scene.shape[0] - test_scene.shape[0]:,int(test_scene.shape[1]/2):int(test_scene.shape[1]/2) + test_scene.shape[1]] = test_scene\n",
    "        \n",
    "        expanded_mask = np.zeros((int(test_scene.shape[0]*1.2), test_scene.shape[1]*2))\n",
    "        expanded_mask[expanded_mask.shape[0] - test_scene.shape[0]:,int(test_scene.shape[1]/2):int(test_scene.shape[1]/2) + test_scene.shape[1]] = mask_resized\n",
    "        \n",
    "        return expanded_scene, expanded_scene_no_cells, expanded_mask\n",
    "    expanded_scene, expanded_scene_no_cells, expanded_mask = get_OPL_image()\n",
    "    if expanded_scene is None:\n",
    "        main_segments = main_segments.reindex(index=main_segments.index[::-1])\n",
    "        expanded_scene, expanded_scene_no_cells, expanded_mask = get_OPL_image()\n",
    "    return expanded_scene, expanded_scene_no_cells, expanded_mask\n",
    "\n",
    "def convolve_rescale(image,kernel,rescale_factor, rescale_int):\n",
    "    output = cuconvolve(cp.array(image),cp.array(kernel))\n",
    "    output = output.get()\n",
    "    output = rescale(output, rescale_factor, anti_aliasing=False)\n",
    "    \n",
    "    if rescale_int:\n",
    "        output = rescale_intensity(output.astype(np.float32), out_range=(0,1))\n",
    "    return output\n",
    "\n",
    "#make convolved image and real image same shape\n",
    "def make_images_same_shape(real_image,synthetic_image, rescale_int = True):\n",
    "    x_diff = synthetic_image.shape[1] - real_image.shape[1]\n",
    "    remove_from_left, remove_from_right = div_odd(x_diff)\n",
    "    y_diff = synthetic_image.shape[0] - real_image.shape[0]\n",
    "    if y_diff > 0:\n",
    "        synthetic_image = synthetic_image[y_diff:,remove_from_left-1:-remove_from_right]\n",
    "    else:\n",
    "        synthetic_image = synthetic_image[:,remove_from_left:-remove_from_right]\n",
    "        real_image = real_image[abs(y_diff):,:]\n",
    "\n",
    "    if rescale_int:\n",
    "        real_image = rescale_intensity(real_image.astype(np.float32), out_range=(0,1))\n",
    "        synthetic_image = rescale_intensity(synthetic_image.astype(np.float32), out_range=(0,1))\n",
    "    return real_image, synthetic_image\n",
    "\n",
    "def generate_test_comparison(media_multiplier, cell_multiplier, device_multiplier, sigma, scene_no, scale, match_histogram, match_noise, offset, debug_plot=True, noise_var=0.002):\n",
    "    \n",
    "    \n",
    "    expanded_scene, expanded_scene_no_cells, expanded_mask = generate_PC_OPL(\n",
    "        main_segments=main_segments,\n",
    "        offset=offset,\n",
    "        scene = scenes[scene_no][0],\n",
    "        mask = scenes[scene_no][1],\n",
    "        media_multiplier=media_multiplier,\n",
    "        cell_multiplier=cell_multiplier,\n",
    "        device_multiplier=device_multiplier\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, sigma, 0.75)\n",
    "\n",
    "\n",
    "\n",
    "    convolved = convolve_rescale(expanded_scene, kernel, 1/resize_amount, rescale_int = True)\n",
    "    real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "    \n",
    "    \n",
    "    if match_histogram:\n",
    "        matched = match_histograms(expanded_resized, real_resize, multichannel=False)\n",
    "    else:\n",
    "        matched = expanded_resized\n",
    "    \n",
    "    \n",
    "    noisy_img = random_noise(rescale_intensity(matched), mode=\"poisson\")\n",
    "    noisy_img = random_noise(rescale_intensity(noisy_img), mode=\"gaussian\", mean=0,var=noise_var,clip=False)\n",
    "    \n",
    "    if match_noise:\n",
    "        noisy_img = match_histograms(noisy_img, real_resize, multichannel=False)\n",
    "    else:\n",
    "        pass\n",
    "    noisy_img = rescale_intensity(noisy_img.astype(np.float32), out_range=(0,1))\n",
    "    \n",
    "    ## getting the cell mask to the right shape\n",
    "    expanded_mask_resized = rescale(expanded_mask, 1/resize_amount, anti_aliasing=False)\n",
    "    _, expanded_mask_resized_reshaped = make_images_same_shape(real_image,expanded_mask_resized, rescale_int=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    expanded_media_mask = rescale((expanded_scene_no_cells == device_multiplier) ^ (expanded_scene - expanded_scene_no_cells).astype(bool) , 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_media_mask = make_images_same_shape(real_image,expanded_media_mask, rescale_int=True)\n",
    "    just_media = expanded_media_mask * noisy_img\n",
    "    \n",
    "    expanded_cell_pseudo_mask = (expanded_scene - expanded_scene_no_cells).astype(bool)\n",
    "    expanded_cell_pseudo_mask = rescale(expanded_cell_pseudo_mask, 1/resize_amount, anti_aliasing=False)\n",
    "\n",
    "    real_resize, expanded_cell_pseudo_mask = make_images_same_shape(real_image,expanded_cell_pseudo_mask, rescale_int=True)\n",
    "    just_cells = expanded_cell_pseudo_mask * noisy_img\n",
    "    \n",
    "    expanded_device_mask = expanded_scene_no_cells == media_multiplier\n",
    "    expanded_device_mask = rescale(expanded_device_mask, 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_device_mask = make_images_same_shape(real_image,expanded_device_mask, rescale_int=True)\n",
    "    just_device = expanded_device_mask * noisy_img\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    simulated_means = np.array([just_media[np.where(just_media)].mean(), just_cells[np.where(just_cells)].mean(), just_device[np.where(just_device)].mean()])\n",
    "    simulated_vars = np.array([just_media[np.where(just_media)].var(), just_cells[np.where(just_cells)].var(), just_device[np.where(just_device)].var()])\n",
    "\n",
    "    \n",
    "    \n",
    "    mean_error.append(np.mean(perc_diff(real_means, simulated_means)))\n",
    "    media_error.append(perc_diff(simulated_means[0], real_media_mean))\n",
    "    cell_error.append(perc_diff(simulated_means[1], real_cell_mean))\n",
    "    device_error.append(perc_diff(simulated_means[2], real_device_mean))\n",
    "    \n",
    "    \n",
    "    mean_var_error.append(np.mean(perc_diff(real_vars, simulated_vars)))\n",
    "    media_var_error.append(perc_diff(simulated_vars[0], real_media_var))\n",
    "    cell_var_error.append(perc_diff(simulated_vars[1], real_cell_var))\n",
    "    device_var_error.append(perc_diff(simulated_vars[2], real_device_var))\n",
    "    if debug_plot == True:\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax1 = plt.subplot2grid((1,8),(0,0),colspan=1,rowspan=1)\n",
    "        ax2 = plt.subplot2grid((1,8),(0,1),colspan=1,rowspan=1)\n",
    "        ax3 = plt.subplot2grid((1,8),(0,2),colspan=3,rowspan=1)\n",
    "        ax4 = plt.subplot2grid((1,8),(0,5),colspan=3,rowspan=1)\n",
    "        ax1.imshow(noisy_img,cmap=\"Greys_r\")\n",
    "        ax1.set_title(\"Synthetic\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(real_resize,cmap=\"Greys_r\")\n",
    "        ax2.set_title(\"Real\")\n",
    "        ax2.axis(\"off\")\n",
    "        ax3.plot(mean_error)\n",
    "        ax3.plot(media_error)\n",
    "        ax3.plot(cell_error)\n",
    "        ax3.plot(device_error)\n",
    "        ax3.legend([\"Mean error\", \"Media error\", \"Cell error\", \"Device error\"])\n",
    "        ax3.set_title(\"Intensity Error\")\n",
    "\n",
    "        ax4.plot(mean_var_error)\n",
    "        ax4.plot(media_var_error)\n",
    "        ax4.plot(cell_var_error)\n",
    "        ax4.plot(device_var_error)\n",
    "        ax4.legend([\"Mean error\", \"Media error\", \"Cell error\", \"Device error\"])\n",
    "        ax4.set_title(\"Variance Error\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    else:\n",
    "        return noisy_img, expanded_mask_resized_reshaped\n",
    "\n",
    "def get_space_size(cell_timeseries_properties):\n",
    "    \"\"\"Iterates through the simulation timeseries properties, \n",
    "    finds the extreme cell positions and retrieves the required \n",
    "    image size to fit all cells into\"\"\"\n",
    "    max_x, max_y = 0, 0\n",
    "    for timepoint in cell_timeseries_properties:\n",
    "        for cell in timepoint:\n",
    "            x_, y_ = np.ceil(cell[3]).astype(int)\n",
    "            length_ = np.ceil(cell[0]).astype(int)\n",
    "            width_ = np.ceil(cell[1]).astype(int)\n",
    "            max_y_ = y_ + length_\n",
    "            max_x_ = x_ + width_\n",
    "            if max_x_ > max_x:\n",
    "                max_x = max_x_\n",
    "            if max_y_ > max_y:\n",
    "                max_y = max_y_\n",
    "    return (int(1.2*max_y), int(1.5*max_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30746946-f64c-48f0-bda8-5c454d7dfcb0",
   "metadata": {},
   "source": [
    "### Do large cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e81a7c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f46e94899b41b197808701f5a7c253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simulation Progress:   0%|          | 0/1750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2085ad178ee149c9974eb82307dfd46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Timeseries Properties::   0%|          | 0/1499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98aa2e2048fe45b0a8b7dd88519efb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scene Draw::   0%|          | 0/1499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_length = 1500\n",
    "cell_timeseries, space = run_simulation(trench_length=15, trench_width=1.45, cell_max_length=5.5, cell_width=1.05, sim_length = sim_length) # growth phase\n",
    "#cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=1.45, cell_width=0.85, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=14)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties:'))\n",
    "do_transformation = True\n",
    "offset = 5\n",
    "mask_threshold = 17\n",
    "space_size = get_space_size(cell_timeseries_properties)\n",
    "scenes = Parallel(n_jobs=14)(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adfcae2d-e685-4232-8cbe-df78a86d2a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f410cdc8af0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(scenes[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "034e81eb-89c7-4ea5-afcc-c078f2d18480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:napari_ndtiffs.affine:Could not import pyopencl. Falling back to scipy for CPU affine transforms\n"
     ]
    }
   ],
   "source": [
    "media_multiplier=-30\n",
    "cell_multiplier=-1\n",
    "device_multiplier=150\n",
    "\n",
    "\n",
    "condensers = get_condensers()\n",
    "W, R, diameter = condensers[\"Ph2\"]\n",
    "scale = 0.108379937 / 3 #0.35 #micron per pixel\n",
    "min_sigma = 0.42*0.6/6 / scale # micron\n",
    "\n",
    "resize_amount = 1/scale/10\n",
    "\n",
    "\n",
    "\n",
    "temp_expanded_scene, temp_expanded_scene_no_cells, temp_expanded_mask = generate_PC_OPL(\n",
    "    main_segments=main_segments,\n",
    "    offset=50,\n",
    "    scene = scenes[0][0],\n",
    "    mask = scenes[0][1],\n",
    "    media_multiplier=1,\n",
    "    cell_multiplier=1,\n",
    "    device_multiplier=1\n",
    ")\n",
    "\n",
    "temp_kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, min_sigma, 0.75)\n",
    "\n",
    "\n",
    "\n",
    "convolved = convolve_rescale(temp_expanded_scene, temp_kernel, 1/resize_amount, rescale_int = True)\n",
    "real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "\n",
    "viewer = napari.view_image(real_resize)\n",
    "media_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"media\")\n",
    "cell_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"cell\")\n",
    "device_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "402fc7cd-5c59-4702-b0b0-c3241cf707e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_media_mean = real_resize[np.where(media_label.data)].mean();\n",
    "real_cell_mean = real_resize[np.where(cell_label.data)].mean(); \n",
    "real_device_mean = real_resize[np.where(device_label.data)].mean()\n",
    "real_means = np.array((real_media_mean, real_cell_mean, real_device_mean))\n",
    "\n",
    "real_media_var = real_resize[np.where(media_label.data)].var();\n",
    "real_cell_var = real_resize[np.where(cell_label.data)].var(); \n",
    "real_device_var = real_resize[np.where(device_label.data)].var()\n",
    "real_vars = np.array((real_media_var, real_cell_var, real_device_var))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ef9f0e0-ec46-410a-ae01-60ef3caa87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=scale,\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "offset=(offset,offset,offset));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6836af3-3e30-4e62-8dcb-2f1cd7900c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663c289a3757468a8b7fa9a198c95ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='media_multiplier', max=300, min=-300), FloatSlider(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ed7086c-92a7-4e94-b2fe-2984c42412d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([54, 2.8, -58, 3.19709, 1361, 0.036126645666666665, True, True, 5, True, 0.0001])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.kwargs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5874dbde-ddfe-41ee-8059-99c93a2cf732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(interactive_output, sample_amount, randomise_hist_match, randomise_noise_match, sim_length, burn_in, n_samples, save_dir):\n",
    "    media_multiplier, cell_multiplier, device_multiplier, sigma, scene_no, scale, match_histogram, match_noise, offset, debug_plot, noise_var = list(interactive_output.kwargs.values())\n",
    "    debug_plot = False\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(save_dir + \"/convolutions\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(save_dir + \"/masks\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    current_file_num = len(os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/convolutions\"))\n",
    "    #for z in range(n_samples):\n",
    "    def generate_samples(z):\n",
    "        _media_multiplier = np.random.uniform(1-sample_amount,1+sample_amount) * media_multiplier\n",
    "        _cell_multiplier = np.random.uniform(1-sample_amount,1+sample_amount) * cell_multiplier\n",
    "        _device_multiplier = np.random.uniform(1-sample_amount,1+sample_amount) * device_multiplier\n",
    "        _sigma = np.random.uniform(1-sample_amount,1+sample_amount) * sigma\n",
    "        _scene_no = np.random.randint(burn_in,sim_length-2)\n",
    "        _noise_var = np.random.uniform(1-sample_amount,1+sample_amount) * noise_var\n",
    "        if randomise_hist_match:\n",
    "            _match_histogram = np.random.choice([True, False])\n",
    "        if randomise_noise_match:\n",
    "            _match_noise = np.random.choice([True, False])\n",
    "        \n",
    "        syn_image, mask = generate_test_comparison(_media_multiplier, _cell_multiplier, _device_multiplier, _sigma, _scene_no, scale, _match_histogram, match_noise, debug_plot, noise_var)\n",
    "        \n",
    "        syn_image = Image.fromarray(skimage.img_as_uint(rescale_intensity(syn_image)))\n",
    "        syn_image.save(\"{}/convolutions/synth_{}.tif\".format(save_dir, str(z).zfill(4)))\n",
    "        mask = Image.fromarray(mask)\n",
    "        mask.save(\"{}/masks/synth_{}.tif\".format(save_dir, str(z).zfill(4)))        \n",
    "    ## TODO: change parallel if not using GPU\n",
    "    Parallel(n_jobs=1)(delayed(generate_samples)(z) for z in tqdm(range(current_file_num,n_samples+current_file_num), desc=\"Sample generation:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "005633aa-0587-4639-a40e-24cc202dad5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6119cbfa13a47f9b36c1e2a68119811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.095, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  5000, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695e753-539c-4365-b373-e38329014986",
   "metadata": {},
   "source": [
    "### Do small cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d9a10de-1304-47a8-a5dd-202bc894f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scene(cell_properties, do_transformation, mask_threshold, space_size, offset):\n",
    "    space_size = np.array(space_size) # 1000, 200 a good value\n",
    "    space = np.zeros(space_size)\n",
    "    space_masks = np.zeros(space_size)\n",
    "    offsets = offset \n",
    "    for properties in cell_properties:\n",
    "        length, width, angle, position, freq_modif, amp_modif, phase_modif,phase_mult = properties\n",
    "        length = length; width = width ; position = np.array(position) \n",
    "        angle = np.rad2deg(angle) - 90\n",
    "        x, y = np.array(position).astype(int) + offsets\n",
    "        OPL_cell = raster_cell(length = length, width=width)\n",
    "        \n",
    "        if do_transformation:\n",
    "            OPL_cell_2 = np.zeros((OPL_cell.shape[0],int(OPL_cell.shape[1]*2)))\n",
    "            midpoint = int(np.median(range(OPL_cell_2.shape[1])))\n",
    "            OPL_cell_2[:,midpoint-int(OPL_cell.shape[1]/2):midpoint-int(OPL_cell.shape[1]/2)+OPL_cell.shape[1]] = OPL_cell\n",
    "            roll_coords = np.array(range(OPL_cell_2.shape[0]))\n",
    "            freq_mult = (OPL_cell_2.shape[0])\n",
    "            amp_mult = OPL_cell_2.shape[1]/10\n",
    "            sin_transform_cell = transform_func(amp_modif, freq_modif, phase_modif)\n",
    "            roll_amounts = sin_transform_cell(roll_coords,amp_mult,freq_mult,phase_mult)\n",
    "            for B in roll_coords:\n",
    "                OPL_cell_2[B,:] = np.roll(OPL_cell_2[B,:], roll_amounts[B])\n",
    "            OPL_cell = (OPL_cell_2)\n",
    "        \n",
    "        rotated_OPL_cell = rotate(OPL_cell,angle,resize=True,clip=False,preserve_range=True)\n",
    "        cell_y, cell_x = (np.array(rotated_OPL_cell.shape)/2).astype(int)\n",
    "        offset_y = rotated_OPL_cell.shape[0] - space[y-cell_y:y+cell_y,x-cell_x:x+cell_x].shape[0]\n",
    "        offset_x = rotated_OPL_cell.shape[1] - space[y-cell_y:y+cell_y,x-cell_x:x+cell_x].shape[1]\n",
    "        assert y > cell_y, \"Cell has {} negative pixels in y coordinate, try increasing your offset\".format(y - cell_y)\n",
    "        assert x > cell_x, \"Cell has negative pixels in x coordinate, try increasing your offset\"\n",
    "        try:\n",
    "            space[\n",
    "                y-cell_y:y+cell_y+offset_y,\n",
    "                x-cell_x:x+cell_x+offset_x\n",
    "            ] += rotated_OPL_cell\n",
    "            space_masks[y-cell_y:y+cell_y+offset_y,x-cell_x:x+cell_x+offset_x] += (rotated_OPL_cell > mask_threshold)\n",
    "            space_masks = space_masks == 1\n",
    "        except:\n",
    "            print(f\"{y=}\")\n",
    "            print(f\"{cell_y=}\")\n",
    "            print(f\"{offset_y=}\")\n",
    "            print(f\"{x=}\")\n",
    "            print(f\"{cell_x=}\")\n",
    "            print(f\"{offset_x=}\")\n",
    "            break\n",
    "\n",
    "        #space_masks = opening(space_masks,np.ones((2,11)))\n",
    "    return space, space_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312d5fb-ca93-4fcf-b322-c9a17ee866c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2744a4eee7254f80b0144c4ce2ed5216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scene Draw::   0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sim_length = 500\n",
    "#cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=1.45, cell_width=0.85, sim_length = sim_length) # stationary phase\n",
    "#main_segments = get_trench_segments(space)\n",
    "#ID_props = generate_curve_props(cell_timeseries)\n",
    "#cell_timeseries_properties = Parallel(n_jobs=-1)(\n",
    "#    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties:'))\n",
    "#do_transformation = True\n",
    "offset = 20\n",
    "mask_threshold = 17\n",
    "space_size = (1000,200)\n",
    "scenes = Parallel(n_jobs=14, backend='multiprocessing')(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99bd965a-cc77-444a-aa0c-2b5fb0e30029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(658, 147)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_space_size(cell_timeseries_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcdd96-3e14-4e2b-b9ef-8f19ab5a5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.095, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  120, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886209b-3b9e-4daf-9161-498fab1ecfa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_images_to_optimise(expanded_scene,expanded_scene_no_cells,expanded_resized, real_image, convolved, resize_amount):\n",
    "    expanded_media_mask = rescale((expanded_scene_no_cells == device_multiplier) ^ (expanded_scene - expanded_scene_no_cells).astype(bool) , 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_media_mask = make_images_same_shape(real_image,expanded_media_mask, rescale_int=True)\n",
    "    just_media = expanded_media_mask * expanded_resized\n",
    "    \n",
    "    expanded_cell_pseudo_mask = (expanded_scene - expanded_scene_no_cells).astype(bool)\n",
    "    expanded_cell_pseudo_mask = rescale(expanded_cell_pseudo_mask, 1/resize_amount, anti_aliasing=False)\n",
    "\n",
    "    real_resize, expanded_cell_pseudo_mask = make_images_same_shape(real_image,expanded_cell_pseudo_mask, rescale_int=True)\n",
    "    just_cells = expanded_cell_pseudo_mask * expanded_resized\n",
    "    \n",
    "    expanded_device_mask = expanded_scene_no_cells == media_multiplier\n",
    "    expanded_device_mask = rescale(expanded_device_mask, 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_device_mask = make_images_same_shape(real_image,expanded_device_mask, rescale_int=True)\n",
    "    just_device = expanded_device_mask * expanded_resized\n",
    "    \n",
    "    return just_media, just_cells, just_device, expanded_media_mask, expanded_cell_pseudo_mask, expanded_device_mask\n",
    "\n",
    "just_media, just_cells, just_device, perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask = get_images_to_optimise(expanded_scene,expanded_scene_no_cells,expanded_resized, real_image, convolved, resize_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4872d-44c8-4bd4-9df2-1f481701b261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_intensity_means(perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask, expanded_resized):\n",
    "    return (perm_expanded_media_mask * expanded_resized).mean(), (perm_expanded_cell_pseudo_mask * expanded_resized).mean(), (perm_expanded_device_mask * expanded_resized).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1be0b7-0723-41e1-afad-dee308759e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPL_image_convolved = []\n",
    "global current_error\n",
    "current_error = 10\n",
    "best_input = []\n",
    "\n",
    "def objective_function(v, return_diagnostics = False):\n",
    "    global current_error\n",
    "    media_multiplier, cell_multiplier, device_multiplier= v\n",
    "    expanded_scene, expanded_scene_no_cells, expanded_mask = generate_PC_OPL(\n",
    "    main_segments=main_segments,\n",
    "    offset=50,\n",
    "    scene = scenes[4][0],\n",
    "    mask = scenes[4][1],\n",
    "    media_multiplier=media_multiplier,\n",
    "    cell_multiplier=cell_multiplier,\n",
    "    device_multiplier=device_multiplier\n",
    "    )\n",
    "\n",
    "\n",
    "    resize_amount = 1/scale/10\n",
    "\n",
    "    ## Creating the synthetic image\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, 7, 0.6)\n",
    "    convolved = convolve_rescale(expanded_scene, kernel, resize_amount, rescale_int = True)\n",
    "    real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "\n",
    "    ## getting the cell mask to the right shape\n",
    "    expanded_mask_resized = rescale(expanded_mask,1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_mask_resized_reshaped = make_images_same_shape(real_image,expanded_mask_resized, rescale_int=True)\n",
    "    _, _, _, perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask = get_images_to_optimise(expanded_scene,expanded_scene_no_cells,expanded_resized, real_image, convolved, resize_amount)\n",
    "    simulated_means = np.array(get_intensity_means(perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask, expanded_resized))\n",
    "\n",
    "    perc_sum = sum(perc_diff(real_means, simulated_means))\n",
    "\n",
    "    if perc_sum < current_error:\n",
    "        current_error = perc_sum\n",
    "        print(current_error)\n",
    "        best_input.append(v)\n",
    "        OPL_image_convolved.append(expanded_resized)\n",
    "    \n",
    "    if return_diagnostics == True:\n",
    "        return expanded_resized, simulated_means, perc_sum\n",
    "    else:\n",
    "        if np.isnan(perc_sum):\n",
    "            return 100\n",
    "        else:\n",
    "            return perc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db630504-15b5-45d2-81e7-c7ce07003771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_function(np.array([-20,-1,20]), return_diagnostics = True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eface7cb-62fe-41de-8971-f6ae3df3309d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(objective_function(np.array([-20,-1,10]), return_diagnostics = True)[0], cmap=\"Greys_r\", vmax=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae16f7-8a7c-4ed0-954f-67653b13fab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(perm_expanded_cell_pseudo_mask*objective_function(np.array([-20,-1,20]), return_diagnostics = True)[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87599530-8f38-4f3b-917f-afed2dc010c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_intensity_means(perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask, objective_function(np.array([-20,-1,20]), return_diagnostics = True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7d0a0-3cb6-4e01-b178-2e604d18a45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "perc_diff = lambda a, b: abs(a-b)/abs((a+b)/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0617b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "progress = []\n",
    "def callbackF(x, f, context):\n",
    "    print(x)\n",
    "    progress.append(x)\n",
    "    \n",
    "def callbackSHGo(x):\n",
    "    print(x)\n",
    "    progress.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fbb71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bounds = list(zip([-500, -500, -500], [500.0, 500.0, 500.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff629a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ret = shgo(objective_function, bounds = np.array(bounds),callback=callbackSHGo,options={\"minimize_every_iter\":True})\n",
    "ret = dual_annealing(objective_function, bounds = np.array(bounds),callback=callbackF) # ,maxiter=10,initial_temp=5*10**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0cc47-57c0-45e6-88b1-89d5a67ae16a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret = basinhopping(objective_function, x0 = (0,0,0),callback=callbackF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2bed2-33a3-4351-af9a-500c0cfe74ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808fbde-39bf-433a-a33b-a35665a52956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret = differential_evolution(objective_function, bounds, popsize = 200, mutation = 1.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c24683-68a7-4956-a38d-b9aadb91fbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranges = [np.arange(-50,50, 5), np.arange(-50,50, 5), np.arange(-50,50, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512915d-0728-4730-9e0f-2337112bd2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = (list(itertools.product(*ranges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073e1c1-bd91-4341-9c02-aa1bb1a3431a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fd458-aa46-4927-b332-e765a936d708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.uniform(low=-1000,high=1000,size=(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cde0c3-407f-4433-81a2-84f2ab20209f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPL_image_convolved = []\n",
    "current_error = 10\n",
    "best_input = []\n",
    "a = 0\n",
    "while True:    \n",
    "    temp_output = objective_function(np.random.uniform(low=-1000,high=1000,size=(3)), True)\n",
    "    a+=1\n",
    "    if temp_output[1] < current_error:\n",
    "        current_error = temp_output[1]\n",
    "        print(current_error)\n",
    "        best_input.append(list(input_) + [3.9])\n",
    "        OPL_image_convolved.append(temp_output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a5014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(OPL_image_convolved[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

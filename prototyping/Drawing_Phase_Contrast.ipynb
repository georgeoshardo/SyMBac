{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8403999f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3704125e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "import sys\n",
    "sys.path.insert(0,'/home/georgeos/Documents/GitHub/SYMPTOMM2')\n",
    "from SYMPTOMM.cell import Cell\n",
    "from SYMPTOMM.scene_functions import create_space, step_and_update\n",
    "from SYMPTOMM.trench_geometry import trench_creator\n",
    "from SYMPTOMM.phase_contrast_drawing import *\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "div_odd = lambda n: (n//2, n//2 + 1)\n",
    "perc_diff = lambda a, b: abs(a-b)/((a+b)/2)\n",
    "from skimage.exposure import rescale_intensity\n",
    "from ipywidgets import interactive\n",
    "import os\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "\n",
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(0,5)).zfill(3)))\n",
    "\n",
    "#viewer = napari.view_image(real_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64476ce1-d433-4a92-965a-6d8d0cf5534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/Lane_02_pos_002_trench_x_1963_y_0067_w_0046_h_0460_c_Phase.tif\")[0][:300,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa476171-0ee2-4c5c-af18-a7fdf33e9374",
   "metadata": {},
   "source": [
    "## FuncDefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11affddf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_simulation(trench_length, trench_width, cell_max_length, cell_width, sim_length):\n",
    "    \n",
    "    \n",
    "    space = create_space()\n",
    "    space.gravity = 0, 0 # arbitrasry units\n",
    "    dt = 1/100 #time-step per frame\n",
    "    pix_mic_conv = 10 # pixels per micron\n",
    "    scale_factor = pix_mic_conv * 3 # resolution scaling factor \n",
    "\n",
    "    trench_length = trench_length*scale_factor\n",
    "    trench_width = trench_width*scale_factor\n",
    "    trench_creator(trench_width,trench_length,(35,0),space) # Coordinates of bottom left corner of the trench\n",
    "    #trench_creator(35,trench_length,(35*3,0),space) # Coordinates of bottom left corner of the trench\n",
    "    #trench_creator(35,trench_length,(35*5,0),space) # Coordinates of bottom left corner of the trench\n",
    "\n",
    "    cell1 = Cell(\n",
    "        length = cell_max_length*scale_factor,  \n",
    "        width = cell_width*scale_factor, \n",
    "        resolution = 60, \n",
    "        position = (20+35,40), \n",
    "        angle = 0.8, \n",
    "        space = space,\n",
    "        dt = 1/60,\n",
    "        growth_rate_constant = 1,\n",
    "        max_length = cell_max_length*scale_factor,\n",
    "        max_length_mean =cell_max_length*scale_factor,\n",
    "        max_length_var = 0.5*np.sqrt(scale_factor),\n",
    "        width_var = 0.07*np.sqrt(scale_factor),\n",
    "        width_mean = cell_width*scale_factor\n",
    "    )\n",
    "\n",
    "\n",
    "    cells = [cell1]\n",
    "    cell_timeseries = []\n",
    "    phys_iters = 250\n",
    "    for x in tqdm(range(sim_length+250),desc=\"Simulation Progress\"):\n",
    "        cells = step_and_update(dt=dt, cells=cells, space=space, phys_iters=phys_iters,ylim=trench_length)\n",
    "        if x > 250:\n",
    "            cell_timeseries.append(deepcopy(cells))\n",
    "    return cell_timeseries, space\n",
    "\n",
    "\n",
    "def get_similarity_metrics(real_image,synthetic_image):\n",
    "    synthetic_image = match_histograms(synthetic_image, real_image, multichannel=False)\n",
    "    synthetic_image = resize(synthetic_image,real_image.shape,clip=False,preserve_range=False,anti_aliasing=None)\n",
    "    synthetic_image = synthetic_image/np.max(synthetic_image)\n",
    "    ssim_real = ssim(synthetic_image, real_image)\n",
    "    intersection = return_intersection_between_image_hists(synthetic_image, real_image, 100)\n",
    "    #sims \n",
    "    synthetic_image_ = deepcopy(synthetic_image)\n",
    "    synthetic_image_.shape += (1,)\n",
    "    \n",
    "    real_image_ = deepcopy(real_image)\n",
    "    real_image_.shape += (1,)\n",
    "    _fsim = fsim(synthetic_image_,real_image_)\n",
    "    _issm = issm(synthetic_image_,real_image_)\n",
    "    _sam = sam(synthetic_image_,real_image_)\n",
    "    _sre = sre(synthetic_image_,real_image_)\n",
    "    objs = [ssim_real, 0.5*intersection, _fsim, _issm, _sam, _sre/20]\n",
    "    return objs\n",
    "\n",
    "def generate_PC_OPL(main_segments, offset, scene, mask, media_multiplier,cell_multiplier,device_multiplier):\n",
    "    def get_OPL_image():\n",
    "        segment_1_top_left = (0 + offset, int(main_segments.iloc[0][\"bb\"][0] + offset))\n",
    "        segment_1_bottom_right = (int(main_segments.iloc[0][\"bb\"][3] + offset), int(main_segments.iloc[0][\"bb\"][2] + offset))\n",
    "\n",
    "        segment_2_top_left = (0 + offset, int(main_segments.iloc[1][\"bb\"][0] + offset))\n",
    "        segment_2_bottom_right = (int(main_segments.iloc[1][\"bb\"][3] + offset), int(main_segments.iloc[1][\"bb\"][2] + offset))\n",
    "\n",
    "        test_scene = np.zeros(scene.shape) + device_multiplier\n",
    "        rr, cc = draw.rectangle(start = segment_1_top_left, end = segment_1_bottom_right, shape = test_scene.shape)\n",
    "        test_scene[rr,cc] = 1 * media_multiplier\n",
    "        rr, cc = draw.rectangle(start = segment_2_top_left, end = segment_2_bottom_right, shape = test_scene.shape)\n",
    "        test_scene[rr,cc] = 1 * media_multiplier\n",
    "        circ_midpoint_y = (segment_1_top_left[1] + segment_2_bottom_right[1])/2\n",
    "        radius = (segment_1_top_left[1] - offset - (segment_2_bottom_right[1] - offset))/2\n",
    "        circ_midpoint_x = (offset) + radius\n",
    "\n",
    "        rr, cc = draw.rectangle(start = segment_2_top_left, end = (circ_midpoint_x,segment_1_top_left[1]), shape = test_scene.shape)\n",
    "        test_scene[rr.astype(int),cc.astype(int)] = 1 * media_multiplier\n",
    "        rr, cc = draw.disk(center = (circ_midpoint_x, circ_midpoint_y), radius = radius, shape = test_scene.shape)\n",
    "        rr_semi = rr[rr < (circ_midpoint_x + 1)]\n",
    "        cc_semi = cc[rr < (circ_midpoint_x + 1)]\n",
    "        test_scene[rr_semi,cc_semi] = device_multiplier\n",
    "        no_cells = deepcopy(test_scene)\n",
    "        test_scene += scene * cell_multiplier\n",
    "        test_scene = test_scene[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "        mask_resized = mask[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "        \n",
    "        no_cells = no_cells[segment_2_top_left[0]:segment_1_bottom_right[0],segment_2_top_left[1]:segment_1_bottom_right[1]]\n",
    "        expanded_scene_no_cells = np.zeros((int(no_cells.shape[0]*1.2), no_cells.shape[1]*2)) + media_multiplier\n",
    "        expanded_scene_no_cells[expanded_scene_no_cells.shape[0] - no_cells.shape[0]:,int(no_cells.shape[1]/2):int(no_cells.shape[1]/2) + no_cells.shape[1]] = no_cells\n",
    "\n",
    "        expanded_scene = np.zeros((int(test_scene.shape[0]*1.2), test_scene.shape[1]*2)) + media_multiplier\n",
    "        expanded_scene[expanded_scene.shape[0] - test_scene.shape[0]:,int(test_scene.shape[1]/2):int(test_scene.shape[1]/2) + test_scene.shape[1]] = test_scene\n",
    "        \n",
    "        expanded_mask = np.zeros((int(test_scene.shape[0]*1.2), test_scene.shape[1]*2))\n",
    "        expanded_mask[expanded_mask.shape[0] - test_scene.shape[0]:,int(test_scene.shape[1]/2):int(test_scene.shape[1]/2) + test_scene.shape[1]] = mask_resized\n",
    "        \n",
    "        return expanded_scene, expanded_scene_no_cells, expanded_mask\n",
    "    expanded_scene, expanded_scene_no_cells, expanded_mask = get_OPL_image()\n",
    "    if expanded_scene is None:\n",
    "        main_segments = main_segments.reindex(index=main_segments.index[::-1])\n",
    "        expanded_scene, expanded_scene_no_cells, expanded_mask = get_OPL_image()\n",
    "    return expanded_scene, expanded_scene_no_cells, expanded_mask\n",
    "\n",
    "def convolve_rescale(image,kernel,rescale_factor, rescale_int):\n",
    "    output = cuconvolve(cp.array(image),cp.array(kernel))\n",
    "    output = output.get()\n",
    "    output = rescale(output, rescale_factor, anti_aliasing=False)\n",
    "    \n",
    "    if rescale_int:\n",
    "        output = rescale_intensity(output.astype(np.float32), out_range=(0,1))\n",
    "    return output\n",
    "\n",
    "#make convolved image and real image same shape\n",
    "def make_images_same_shape(real_image,synthetic_image, rescale_int = True):\n",
    "    x_diff = synthetic_image.shape[1] - real_image.shape[1]\n",
    "    remove_from_left, remove_from_right = div_odd(x_diff)\n",
    "    y_diff = synthetic_image.shape[0] - real_image.shape[0]\n",
    "    if y_diff > 0:\n",
    "        synthetic_image = synthetic_image[y_diff:,remove_from_left-1:-remove_from_right]\n",
    "    else:\n",
    "        synthetic_image = synthetic_image[:,remove_from_left:-remove_from_right]\n",
    "        real_image = real_image[abs(y_diff):,:]\n",
    "\n",
    "    if rescale_int:\n",
    "        real_image = rescale_intensity(real_image.astype(np.float32), out_range=(0,1))\n",
    "        synthetic_image = rescale_intensity(synthetic_image.astype(np.float32), out_range=(0,1))\n",
    "    return real_image, synthetic_image\n",
    "\n",
    "def generate_test_comparison(media_multiplier, cell_multiplier, device_multiplier, sigma, scene_no, scale, match_histogram, match_noise, offset, debug_plot=True, noise_var=0.002):\n",
    "    \n",
    "    \n",
    "    expanded_scene, expanded_scene_no_cells, expanded_mask = generate_PC_OPL(\n",
    "        main_segments=main_segments,\n",
    "        offset=offset,\n",
    "        scene = scenes[scene_no][0],\n",
    "        mask = scenes[scene_no][1],\n",
    "        media_multiplier=media_multiplier,\n",
    "        cell_multiplier=cell_multiplier,\n",
    "        device_multiplier=device_multiplier\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, sigma, 0.75)\n",
    "\n",
    "\n",
    "\n",
    "    convolved = convolve_rescale(expanded_scene, kernel, 1/resize_amount, rescale_int = True)\n",
    "    real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "    \n",
    "    \n",
    "    if match_histogram:\n",
    "        matched = match_histograms(expanded_resized, real_resize, multichannel=False)\n",
    "    else:\n",
    "        matched = expanded_resized\n",
    "    \n",
    "    \n",
    "    noisy_img = random_noise(rescale_intensity(matched), mode=\"poisson\")\n",
    "    noisy_img = random_noise(rescale_intensity(noisy_img), mode=\"gaussian\", mean=0,var=noise_var,clip=False)\n",
    "    \n",
    "    if match_noise:\n",
    "        noisy_img = match_histograms(noisy_img, real_resize, multichannel=False)\n",
    "    else:\n",
    "        pass\n",
    "    noisy_img = rescale_intensity(noisy_img.astype(np.float32), out_range=(0,1))\n",
    "    \n",
    "    ## getting the cell mask to the right shape\n",
    "    expanded_mask_resized = rescale(expanded_mask, 1/resize_amount, anti_aliasing=False)\n",
    "    _, expanded_mask_resized_reshaped = make_images_same_shape(real_image,expanded_mask_resized, rescale_int=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    expanded_media_mask = rescale((expanded_scene_no_cells == device_multiplier) ^ (expanded_scene - expanded_scene_no_cells).astype(bool) , 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_media_mask = make_images_same_shape(real_image,expanded_media_mask, rescale_int=True)\n",
    "    just_media = expanded_media_mask * noisy_img\n",
    "    \n",
    "    expanded_cell_pseudo_mask = (expanded_scene - expanded_scene_no_cells).astype(bool)\n",
    "    expanded_cell_pseudo_mask = rescale(expanded_cell_pseudo_mask, 1/resize_amount, anti_aliasing=False)\n",
    "\n",
    "    real_resize, expanded_cell_pseudo_mask = make_images_same_shape(real_image,expanded_cell_pseudo_mask, rescale_int=True)\n",
    "    just_cells = expanded_cell_pseudo_mask * noisy_img\n",
    "    \n",
    "    expanded_device_mask = expanded_scene_no_cells == media_multiplier\n",
    "    expanded_device_mask = rescale(expanded_device_mask, 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_device_mask = make_images_same_shape(real_image,expanded_device_mask, rescale_int=True)\n",
    "    just_device = expanded_device_mask * noisy_img\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    simulated_means = np.array([just_media[np.where(just_media)].mean(), just_cells[np.where(just_cells)].mean(), just_device[np.where(just_device)].mean()])\n",
    "    simulated_vars = np.array([just_media[np.where(just_media)].var(), just_cells[np.where(just_cells)].var(), just_device[np.where(just_device)].var()])\n",
    "\n",
    "    \n",
    "    \n",
    "    mean_error.append(np.mean(perc_diff(real_means, simulated_means)))\n",
    "    media_error.append(perc_diff(simulated_means[0], real_media_mean))\n",
    "    cell_error.append(perc_diff(simulated_means[1], real_cell_mean))\n",
    "    device_error.append(perc_diff(simulated_means[2], real_device_mean))\n",
    "    \n",
    "    \n",
    "    mean_var_error.append(np.mean(perc_diff(real_vars, simulated_vars)))\n",
    "    media_var_error.append(perc_diff(simulated_vars[0], real_media_var))\n",
    "    cell_var_error.append(perc_diff(simulated_vars[1], real_cell_var))\n",
    "    device_var_error.append(perc_diff(simulated_vars[2], real_device_var))\n",
    "    if debug_plot == True:\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax1 = plt.subplot2grid((1,8),(0,0),colspan=1,rowspan=1)\n",
    "        ax2 = plt.subplot2grid((1,8),(0,1),colspan=1,rowspan=1)\n",
    "        ax3 = plt.subplot2grid((1,8),(0,2),colspan=3,rowspan=1)\n",
    "        ax4 = plt.subplot2grid((1,8),(0,5),colspan=3,rowspan=1)\n",
    "        ax1.imshow(noisy_img,cmap=\"Greys_r\")\n",
    "        ax1.set_title(\"Synthetic\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(real_resize,cmap=\"Greys_r\")\n",
    "        ax2.set_title(\"Real\")\n",
    "        ax2.axis(\"off\")\n",
    "        ax3.plot(mean_error)\n",
    "        ax3.plot(media_error)\n",
    "        ax3.plot(cell_error)\n",
    "        ax3.plot(device_error)\n",
    "        ax3.legend([\"Mean error\", \"Media error\", \"Cell error\", \"Device error\"])\n",
    "        ax3.set_title(\"Intensity Error\")\n",
    "\n",
    "        ax4.plot(mean_var_error)\n",
    "        ax4.plot(media_var_error)\n",
    "        ax4.plot(cell_var_error)\n",
    "        ax4.plot(device_var_error)\n",
    "        ax4.legend([\"Mean error\", \"Media error\", \"Cell error\", \"Device error\"])\n",
    "        ax4.set_title(\"Variance Error\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    else:\n",
    "        return noisy_img, expanded_mask_resized_reshaped\n",
    "\n",
    "def get_space_size(cell_timeseries_properties):\n",
    "    \"\"\"Iterates through the simulation timeseries properties, \n",
    "    finds the extreme cell positions and retrieves the required \n",
    "    image size to fit all cells into\"\"\"\n",
    "    max_x, max_y = 0, 0\n",
    "    for timepoint in cell_timeseries_properties:\n",
    "        for cell in timepoint:\n",
    "            x_, y_ = np.ceil(cell[3]).astype(int)\n",
    "            length_ = np.ceil(cell[0]).astype(int)\n",
    "            width_ = np.ceil(cell[1]).astype(int)\n",
    "            max_y_ = y_ + length_\n",
    "            max_x_ = x_ + width_\n",
    "            if max_x_ > max_x:\n",
    "                max_x = max_x_\n",
    "            if max_y_ > max_y:\n",
    "                max_y = max_y_\n",
    "    return (int(1.2*max_y), int(1.5*max_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30746946-f64c-48f0-bda8-5c454d7dfcb0",
   "metadata": {},
   "source": [
    "### Do large cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e81a7c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d9850227ca4135b5a3ab1f57a65742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simulation Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf6ff9ac0cb451e858a95ef55c2a5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Timeseries Properties::   0%|          | 0/749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009f2983be504c7daa79eeaa0eedc227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scene Draw::   0%|          | 0/749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_length = 750\n",
    "cell_timeseries, space = run_simulation(trench_length=15, trench_width=1.45, cell_max_length=5.5, cell_width=1.05, sim_length = sim_length) # growth phase\n",
    "#cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=1.45, cell_width=0.85, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=14)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties:'))\n",
    "do_transformation = False\n",
    "offset = 5\n",
    "mask_threshold = 17\n",
    "space_size = get_space_size(cell_timeseries_properties)\n",
    "scenes = Parallel(n_jobs=-1)(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "034e81eb-89c7-4ea5-afcc-c078f2d18480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:napari_ndtiffs.affine:Could not import pyopencl. Falling back to scipy for CPU affine transforms\n"
     ]
    }
   ],
   "source": [
    "media_multiplier=-30\n",
    "cell_multiplier=-1\n",
    "device_multiplier=150\n",
    "\n",
    "\n",
    "condensers = get_condensers()\n",
    "W, R, diameter = condensers[\"Ph2\"]\n",
    "scale = 0.108379937 / 3 #0.35 #micron per pixel\n",
    "min_sigma = 0.42*0.6/6 / scale # micron\n",
    "\n",
    "resize_amount = 1/scale/10\n",
    "\n",
    "\n",
    "\n",
    "temp_expanded_scene, temp_expanded_scene_no_cells, temp_expanded_mask = generate_PC_OPL(\n",
    "    main_segments=main_segments,\n",
    "    offset=50,\n",
    "    scene = scenes[0][0],\n",
    "    mask = scenes[0][1],\n",
    "    media_multiplier=1,\n",
    "    cell_multiplier=1,\n",
    "    device_multiplier=1\n",
    ")\n",
    "\n",
    "temp_kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, min_sigma, 0.75)\n",
    "\n",
    "\n",
    "\n",
    "convolved = convolve_rescale(temp_expanded_scene, temp_kernel, 1/resize_amount, rescale_int = True)\n",
    "real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "\n",
    "viewer = napari.view_image(real_resize)\n",
    "media_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"media\")\n",
    "cell_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"cell\")\n",
    "device_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "402fc7cd-5c59-4702-b0b0-c3241cf707e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_media_mean = real_resize[np.where(media_label.data)].mean();\n",
    "real_cell_mean = real_resize[np.where(cell_label.data)].mean(); \n",
    "real_device_mean = real_resize[np.where(device_label.data)].mean()\n",
    "real_means = np.array((real_media_mean, real_cell_mean, real_device_mean))\n",
    "\n",
    "real_media_var = real_resize[np.where(media_label.data)].var();\n",
    "real_cell_var = real_resize[np.where(cell_label.data)].var(); \n",
    "real_device_var = real_resize[np.where(device_label.data)].var()\n",
    "real_vars = np.array((real_media_var, real_cell_var, real_device_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7ef9f0e0-ec46-410a-ae01-60ef3caa87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=(scale,scale,scale),\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "offset=(offset,offset,offset));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f6836af3-3e30-4e62-8dcb-2f1cd7900c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765e59d5ebd84e79aaea3d6b72bac95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='media_multiplier', max=300, min=-300), FloatSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c10830fe-3a9b-4ec7-a591-e1079693ea91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353343"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5874dbde-ddfe-41ee-8059-99c93a2cf732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(interactive_output, sample_amount, randomise_hist_match, randomise_noise_match, sim_length, burn_in, n_samples, save_dir):\n",
    "    media_multiplier, cell_multiplier, device_multiplier, sigma, scene_no, scale, match_histogram, match_noise, offset, debug_plot, noise_var = list(interactive_output.kwargs.values())\n",
    "    debug_plot = False\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(save_dir + \"/convolutions\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(save_dir + \"/masks\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    current_file_num = len(os.listdir(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/convolutions\"))\n",
    "    #for z in range(n_samples):\n",
    "    def generate_samples(z):\n",
    "        _media_multiplier = np.random.uniform(1-sample_amount,1+sample_amount) * media_multiplier\n",
    "        _cell_multiplier = np.random.uniform(1-sample_amount,1+sample_amount) * cell_multiplier\n",
    "        _device_multiplier = np.random.uniform(1-sample_amount,1+sample_amount) * device_multiplier\n",
    "        _sigma = np.random.uniform(1-sample_amount,1+sample_amount) * sigma\n",
    "        _scene_no = np.random.randint(burn_in,sim_length-2)\n",
    "        _noise_var = np.random.uniform(1-sample_amount,1+sample_amount) * noise_var\n",
    "        if randomise_hist_match:\n",
    "            _match_histogram = np.random.choice([True, False])\n",
    "        if randomise_noise_match:\n",
    "            _match_noise = np.random.choice([True, False])\n",
    "        \n",
    "        syn_image, mask = generate_test_comparison(_media_multiplier, _cell_multiplier, _device_multiplier, _sigma, _scene_no, scale, _match_histogram, match_noise, offset, debug_plot, noise_var)\n",
    "        \n",
    "        syn_image = Image.fromarray(skimage.img_as_uint(rescale_intensity(syn_image)))\n",
    "        syn_image.save(\"{}/convolutions/synth_{}.tif\".format(save_dir, str(z).zfill(5)))\n",
    "        mask = Image.fromarray(mask)\n",
    "        mask.save(\"{}/masks/synth_{}.tif\".format(save_dir, str(z).zfill(5)))        \n",
    "    ## TODO: change parallel if not using GPU\n",
    "    Parallel(n_jobs=1)(delayed(generate_samples)(z) for z in tqdm(range(current_file_num,n_samples+current_file_num), desc=\"Sample generation:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "005633aa-0587-4639-a40e-24cc202dad5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c9a1096bf64a2ca188b74b72031578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sample generation::   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.02, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  1500, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695e753-539c-4365-b373-e38329014986",
   "metadata": {},
   "source": [
    "### Do small cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d9a10de-1304-47a8-a5dd-202bc894f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scene(cell_properties, do_transformation, mask_threshold, space_size, offset):\n",
    "    space_size = np.array(space_size) # 1000, 200 a good value\n",
    "    space = np.zeros(space_size)\n",
    "    space_masks = np.zeros(space_size)\n",
    "    offsets = offset \n",
    "    for properties in cell_properties:\n",
    "        length, width, angle, position, freq_modif, amp_modif, phase_modif,phase_mult = properties\n",
    "        length = length; width = width ; position = np.array(position) \n",
    "        angle = np.rad2deg(angle) - 90\n",
    "        x, y = np.array(position).astype(int) + offsets\n",
    "        OPL_cell = raster_cell(length = length, width=width)\n",
    "        \n",
    "        if do_transformation:\n",
    "            OPL_cell_2 = np.zeros((OPL_cell.shape[0],int(OPL_cell.shape[1]*2)))\n",
    "            midpoint = int(np.median(range(OPL_cell_2.shape[1])))\n",
    "            OPL_cell_2[:,midpoint-int(OPL_cell.shape[1]/2):midpoint-int(OPL_cell.shape[1]/2)+OPL_cell.shape[1]] = OPL_cell\n",
    "            roll_coords = np.array(range(OPL_cell_2.shape[0]))\n",
    "            freq_mult = (OPL_cell_2.shape[0])\n",
    "            amp_mult = OPL_cell_2.shape[1]/10\n",
    "            sin_transform_cell = transform_func(amp_modif, freq_modif, phase_modif)\n",
    "            roll_amounts = sin_transform_cell(roll_coords,amp_mult,freq_mult,phase_mult)\n",
    "            for B in roll_coords:\n",
    "                OPL_cell_2[B,:] = np.roll(OPL_cell_2[B,:], roll_amounts[B])\n",
    "            OPL_cell = (OPL_cell_2)\n",
    "        \n",
    "        rotated_OPL_cell = rotate(OPL_cell,angle,resize=True,clip=False,preserve_range=True)\n",
    "        cell_y, cell_x = (np.array(rotated_OPL_cell.shape)/2).astype(int)\n",
    "        offset_y = rotated_OPL_cell.shape[0] - space[y-cell_y:y+cell_y,x-cell_x:x+cell_x].shape[0]\n",
    "        offset_x = rotated_OPL_cell.shape[1] - space[y-cell_y:y+cell_y,x-cell_x:x+cell_x].shape[1]\n",
    "        assert y > cell_y, \"Cell has {} negative pixels in y coordinate, try increasing your offset\".format(y - cell_y)\n",
    "        assert x > cell_x, \"Cell has negative pixels in x coordinate, try increasing your offset\"\n",
    "        space[\n",
    "            y-cell_y:y+cell_y+offset_y,\n",
    "            x-cell_x:x+cell_x+offset_x\n",
    "        ] += rotated_OPL_cell\n",
    "        space_masks[y-cell_y:y+cell_y+offset_y,x-cell_x:x+cell_x+offset_x] += (rotated_OPL_cell > mask_threshold)\n",
    "        space_masks = space_masks == 1\n",
    "\n",
    "\n",
    "        #space_masks = opening(space_masks,np.ones((2,11)))\n",
    "    return space, space_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312d5fb-ca93-4fcf-b322-c9a17ee866c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5258aed8c2427f8c41cd78cff58fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simulation Progress:   0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafe7a4473964656ad67470b4637578b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Timeseries Properties::   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85a012aa9c84a538b963033e536e3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scene Draw::   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_length = 200\n",
    "cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=1.45, cell_width=0.85, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=-1)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties:'))\n",
    "do_transformation = False\n",
    "offset = 20\n",
    "mask_threshold = 17\n",
    "space_size = (1000,200)\n",
    "scenes = Parallel(n_jobs=-1, backend='multiprocessing')(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "30fb03dd-24b7-4ba2-9cc0-af491bdd68b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f40b332bf70>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scenes[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99bd965a-cc77-444a-aa0c-2b5fb0e30029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cfb3353f2441cfa75e37f293b0caf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='media_multiplier', max=300, min=-300), FloatSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=scale,\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "offset=(offset,offset,offset));\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6abcdd96-3e14-4e2b-b9ef-8f19ab5a5ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d21406c961471abf0520ad370ed390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sample generation::   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.095, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  120, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886209b-3b9e-4daf-9161-498fab1ecfa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_images_to_optimise(expanded_scene,expanded_scene_no_cells,expanded_resized, real_image, convolved, resize_amount):\n",
    "    expanded_media_mask = rescale((expanded_scene_no_cells == device_multiplier) ^ (expanded_scene - expanded_scene_no_cells).astype(bool) , 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_media_mask = make_images_same_shape(real_image,expanded_media_mask, rescale_int=True)\n",
    "    just_media = expanded_media_mask * expanded_resized\n",
    "    \n",
    "    expanded_cell_pseudo_mask = (expanded_scene - expanded_scene_no_cells).astype(bool)\n",
    "    expanded_cell_pseudo_mask = rescale(expanded_cell_pseudo_mask, 1/resize_amount, anti_aliasing=False)\n",
    "\n",
    "    real_resize, expanded_cell_pseudo_mask = make_images_same_shape(real_image,expanded_cell_pseudo_mask, rescale_int=True)\n",
    "    just_cells = expanded_cell_pseudo_mask * expanded_resized\n",
    "    \n",
    "    expanded_device_mask = expanded_scene_no_cells == media_multiplier\n",
    "    expanded_device_mask = rescale(expanded_device_mask, 1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_device_mask = make_images_same_shape(real_image,expanded_device_mask, rescale_int=True)\n",
    "    just_device = expanded_device_mask * expanded_resized\n",
    "    \n",
    "    return just_media, just_cells, just_device, expanded_media_mask, expanded_cell_pseudo_mask, expanded_device_mask\n",
    "\n",
    "just_media, just_cells, just_device, perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask = get_images_to_optimise(expanded_scene,expanded_scene_no_cells,expanded_resized, real_image, convolved, resize_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4872d-44c8-4bd4-9df2-1f481701b261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_intensity_means(perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask, expanded_resized):\n",
    "    return (perm_expanded_media_mask * expanded_resized).mean(), (perm_expanded_cell_pseudo_mask * expanded_resized).mean(), (perm_expanded_device_mask * expanded_resized).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1be0b7-0723-41e1-afad-dee308759e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPL_image_convolved = []\n",
    "global current_error\n",
    "current_error = 10\n",
    "best_input = []\n",
    "\n",
    "def objective_function(v, return_diagnostics = False):\n",
    "    global current_error\n",
    "    media_multiplier, cell_multiplier, device_multiplier= v\n",
    "    expanded_scene, expanded_scene_no_cells, expanded_mask = generate_PC_OPL(\n",
    "    main_segments=main_segments,\n",
    "    offset=50,\n",
    "    scene = scenes[4][0],\n",
    "    mask = scenes[4][1],\n",
    "    media_multiplier=media_multiplier,\n",
    "    cell_multiplier=cell_multiplier,\n",
    "    device_multiplier=device_multiplier\n",
    "    )\n",
    "\n",
    "\n",
    "    resize_amount = 1/scale/10\n",
    "\n",
    "    ## Creating the synthetic image\n",
    "    kernel = get_phase_contrast_kernel(R, W, 50, scale, 5, 7, 0.6)\n",
    "    convolved = convolve_rescale(expanded_scene, kernel, resize_amount, rescale_int = True)\n",
    "    real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "\n",
    "    ## getting the cell mask to the right shape\n",
    "    expanded_mask_resized = rescale(expanded_mask,1/resize_amount, anti_aliasing=False)\n",
    "    real_resize, expanded_mask_resized_reshaped = make_images_same_shape(real_image,expanded_mask_resized, rescale_int=True)\n",
    "    _, _, _, perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask = get_images_to_optimise(expanded_scene,expanded_scene_no_cells,expanded_resized, real_image, convolved, resize_amount)\n",
    "    simulated_means = np.array(get_intensity_means(perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask, expanded_resized))\n",
    "\n",
    "    perc_sum = sum(perc_diff(real_means, simulated_means))\n",
    "\n",
    "    if perc_sum < current_error:\n",
    "        current_error = perc_sum\n",
    "        print(current_error)\n",
    "        best_input.append(v)\n",
    "        OPL_image_convolved.append(expanded_resized)\n",
    "    \n",
    "    if return_diagnostics == True:\n",
    "        return expanded_resized, simulated_means, perc_sum\n",
    "    else:\n",
    "        if np.isnan(perc_sum):\n",
    "            return 100\n",
    "        else:\n",
    "            return perc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db630504-15b5-45d2-81e7-c7ce07003771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_function(np.array([-20,-1,20]), return_diagnostics = True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eface7cb-62fe-41de-8971-f6ae3df3309d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(objective_function(np.array([-20,-1,10]), return_diagnostics = True)[0], cmap=\"Greys_r\", vmax=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae16f7-8a7c-4ed0-954f-67653b13fab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(perm_expanded_cell_pseudo_mask*objective_function(np.array([-20,-1,20]), return_diagnostics = True)[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87599530-8f38-4f3b-917f-afed2dc010c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_intensity_means(perm_expanded_media_mask, perm_expanded_cell_pseudo_mask, perm_expanded_device_mask, objective_function(np.array([-20,-1,20]), return_diagnostics = True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7d0a0-3cb6-4e01-b178-2e604d18a45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "perc_diff = lambda a, b: abs(a-b)/abs((a+b)/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0617b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "progress = []\n",
    "def callbackF(x, f, context):\n",
    "    print(x)\n",
    "    progress.append(x)\n",
    "    \n",
    "def callbackSHGo(x):\n",
    "    print(x)\n",
    "    progress.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fbb71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bounds = list(zip([-500, -500, -500], [500.0, 500.0, 500.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff629a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ret = shgo(objective_function, bounds = np.array(bounds),callback=callbackSHGo,options={\"minimize_every_iter\":True})\n",
    "ret = dual_annealing(objective_function, bounds = np.array(bounds),callback=callbackF) # ,maxiter=10,initial_temp=5*10**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0cc47-57c0-45e6-88b1-89d5a67ae16a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret = basinhopping(objective_function, x0 = (0,0,0),callback=callbackF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2bed2-33a3-4351-af9a-500c0cfe74ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808fbde-39bf-433a-a33b-a35665a52956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret = differential_evolution(objective_function, bounds, popsize = 200, mutation = 1.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c24683-68a7-4956-a38d-b9aadb91fbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranges = [np.arange(-50,50, 5), np.arange(-50,50, 5), np.arange(-50,50, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512915d-0728-4730-9e0f-2337112bd2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = (list(itertools.product(*ranges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073e1c1-bd91-4341-9c02-aa1bb1a3431a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fd458-aa46-4927-b332-e765a936d708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.uniform(low=-1000,high=1000,size=(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cde0c3-407f-4433-81a2-84f2ab20209f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPL_image_convolved = []\n",
    "current_error = 10\n",
    "best_input = []\n",
    "a = 0\n",
    "while True:    \n",
    "    temp_output = objective_function(np.random.uniform(low=-1000,high=1000,size=(3)), True)\n",
    "    a+=1\n",
    "    if temp_output[1] < current_error:\n",
    "        current_error = temp_output[1]\n",
    "        print(current_error)\n",
    "        best_input.append(list(input_) + [3.9])\n",
    "        OPL_image_convolved.append(temp_output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a5014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(OPL_image_convolved[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

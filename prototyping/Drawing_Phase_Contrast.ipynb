{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8403999f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93dc6125-400d-40ff-ab4d-38101cfdc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3704125e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "import sys\n",
    "sys.path.insert(0,'/home/georgeos/Documents/GitHub/SYMPTOMM2')\n",
    "from SYMPTOMM.cell import Cell\n",
    "from SYMPTOMM.scene_functions import create_space, step_and_update\n",
    "from SYMPTOMM.trench_geometry import trench_creator\n",
    "from SYMPTOMM.phase_contrast_drawing import *\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from skimage.exposure import rescale_intensity\n",
    "from ipywidgets import interactive\n",
    "import os\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "from SYMPTOMM.PSF import get_phase_contrast_kernel, get_condensers\n",
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/top_trenches_PC/trench_{}/T_{}.tif\".format(\n",
    "    str(np.random.randint(1,56)).zfill(2),\n",
    "    str(np.random.randint(10,20)).zfill(3)))\n",
    "\n",
    "#viewer = napari.view_image(real_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64476ce1-d433-4a92-965a-6d8d0cf5534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = tifffile.imread(\"/home/georgeos/Storage/Dropbox (Cambridge University)/Phase/Lane_02_pos_002_trench_x_1963_y_0067_w_0046_h_0460_c_Phase.tif\")[0][:300,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdde6fa3-2b58-4a6b-9828-7350db850d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 46)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa476171-0ee2-4c5c-af18-a7fdf33e9374",
   "metadata": {},
   "source": [
    "### Scope props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51cc96ea-77be-4860-8f5d-eb0aaa1f4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensers = get_condensers()\n",
    "W, R, diameter = condensers[\"Ph2\"]\n",
    "radius=50\n",
    "#F = 5\n",
    "λ = 0.75\n",
    "resize_amount = 3\n",
    "pix_mic_conv = 0.0655 ##0.108379937 micron/pix for 60x, 0.0655 for 100x\n",
    "scale = pix_mic_conv / resize_amount \n",
    "min_sigma = 0.42*0.6/6 / scale # micron#\n",
    "sigma=min_sigma\n",
    "NA=1.54\n",
    "n = 1.4\n",
    "kernel_params = (R,W,radius,scale,NA,n,sigma,λ)\n",
    "\n",
    "#kernel_params = (R,W,radius,scale,F,sigma,λ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b893f2-a358-416e-bae6-56e4c4a33a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_params = (R,W,radius,scale,NA,n,sigma,λ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30746946-f64c-48f0-bda8-5c454d7dfcb0",
   "metadata": {},
   "source": [
    "### Do large cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e81a7c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulation Progress: 100%|██████████| 290/290 [00:03<00:00, 75.86it/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1cebd0276048999c2bd65212dbb0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Timeseries Properties:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2540973b4f4a93818e27df4fa50f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scene Draw::   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_length = 40\n",
    "cell_timeseries, space = run_simulation(\n",
    "    trench_length=17, \n",
    "    trench_width=1.5, \n",
    "    cell_max_length=4.7, \n",
    "    cell_width=1.15, \n",
    "    sim_length = sim_length, \n",
    "    pix_mic_conv = pix_mic_conv,\n",
    "    gravity=-10,\n",
    "    phys_iters=25\n",
    ") # growth phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=14)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties'))\n",
    "do_transformation = True\n",
    "offset = 30\n",
    "mask_threshold = 18\n",
    "label_masks = True\n",
    "space_size = get_space_size(cell_timeseries_properties)\n",
    "scenes = Parallel(n_jobs=-1)(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset, label_masks) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "034e81eb-89c7-4ea5-afcc-c078f2d18480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/georgeos/Documents/GitHub/SYMPTOMM2/SYMPTOMM/PSF.py:104: RuntimeWarning: invalid value encountered in true_divide\n",
      "  kernel1 = 2*jv(1,rr)/(rr)\n",
      "/home/georgeos/Documents/GitHub/SYMPTOMM2/SYMPTOMM/PSF.py:107: RuntimeWarning: invalid value encountered in true_divide\n",
      "  kernel2 = 2*(R-W)**2/R**2 * jv(1,(R-W)**2/R**2 * rr)/rr\n"
     ]
    }
   ],
   "source": [
    "media_multiplier=30\n",
    "cell_multiplier=1\n",
    "device_multiplier=-50\n",
    "y_border_expansion_coefficient = 2\n",
    "x_border_expansion_coefficient = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "temp_expanded_scene, temp_expanded_scene_no_cells, temp_expanded_mask = generate_PC_OPL(\n",
    "   main_segments=main_segments,\n",
    "    offset=offset,\n",
    "    scene = scenes[0][0],\n",
    "    mask = scenes[0][1],\n",
    "    media_multiplier=media_multiplier,\n",
    "    cell_multiplier=cell_multiplier,\n",
    "    device_multiplier=cell_multiplier,\n",
    "    y_border_expansion_coefficient = y_border_expansion_coefficient,\n",
    "    x_border_expansion_coefficient = x_border_expansion_coefficient\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "### Generate temporary image to make same shape\n",
    "temp_kernel = get_phase_contrast_kernel(*kernel_params)\n",
    "convolved = convolve_rescale(temp_expanded_scene, temp_kernel, 1/resize_amount, rescale_int = True)\n",
    "real_resize, expanded_resized = make_images_same_shape(real_image,convolved, rescale_int=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6eb54f0-ee62-4dd0-afcd-69374fbe6608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:napari_ndtiffs.affine:Could not import pyopencl. Falling back to scipy for CPU affine transforms\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.view_image(real_resize)\n",
    "media_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"media\")\n",
    "cell_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"cell\")\n",
    "device_label = viewer.add_labels(np.zeros(real_resize.shape).astype(int), name = \"device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "402fc7cd-5c59-4702-b0b0-c3241cf707e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-c6a8b6c5825e>:1: RuntimeWarning: Mean of empty slice.\n",
      "  real_media_mean = real_resize[np.where(media_label.data)].mean();\n",
      "<ipython-input-15-c6a8b6c5825e>:2: RuntimeWarning: Mean of empty slice.\n",
      "  real_cell_mean = real_resize[np.where(cell_label.data)].mean();\n",
      "<ipython-input-15-c6a8b6c5825e>:3: RuntimeWarning: Mean of empty slice.\n",
      "  real_device_mean = real_resize[np.where(device_label.data)].mean()\n",
      "<ipython-input-15-c6a8b6c5825e>:6: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  real_media_var = real_resize[np.where(media_label.data)].var();\n",
      "<ipython-input-15-c6a8b6c5825e>:7: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  real_cell_var = real_resize[np.where(cell_label.data)].var();\n",
      "<ipython-input-15-c6a8b6c5825e>:8: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  real_device_var = real_resize[np.where(device_label.data)].var()\n"
     ]
    }
   ],
   "source": [
    "real_media_mean = real_resize[np.where(media_label.data)].mean();\n",
    "real_cell_mean = real_resize[np.where(cell_label.data)].mean(); \n",
    "real_device_mean = real_resize[np.where(device_label.data)].mean()\n",
    "real_means = np.array((real_media_mean, real_cell_mean, real_device_mean))\n",
    "\n",
    "real_media_var = real_resize[np.where(media_label.data)].var();\n",
    "real_cell_var = real_resize[np.where(cell_label.data)].var(); \n",
    "real_device_var = real_resize[np.where(device_label.data)].var()\n",
    "real_vars = np.array((real_media_var, real_cell_var, real_device_var))\n",
    "\n",
    "image_params = (real_media_mean, real_cell_mean, real_device_mean, real_means, real_media_var, real_cell_var, real_device_var, real_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ef9f0e0-ec46-410a-ae01-60ef3caa87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "error_params = (mean_error,media_error,cell_error,device_error,mean_var_error,media_var_error,cell_var_error,device_var_error)\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.01),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=(scale,scale,scale),\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "    offset=fixed(offset),\n",
    "    main_segments = fixed(main_segments),\n",
    "    debug_plot=fixed(True),\n",
    "    scenes = fixed(scenes),\n",
    "    kernel_params = fixed(kernel_params),\n",
    "    resize_amount = fixed(resize_amount), \n",
    "    real_image = fixed(real_image),\n",
    "    image_params = fixed(image_params),\n",
    "    error_params = fixed(error_params),\n",
    "    x_border_expansion_coefficient = fixed(x_border_expansion_coefficient),\n",
    "    y_border_expansion_coefficient = fixed(y_border_expansion_coefficient)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46a8a43d-4bae-4630-8cdb-ac33f03181ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb560bb35d6431cbeebc9051c0d566e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='media_multiplier', max=300, min=-300), FloatSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c10830fe-3a9b-4ec7-a591-e1079693ea91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79967"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005633aa-0587-4639-a40e-24cc202dad5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.01, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  5000, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/for_stardist_bent_histmatched/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695e753-539c-4365-b373-e38329014986",
   "metadata": {},
   "source": [
    "### Do medium cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312d5fb-ca93-4fcf-b322-c9a17ee866c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_length = 50\n",
    "cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=2.45, cell_width=1.0, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=-1)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties:'))\n",
    "do_transformation = False\n",
    "offset = 40\n",
    "mask_threshold = 25\n",
    "space_size = (1000,200)\n",
    "label_masks = True\n",
    "scenes = Parallel(n_jobs=-1, backend='multiprocessing')(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset, label_masks) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd965a-cc77-444a-aa0c-2b5fb0e30029",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=scale,\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "offset=(offset,offset,offset));\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcdd96-3e14-4e2b-b9ef-8f19ab5a5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.02, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  1000, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/for_stardist_bent_histmatched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9ba8f-bbea-4da8-8be0-1be158493b41",
   "metadata": {},
   "source": [
    "## Do small cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0a552-e91e-4175-93d1-a43462971fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_length = 100\n",
    "cell_timeseries, space = run_simulation(trench_length=15.5, trench_width=1.25, cell_max_length=1.45, cell_width=1.0, sim_length = sim_length) # stationary phase\n",
    "main_segments = get_trench_segments(space)\n",
    "ID_props = generate_curve_props(cell_timeseries)\n",
    "cell_timeseries_properties = Parallel(n_jobs=-1)(\n",
    "    delayed(gen_cell_props_for_draw)(a, ID_props) for a in tqdm(cell_timeseries, desc='Timeseries Properties:'))\n",
    "do_transformation = False\n",
    "offset = 40\n",
    "mask_threshold = 25\n",
    "space_size = (1000,200)\n",
    "label_masks = True\n",
    "scenes = Parallel(n_jobs=-1, backend='multiprocessing')(delayed(draw_scene)(\n",
    "    cell_properties, do_transformation, mask_threshold, space_size, offset, label_masks) for cell_properties in tqdm(cell_timeseries_properties, desc='Scene Draw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f35ce-86a5-41f8-a1c7-210812aeb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "media_error = []\n",
    "cell_error = []\n",
    "device_error = []\n",
    "\n",
    "mean_var_error = []\n",
    "media_var_error = []\n",
    "cell_var_error = []\n",
    "device_var_error = []\n",
    "\n",
    "\n",
    "params = interactive(\n",
    "    generate_test_comparison,\n",
    "    media_multiplier=(-300,300,1),\n",
    "    cell_multiplier=(-30,30,0.1),\n",
    "    device_multiplier=(-300,300,1),\n",
    "    sigma=(min_sigma,min_sigma*20, min_sigma/20),\n",
    "    scene_no = (0,sim_length-2,1),\n",
    "    noise_var=(0,0.01, 0.0001),\n",
    "    scale=scale,\n",
    "    match_histogram = [True, False],\n",
    "    match_noise = [True, False],\n",
    "offset=(offset,offset,offset));\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545c16f-6cf4-40c8-9a86-e2acd5d943c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_training_data(interactive_output = params, sample_amount = 0.02, randomise_hist_match = True, randomise_noise_match = True, sim_length = sim_length, burn_in = 0, n_samples =  200, save_dir = \"/home/georgeos/Storage/Dropbox (Cambridge University)/PhD_Georgeos_Hardo/ML_based_segmentation_results/40x_Ph2_test_1.5/PC_training_data/for_stardist_bent_histmatched\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

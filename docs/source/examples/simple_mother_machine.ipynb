{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mother machine simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['DISPLAY'] = ':1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/georgeos/Documents/SyMBac/') # Not needed if you installed SyMBac using pip\n",
    "\n",
    "from SyMBac.simulation import Simulation\n",
    "from SyMBac.PSF import PSF_generator\n",
    "from SyMBac.renderer import Renderer\n",
    "from SyMBac.PSF import Camera\n",
    "from SyMBac.misc import get_sample_images\n",
    "real_image = get_sample_images()[\"E. coli 100x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a simulation\n",
    "\n",
    "Mother machine simulations are handled with the  `Simulation` class.\n",
    "\n",
    "Instantiating a `Simulation` object requires the following arguments to be specified:\n",
    "\n",
    "- *trench_length*: The length of the trench.\n",
    "- *trench_width*: The width of the trench.\n",
    "- *cell_max_length*: The maximum allowable length of a cell in the simulation.\n",
    "- *cell_width*: The average width of cells in the simulation.\n",
    "- *sim_length*: The number of timesteps to run the simulation for.\n",
    "- *pix_mic_conv*: The number of microns per pixel in the simulation. \n",
    "- *gravity*: The strength of the arbitrary gravity force in the simulations.\n",
    "- *phys_iters*: The number of iterations of the rigid body physics solver to run each timestep. Note that this affects how gravity works in the simulation, as gravity is applied every physics iteration, higher values of *phys_iters* will result in more gravity if it is turned on.\n",
    "- *max_length_var*: The variance applied to the normal distribution which has mean *cell_max_length*, from which maximum cell lengths are sampled.\n",
    "- *width_var*: The variance applied to the normal distribution of cell widths which has mean *cell_width*.\n",
    "- *save_dir*: The save location of the return value of the function. The output will be pickled and saved here, so that the simulation can be reloaded later withuot having to rerun it, for reproducibility. If you don't want to save it, just leave it as /tmp/`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "More details about this class can be found at the API reference: :meth:`SyMBac.simulation.Simulation` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "my_simulation = Simulation(\n",
    "    trench_length=15,\n",
    "    trench_width=1.15,\n",
    "    cell_max_length=6.65, #6, long cells # 1.65 short cells\n",
    "    cell_width= 1, #1 long cells # 0.95 short cells\n",
    "    sim_length = 100,\n",
    "    pix_mic_conv = 0.065,\n",
    "    gravity=0,\n",
    "    phys_iters=15,\n",
    "    max_length_var = 0.,\n",
    "    width_var = 0.,\n",
    "    lysis_p = 0.,\n",
    "    save_dir=\"/tmp/\",\n",
    "    resize_amount = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "We can then run the simulation by calling the :meth:`SyMBac.simulation.Simulation.run_simulation` method on our instantiated object. Setting `show_window=True` will bring up a `pyglet` window, allowing you to watch the simulation in real time. If you run SyMBac headless, then keep this setting set to `False`, you will be able to visualise the simulation in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "my_simulation.run_simulation(show_window=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "Next we call :meth:`SyMBac.simulation.Simulation.draw_simulation_OPL`, which will convert the output of the simulation to a tuple of two arrays, the first being the optical path length (OPL) images, and the second being the masks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes two arguments. \n",
    "\n",
    "- *do_transformation* - Whether or not to bend or morph the cells to increase realism.\n",
    "- *label_masks* - This controls whether the output training masks will be binary or labeled. Binary masks are used to train U-net (e.g DeLTA), wheras labeled masks are used to train Omnipose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_simulation.draw_simulation_OPL(do_transformation=True, label_masks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation visualisation\n",
    "\n",
    "We can visualise one of the OPL images and masks from the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(2,5))\n",
    "ax1.imshow(my_simulation.OPL_scenes[-1], cmap=\"Greys_r\")\n",
    "ax1.axis(\"off\")\n",
    "ax2.imshow(my_simulation.masks[-1])\n",
    "ax2.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "Alternatively we can bring up a napari window to visualise the simulation interactively using :meth:`SyMBac.simulation.Simulation.visualise_in_napari`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_simulation.visualise_in_napari()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point spread function (PSF) generation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "The next thing we must do is define the optical parameters which define the microscope simulation. To do this we instantiate a `PSF_generator`, which will create our point spread functions for us. We do this by passing in the parameters defined in :class:`SyMBac.PSF.PSF_generator` but below we show 3 examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 2D simple fluorescence kernel based on Airy\n",
    "my_kernel = PSF_generator(\n",
    "    radius = 50, \n",
    "    wavelength = 0.75, \n",
    "    NA = 1.4, \n",
    "    n = 1.51, \n",
    "    resize_amount = 3, \n",
    "    pix_mic_conv = 0.065, \n",
    "    apo_sigma = None, \n",
    "    mode=\"simple fluo\")\n",
    "my_kernel.calculate_PSF()\n",
    "my_kernel.plot_PSF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 3D fluorescence kernel based on the psfmodels library\n",
    "# (note the larger looking PSF due to the summed projection)\n",
    "# (During convolution, each slice of the image is convolved with the relevent \n",
    "# volume slice of the cell)\n",
    "my_kernel = PSF_generator(\n",
    "    z_height=50,\n",
    "    radius = 50, \n",
    "    wavelength = 0.75, \n",
    "    NA = 1.2, \n",
    "    n = 1.3, \n",
    "    resize_amount = 3, \n",
    "    pix_mic_conv = 0.065, \n",
    "    apo_sigma = None, \n",
    "    pz = 1,\n",
    "    working_distance = 170,\n",
    "    mode=\"3D fluo\")\n",
    "my_kernel.calculate_PSF()\n",
    "my_kernel.plot_PSF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# A phase contrast kernel\n",
    "my_kernel = PSF_generator(\n",
    "    radius = 50, \n",
    "    wavelength = 0.75, \n",
    "    NA = 1.2, \n",
    "    n = 1.3, \n",
    "    resize_amount = 3, \n",
    "    pix_mic_conv = 0.065, \n",
    "    apo_sigma = 20, \n",
    "    mode=\"phase contrast\", \n",
    "    condenser = \"Ph3\")\n",
    "my_kernel.calculate_PSF()\n",
    "my_kernel.plot_PSF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "Next we optionally define a camera based on :meth:`SyMBac.camera.Camera`, if your camera properties are known. If you do not know them, then you will be allowed to do *ad-hoc* noise matching during image optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "my_camera = Camera(baseline=100, sensitivity=2.9, dark_noise=8)\n",
    "my_camera.render_dark_image(size=(300,300));"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "Rendering\n",
    "---------\n",
    "\n",
    "Next we will create a renderer with :meth:`SyMBac.renderer.Renderer`, this will take our simulation, our PSF (in this case phase contrast), a real image, and optionally our camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "my_renderer = Renderer(simulation = my_simulation, PSF = my_kernel, real_image = real_image, camera = my_camera, additional_real_images = [real_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we shall extract some pixels from the real image which we will use to optimise the synthetic image. We will extract the pixel intensities and variances from the 3 important regions of the image. The cells, the device, and the media. These are the same three aforementioned intensities for which we “guessed” some parameters in the previous code block.\n",
    "\n",
    "We use napari to load the real image, and create three layers above it, called `media_label`, `cell_label`, and `device_label`. We will then select each layer and draw over the relevant regions of the image.\n",
    "\n",
    "A video below shows how it's done:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    ".. note:: \n",
    "    You do not need to completely draw over all the cells, the entire device, or all the media gaps between the cells. Simply getting a representative sample of pixels is generally enough. See the video below for a visual demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"sPC3nV_5DfM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "my_renderer.select_intensity_napari()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "Finally, we will use the manual optimiser (:meth:`SyMBac.renderer.Renderer.optimise_synth_image`) to generate a realistic image. The output from the optimiser will then be used to generate an entire dataset of synthetic images. Below the code is a video demonstrating the optimisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo(\"PeeyotMQAQU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "my_renderer.optimise_synth_image(manual_update=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "Finally, we generate our training data using :meth:`SyMBac.renderer.Renderer.generate_training_data`. \n",
    "\n",
    "The important parameters to recognise are:\n",
    "\n",
    "- *sample_amount*: This is a percentage by which all continuous parameters :func:`~SyMBac.optimisation.manual_optimise` can be randomly scaled during the synthesis process. For example, a value of 0.05 will randomly scale all continuous parameters by :math:`X \\sim U(0.95, 1.05)` Higher values will generate more variety in the training data (but too high values may result in unrealistic images).\n",
    "- *randomise_hist_match*: Whether to randomise the switching on and off of histogram matching.\n",
    "- *randomise_noise_match*: Whether to randomise the switching on and off of noise matching.\n",
    "- *sim_length*: The length of the simulation\n",
    "- *burn_in*: The number of frames at the beginning of the simulation to ignore. Useful if you do not want images of single cells to appear in your training data.\n",
    "- *n_samples*: The number of random training samples to generate.\n",
    "- *save_dir*: The save directory of the images. Will output two folders, ``convolutions`` and ``masks``.\n",
    "- *in_series*: Whether or not to shuffle the simulation while generating training samples.\n",
    "\n",
    ".. note::\n",
    "    When running this, you may choose to set ``in_series=True``. This will generate training data whereby each image is taken sequentially from the simulation. This useful if you want train a tracking model, where you need the frames to be in order. If you choose to set ``in_series=True``, then it is a good idea to choose a low value of ``sample_amount``, typically less than 0.05 is sensible. This reduces the frame-to-frame variability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample generation: 153it [00:05, 26.91it/s]"
     ]
    }
   ],
   "source": [
    "my_renderer.generate_training_data(sample_amount=0.1, randomise_hist_match=True, randomise_noise_match=True,  burn_in=40, n_samples = 500, save_dir=\"/tmp/test/\", in_series=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d73e5fda5dcb2575a75a56ed9fbeea47b5fa7fb8337a6ef0dda72b5e90aab48f"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
